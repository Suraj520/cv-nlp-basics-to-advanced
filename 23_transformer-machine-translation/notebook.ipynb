{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHKbMOH8CbxW"
      },
      "source": [
        "#### About\n",
        "Machine Translation using Transformers.\n",
        "\n",
        "Dataset link - https://www.kaggle.com/datasets/kaushal2896/english-to-german?select=deu.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s1RbdwACoeM",
        "outputId": "8ed5b8a3-526a-4e14-abd1-22210eba5ef8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "6Mh5gzhGDYzg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJQ1lDprCbxd",
        "outputId": "40f2b761-19be-4fff-8649-627732f58033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-12 05:59:50.760407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-12 05:59:50.760574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-12 05:59:50.760604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-12 05:59:53.608168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-12 06:00:05.405248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-12 06:00:05.405499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-12 06:00:05.405527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-12 06:00:07.852491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "#neccessary imports \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import spacy\n",
        "from torch import Tensor\n",
        "!pip install einops\n",
        "from einops import rearrange\n",
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "import math\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "-J-wDrloCbxg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/deu.txt',delimiter='\\t',header=None)\n",
        "df.columns = ['English','German','Source']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNZkO6cHNkym"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3jO2JODYCbxh",
        "outputId": "4aa0c047-f43b-45e8-fe23-fe5f98154946"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  English      German                                             Source\n",
              "0     Go.        Geh.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1     Hi.      Hallo!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "2     Hi.  Grüß Gott!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "3    Run!       Lauf!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4    Run.       Lauf!  CC-BY 2.0 (France) Attribution: tatoeba.org #4..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565369e3-8928-4c31-854d-f3bb661e8181\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Geh.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hallo!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Grüß Gott!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lauf!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Lauf!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565369e3-8928-4c31-854d-f3bb661e8181')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-565369e3-8928-4c31-854d-f3bb661e8181 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-565369e3-8928-4c31-854d-f3bb661e8181');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx3-x1meCbxj",
        "outputId": "6f1a6596-dd91-4fa7-8fcc-e51656fba8a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221533"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m02mCedCbxj",
        "outputId": "df72b4bd-2a8c-480e-8ce5-d503342eee3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Text - Hi.\n",
            "German Text - Hallo!\n",
            "End of sample- 1\n",
            "English Text - This may be our only chance.\n",
            "German Text - Das könnte unsere einzige Chance sein.\n",
            "End of sample- 100001\n",
            "English Text - This book deals with the invasion of the Romans.\n",
            "German Text - Dieses Buch handelt von der Invasion der Römer.\n",
            "End of sample- 200001\n"
          ]
        }
      ],
      "source": [
        "#printing few samples:\n",
        "for i in range(1,len(df),100000):\n",
        "    print(\"English Text - {}\".format(df['English'][i]))\n",
        "    print(\"German Text - {}\".format(df['German'][i]))\n",
        "    print('End of sample- {}'.format(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Y598NVe1Cbxk"
      },
      "outputs": [],
      "source": [
        "#splitting into train,val\n",
        "train_df,val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "LIOPaXwRCbxl"
      },
      "outputs": [],
      "source": [
        "#preprocessing the dataframe\n",
        "train_df.dropna(inplace=True)\n",
        "val_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GZWZqFb2Cbxm",
        "outputId": "3194547a-ac8f-4c6d-c17b-52e9ace2175c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                           Get out of here quickly!   \n",
              "1                                 Did you wash that?   \n",
              "2  Unless you make a decision quickly, the opport...   \n",
              "3          How did you know Tom was going to Boston?   \n",
              "4                                    Tom is humming.   \n",
              "\n",
              "                                              German  \\\n",
              "0                                 Schnell raus hier!   \n",
              "1                           Haben Sie das gewaschen?   \n",
              "2  Wenn du dich nicht schnell entscheidest, ist d...   \n",
              "3    Woher wusstest du, dass Tom nach Bosten fliegt?   \n",
              "4                                  Tom summt gerade.   \n",
              "\n",
              "                                              Source  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #8...  \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c84b0ef-6f97-47c7-a107-c4a129f2453a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Get out of here quickly!</td>\n",
              "      <td>Schnell raus hier!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did you wash that?</td>\n",
              "      <td>Haben Sie das gewaschen?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unless you make a decision quickly, the opport...</td>\n",
              "      <td>Wenn du dich nicht schnell entscheidest, ist d...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How did you know Tom was going to Boston?</td>\n",
              "      <td>Woher wusstest du, dass Tom nach Bosten fliegt?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tom is humming.</td>\n",
              "      <td>Tom summt gerade.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c84b0ef-6f97-47c7-a107-c4a129f2453a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c84b0ef-6f97-47c7-a107-c4a129f2453a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c84b0ef-6f97-47c7-a107-c4a129f2453a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xXdQN-nGCbxn",
        "outputId": "feb7164c-50f5-4db2-8161-5015e71032ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                         He was lying on the couch.   \n",
              "1  All generalizations are false, including this ...   \n",
              "2                      She dyed her white skirt red.   \n",
              "3                    Why don't you go play with Tom?   \n",
              "4                  She picked him up at the station.   \n",
              "\n",
              "                                              German  \\\n",
              "0                               Er lag auf dem Sofa.   \n",
              "1  Alle Verallgemeinerungen sind falsch, einschli...   \n",
              "2                  Sie färbte ihren weißen Rock rot.   \n",
              "3           Warum gehst du zum Spielen nicht zu Tom?   \n",
              "4                       Sie holte ihn am Bahnhof ab.   \n",
              "\n",
              "                                              Source  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #8...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a69c286-6c49-415b-91fd-9044d5563bd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was lying on the couch.</td>\n",
              "      <td>Er lag auf dem Sofa.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All generalizations are false, including this ...</td>\n",
              "      <td>Alle Verallgemeinerungen sind falsch, einschli...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She dyed her white skirt red.</td>\n",
              "      <td>Sie färbte ihren weißen Rock rot.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why don't you go play with Tom?</td>\n",
              "      <td>Warum gehst du zum Spielen nicht zu Tom?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>She picked him up at the station.</td>\n",
              "      <td>Sie holte ihn am Bahnhof ab.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a69c286-6c49-415b-91fd-9044d5563bd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a69c286-6c49-415b-91fd-9044d5563bd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a69c286-6c49-415b-91fd-9044d5563bd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5lcULGpMCbxo"
      },
      "outputs": [],
      "source": [
        "#cleaning the text\n",
        "#turning unicode string to plain ASCII\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "#clean text by converting to lower case, removing non -letter characters\n",
        "def clean_text(text):\n",
        "    text = unicodeToAscii(text.lower().strip())\n",
        "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
        "    text = re.sub(\"[.!?]\", '', text)\n",
        "    text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "fG8_YeNHCbxp"
      },
      "outputs": [],
      "source": [
        "#applying the clean_text method to df\n",
        "train_df[\"English\"] = train_df[\"English\"].apply(clean_text)\n",
        "train_df[\"German\"] = train_df[\"German\"].apply(clean_text)\n",
        "\n",
        "val_df[\"English\"] = val_df[\"English\"].apply(clean_text)\n",
        "val_df[\"German\"] = val_df[\"German\"].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9pqt-67DCbxp",
        "outputId": "0cbebee6-0586-4a96-b3bc-96010c3ff140"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                           get out of here quickly    \n",
              "1                                 did you wash that    \n",
              "2  unless you make a decision quickly the opportu...   \n",
              "3          how did you know tom was going to boston    \n",
              "4                                    tom is humming    \n",
              "\n",
              "                                              German  \\\n",
              "0                                 schnell raus hier    \n",
              "1                           haben sie das gewaschen    \n",
              "2  wenn du dich nicht schnell entscheidest ist di...   \n",
              "3     woher wusstest du dass tom nach bosten fliegt    \n",
              "4                                  tom summt gerade    \n",
              "\n",
              "                                              Source  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #8...  \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54afc4e7-ceac-423c-990e-15b0851fe1af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get out of here quickly</td>\n",
              "      <td>schnell raus hier</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>did you wash that</td>\n",
              "      <td>haben sie das gewaschen</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unless you make a decision quickly the opportu...</td>\n",
              "      <td>wenn du dich nicht schnell entscheidest ist di...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how did you know tom was going to boston</td>\n",
              "      <td>woher wusstest du dass tom nach bosten fliegt</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tom is humming</td>\n",
              "      <td>tom summt gerade</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54afc4e7-ceac-423c-990e-15b0851fe1af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54afc4e7-ceac-423c-990e-15b0851fe1af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54afc4e7-ceac-423c-990e-15b0851fe1af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MRefDjaKCbxq",
        "outputId": "4cbfb40c-500d-46f9-a014-7c216fd8f24e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                         he was lying on the couch    \n",
              "1  all generalizations are false including this one    \n",
              "2                      she dyed her white skirt red    \n",
              "3                    why don t you go play with tom    \n",
              "4                  she picked him up at the station    \n",
              "\n",
              "                                              German  \\\n",
              "0                               er lag auf dem sofa    \n",
              "1  alle verallgemeinerungen sind falsch einschlie...   \n",
              "2                  sie farbte ihren wei en rock rot    \n",
              "3           warum gehst du zum spielen nicht zu tom    \n",
              "4                       sie holte ihn am bahnhof ab    \n",
              "\n",
              "                                              Source  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #8...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1daf3b5-bece-4dd8-a1c9-5706375434c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>he was lying on the couch</td>\n",
              "      <td>er lag auf dem sofa</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all generalizations are false including this one</td>\n",
              "      <td>alle verallgemeinerungen sind falsch einschlie...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she dyed her white skirt red</td>\n",
              "      <td>sie farbte ihren wei en rock rot</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>why don t you go play with tom</td>\n",
              "      <td>warum gehst du zum spielen nicht zu tom</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she picked him up at the station</td>\n",
              "      <td>sie holte ihn am bahnhof ab</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1daf3b5-bece-4dd8-a1c9-5706375434c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1daf3b5-bece-4dd8-a1c9-5706375434c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1daf3b5-bece-4dd8-a1c9-5706375434c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvmIkt8UCbxq",
        "outputId": "ec303af1-a632-4c45-c60b-18aa636c4209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "OKiQJg9cCbxq"
      },
      "outputs": [],
      "source": [
        "start_token = 1\n",
        "end_token =2\n",
        "oov_token=3\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, language):\n",
        "        self.language = language\n",
        "        self.stoi = {}#string2index\n",
        "        self.stoc = {} # string2count\n",
        "        self.itos = {0:\"<PAD>\",start_token:\"<START>\",end_token:\"<END>\"}#index2sting #additional- add ,oov_token:\"<OOV>\"\n",
        "        for k,v in self.itos.items():\n",
        "            self.stoi[v]=k\n",
        "        self.num_words =31\n",
        "        if self.language == \"English\":\n",
        "            self.tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "        elif self.language == \"German\":\n",
        "            self.tokenizer = spacy.load(\"de_core_news_sm\")\n",
        "        else:\n",
        "            print(\"Invalid language\")\n",
        "\n",
        "    def tokenize_sent(self,sentence):\n",
        "        return [token.text.lower() for token in self.tokenizer.tokenizer(sentence)]\n",
        "    \n",
        "    def add_word(self,word):\n",
        "        if word not in self.stoi:\n",
        "            self.stoi[word]=self.num_words\n",
        "            self.stoc[word]=1\n",
        "            self.itos[self.num_words]=word\n",
        "            self.num_words+=1\n",
        "        else:\n",
        "            self.stoc[word]+=1\n",
        "\n",
        "    def build_vocab(self,sentence):\n",
        "        for word in self.tokenize_sent(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def process_sentence(self,sentence):\n",
        "        \n",
        "        return [self.stoi[token] for token in self.tokenize_sent(sentence)]\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "nkfCjT54Cbxr"
      },
      "outputs": [],
      "source": [
        "#building vocab for english and german\n",
        "eng_vocab = Vocabulary(\"English\")\n",
        "ger_vocab = Vocabulary(\"German\")\n",
        "\n",
        "for english_sentence,german_sentence in zip(train_df[\"English\"].values.tolist(),train_df[\"German\"].values.tolist()):\n",
        "    eng_vocab.build_vocab(english_sentence)\n",
        "    ger_vocab.build_vocab(german_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCcisyLBCbxs",
        "outputId": "cbfd5049-e1af-421f-dae2-585ddc159e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of English vocab - 14630\n",
            "Length of German vocab - 30955\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of English vocab - {}\".format(len(eng_vocab.stoi)))\n",
        "print(\"Length of German vocab - {}\".format(len(ger_vocab.stoi)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "g5LEbU_JCbxs"
      },
      "outputs": [],
      "source": [
        "# creating dataset\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self,dataframe,eng_vocab,ger_vocab):\n",
        "        super(TranslationDataset,self).__init__()\n",
        "        self.dataframe = dataframe\n",
        "        self.eng_vocab = eng_vocab\n",
        "        self.ger_vocab = ger_vocab\n",
        "        self.english = self.dataframe['English'].values.tolist()\n",
        "        self.german = self.dataframe['German'].values.tolist()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def process_sent(self,sent,vocab):\n",
        "        #starting each sentence with start_token and ending with end_token\n",
        "        processed_sent = [vocab.stoi[\"<START>\"]]\n",
        "        processed_sent.extend(vocab.process_sentence(sent))\n",
        "        processed_sent.append(vocab.stoi[\"<END>\"])\n",
        "        return processed_sent\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        processed_eng_sent = self.process_sent(self.english[index],self.eng_vocab)\n",
        "        processed_ger_sent = self.process_sent(self.german[index],self.ger_vocab)\n",
        "\n",
        "        \n",
        "        item = {'input': torch.tensor(processed_eng_sent), 'output':torch.tensor(processed_ger_sent)}\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "tPKGM0VGCbxt"
      },
      "outputs": [],
      "source": [
        "train_dataset = TranslationDataset(train_df,eng_vocab,ger_vocab)\n",
        "val_dataset = TranslationDataset(val_df,eng_vocab,ger_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_hgSwZqCbxt",
        "outputId": "9d342688-1cc3-4465-c78e-40b2124d7d66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': tensor([ 1, 58, 59, 44, 60, 61, 62, 63, 64, 65, 66, 67,  2]),\n",
              " 'output': tensor([ 1, 56, 57, 58, 59, 60, 61, 62, 63, 64,  2])}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "train_dataset.__getitem__(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "oeo0Pv1QCbxu"
      },
      "outputs": [],
      "source": [
        "#collate_function\n",
        "class Collater(object):\n",
        "    def __init__(self, pad_index):\n",
        "        self.pad_index = pad_index\n",
        "\n",
        "    def __call__(self, batch):\n",
        "\n",
        "        input = [item['input'] for item in batch]\n",
        "        output = [item['output'] for item in batch]\n",
        "        input = pad_sequence(input, batch_first=False, padding_value=self.pad_index)\n",
        "        output = pad_sequence(output, batch_first=False, padding_value=self.pad_index)\n",
        "        #can do via collater too, but we'll unpack during training\n",
        "        # inputs = input.detach().numpy().copy()\n",
        "        # outputs = output.detach().numpy().copy()\n",
        "        # input_mask, output_mask = [],[]\n",
        "        # #generating mask for input\n",
        "        # for input_seq in inputs:\n",
        "        #     input_mask_seq = []\n",
        "        #     for input_token in input_seq:\n",
        "        #         if input_token ==0:\n",
        "        #             input_mask_seq.append(False)\n",
        "        #         else:\n",
        "        #             input_mask_seq.append(True)\n",
        "        #     input_mask.append(input_mask_seq)\n",
        "        # #generating mask for output\n",
        "        # for output_seq in outputs:\n",
        "        #     output_mask_seq = []\n",
        "        #     for output_token in output_seq:\n",
        "        #         if output_token ==0:\n",
        "        #             output_mask_seq.append(False)\n",
        "        #         else:\n",
        "        #             output_mask_seq.append(True)\n",
        "        #     output_mask.append(output_mask_seq)\n",
        "        \n",
        "        # input_mask = torch.tensor(input_mask)\n",
        "        # output_mask = torch.tensor(output_mask)\n",
        "\n",
        "        #item = {'input':input,'input_mask':input_mask, 'output':output,'output_mask':output_mask}\n",
        "        item = {'input':input, 'output':output}\n",
        "        return item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHNm57T-Cbxv",
        "outputId": "d4beb541-ec9a-4b17-cbf8-ffd2a2b650c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "#creating dataloaders\n",
        "batch_size=1\n",
        "pad_idx = eng_vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size, num_workers=4, shuffle=False,pin_memory=True, collate_fn=Collater(pad_idx))\n",
        "val_loader = DataLoader(val_dataset,batch_size, num_workers=4, shuffle=False,pin_memory=True, collate_fn=Collater(pad_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFzQsnyoCbxv",
        "outputId": "a680b161-563d-4b82-f0a6-926d30fa1c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch details  tensor([[ 1],\n",
            "        [31],\n",
            "        [32],\n",
            "        [33],\n",
            "        [34],\n",
            "        [35],\n",
            "        [ 2]]) torch.Size([7, 1])\n",
            "_______________________________\n",
            "_______________________________\n",
            "Output batch details tensor([[ 1],\n",
            "        [31],\n",
            "        [32],\n",
            "        [33],\n",
            "        [ 2]]) torch.Size([5, 1])\n",
            "_______________________________\n"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate(train_loader):\n",
        "    \n",
        "    print(\"Input batch details \",batch['input'],batch['input'].shape)\n",
        "    print(\"_______________________________\")\n",
        "    #print(\"Input mask batch details \",batch['input_mask'],batch['input_mask'].shape)\n",
        "    print(\"_______________________________\")\n",
        "    print(\"Output batch details\", batch['output'],batch['output'].shape)\n",
        "    print(\"_______________________________\")\n",
        "    #print(\"Output mask batch details\", batch['output_mask'],batch['output_mask'].shape)\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "wPYZKUUgCbxw"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding +\n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "cqFxx1j9Cbxw"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(eng_vocab.stoi)\n",
        "OUTPUT_DIM = len(ger_vocab.stoi)\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# Source: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.tgt_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.transformer = nn.Transformer(nhead=8, num_encoder_layers=2, d_model=ENC_EMB_DIM)\n",
        "        self.linear = nn.Linear(ENC_EMB_DIM, OUTPUT_DIM)\n",
        "        pos_dropout = 0.1\n",
        "        max_seq_length = 128\n",
        "        self.pos_enc = PositionalEncoding(ENC_EMB_DIM, pos_dropout, max_seq_length)\n",
        "    \n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, tgt_mask=None):\n",
        "        # TODO: Investigate masks, positional encoding, understand Rearrange(), debug model output (output has negative numbers for some reason)\n",
        "        # Original src shape: (sentence length=24?, batch_size=128)\n",
        "        # Original tgt shape: (sentence length=24?, batch_size=128)\n",
        "        # Transformer expects: (sentence length=24, batch_size=128, embedding_size=128)\n",
        "        src_emb = self.pos_enc(self.src_embedding(src) * math.sqrt(ENC_EMB_DIM))\n",
        "        tgt_emb = self.pos_enc(self.tgt_embedding(tgt) * math.sqrt(ENC_EMB_DIM))\n",
        "        out = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "2v_KJv6OCbxw"
      },
      "outputs": [],
      "source": [
        "\n",
        "writer = SummaryWriter(f'runs/loss_plot')\n",
        "\n",
        "model = TransformerModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zInedVbbCbxx",
        "outputId": "f87f45d1-93fc-470c-9f2d-cdb27b9bc448"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (src_embedding): Embedding(14630, 32)\n",
              "  (tgt_embedding): Embedding(14630, 32)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (3): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (4): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (5): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
              "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=32, out_features=30955, bias=True)\n",
              "  (pos_enc): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "wADBVICoCbxx"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)#0 for <PAD>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "jlvQu7zwCbxx"
      },
      "outputs": [],
      "source": [
        "#using xavier normal init in the transformer\n",
        "for param in model.parameters():\n",
        "    if param.dim() >1:\n",
        "        nn.init.xavier_normal_(param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "DajWpFmhCbxx"
      },
      "outputs": [],
      "source": [
        "def gen_nopeek_mask(length):\n",
        "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "DO4ZUezGCbxy"
      },
      "outputs": [],
      "source": [
        "PAD_IDX =0\n",
        "def indices_to_string(LANGUAGE, batch):\n",
        "    if LANGUAGE == \"ENGLISH\":\n",
        "        vocab = eng_vocab\n",
        "    else:\n",
        "        vocab = ger_vocab\n",
        "    words_list = []\n",
        "    for sentence in batch.transpose(1, 0):\n",
        "        sentence_list = sentence.tolist()\n",
        "        words = []\n",
        "        for index in sentence_list:\n",
        "            word = vocab.itos[index]\n",
        "            words.append(word)\n",
        "        words_list.append(words)\n",
        "    return words_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "TtBC4RFGCbxy"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "\n",
        "\n",
        "step=0\n",
        "num_epochs=10\n",
        "def fit(num_epochs,train_loader,val_loader, model, optimizer,criterion):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\n",
        "        if epoch%10==0:\n",
        "            torch.save(checkpoint,\"checkpoint.pth.tar\")\n",
        "        #loading batch\n",
        "        for i,batch in enumerate(train_loader):\n",
        "            input_seq = batch['input'].to(device)\n",
        "            #input_mask = batch['input_mask'].to(device)\n",
        "            output_seq = batch['output'].to(device)\n",
        "            #output_mask = batch['output_mask'].to(device)\n",
        "            input_padding_mask = input_seq == PAD_IDX\n",
        "            output_padding_mask = output_seq == PAD_IDX\n",
        "            #input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_seq, output_seq)\n",
        "            memory_key_padding_mask = input_padding_mask.clone()\n",
        "            input_padding_mask = rearrange(input_padding_mask, 'n s -> s n')\n",
        "            output_padding_mask = rearrange(output_padding_mask, 'n s -> s n')\n",
        "            memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "            \n",
        "            tgt_sentence_len = output_seq.shape[0] - torch.sum(output_padding_mask,axis=1)\n",
        "            tgt_inp, tgt_out = output_seq[:,:], output_seq[:,:]\n",
        "            tgt_mask = gen_nopeek_mask(output_seq.shape[0])#.to('cuda') #('cuda)\n",
        "            tgt_mask = tgt_mask.to(device)\n",
        "            output = model(input_seq,tgt_inp,0,input_padding_mask, output_padding_mask,memory_key_padding_mask,tgt_mask)\n",
        "\n",
        "            #generating one hot\n",
        "            from_one_hot = torch.argmax(output,dim=2)\n",
        "\n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            tgt_out = tgt_out.view(-1)\n",
        "            loss = criterion(output,tgt_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        #validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(val_loader):\n",
        "                input_seq = batch['input'].to(device)\n",
        "                output_seq = batch['output'].to(device)\n",
        "                input_padding_mask = input_seq == PAD_IDX\n",
        "                output_padding_mask = output_seq == PAD_IDX\n",
        "                #input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_seq, output_seq)\n",
        "                memory_key_padding_mask = input_padding_mask.clone()\n",
        "                input_padding_mask = rearrange(input_padding_mask, 'n s -> s n')\n",
        "                output_padding_mask = rearrange(output_padding_mask, 'n s -> s n')\n",
        "                memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "                \n",
        "                tgt_sentence_len = output_seq.shape[0] - torch.sum(output_padding_mask,axis=1)\n",
        "                tgt_inp, tgt_out = output_seq[:,:], output_seq[:,:]\n",
        "                tgt_mask = gen_nopeek_mask(output_seq.shape[0])#.to('cuda') #('cuda)\n",
        "                tgt_mask = tgt_mask.to(device)\n",
        "                output = model(input_seq,tgt_inp,0,input_padding_mask, output_padding_mask,memory_key_padding_mask,tgt_mask)\n",
        "\n",
        "                #generating one hot\n",
        "                from_one_hot = torch.argmax(output,dim=2)\n",
        "\n",
        "                output = output.view(-1, output.shape[-1])\n",
        "                src_words = indices_to_string(\"ENGLISH\",input_seq)\n",
        "                predicted_words = indices_to_string(\"GERMAN\",from_one_hot)\n",
        "                tgt_words = indices_to_string(\"GERMAN\",output_seq)\n",
        "                print(\"Input English word - {}\".format(src_words))\n",
        "                print('Output German word - {}'.format(predicted_words))\n",
        "                print(\"Actual German Word - {}\".format(tgt_words))\n",
        "                output_seq = output_seq.view(-1)\n",
        "                val_loss = criterion(output,output_seq)\n",
        "\n",
        "        print(\"Epoch - {}, Train Loss - {}, Val Loss - {}\".format(epoch,loss.item(),val_loss.item()))\n",
        "        writer.add_scalar(\"Train loss\",loss, global_step=step)\n",
        "        step+=1    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfGoEd6_Cbxy"
      },
      "outputs": [],
      "source": [
        "fit(1,train_loader,val_loader,model,optimizer,criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G80No91dCbxz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def string_to_indices(LANGUAGE, sentence):\n",
        "    words = sentence.split()\n",
        "    indices = []\n",
        "    if LANGUAGE == \"ENGLISH\":\n",
        "        vocab = eng_vocab\n",
        "    else:\n",
        "        vocab = ger_vocab\n",
        "    for word in words:\n",
        "        if word in vocab.stoi:\n",
        "            index = vocab.stoi[word]\n",
        "            indices.append(index)\n",
        "        else:\n",
        "            index = 0 # should ideally be unknown but we are assuming it's pad\n",
        "            indices.append(index)\n",
        "    result = torch.tensor(indices)\n",
        "    return result\n",
        "\n",
        "def translate_english_to_german(model, example_sentence_src):\n",
        "    # Translate example sentence\n",
        "    example_tensor_src = string_to_indices(\"ENGLISH\", example_sentence_src).view(-1, 1)\n",
        "    example_sentence_tgt = '<START>'\n",
        "    example_tensor_tgt = string_to_indices(\"GERMAN\", example_sentence_tgt).view(-1, 1)\n",
        "    src = example_tensor_src.to(device)\n",
        "    tgt = example_tensor_tgt.to(device)\n",
        "\n",
        "    for i in range(128):\n",
        "        print('Source Translation', src)\n",
        "        print('Target Translation', tgt)\n",
        "        src_key_padding_mask = src == PAD_IDX\n",
        "        tgt_key_padding_mask = tgt == PAD_IDX\n",
        "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "        src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "        tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "        memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "        tgt_mask = gen_nopeek_mask(tgt.shape[0]).to('cpu')\n",
        "        print('Target Mask:', tgt_mask)\n",
        "\n",
        "        output = model(src, tgt, 0, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask) \n",
        "\n",
        "        print('Output:', output)\n",
        "        # TODO: Check that the argmax line is correct\n",
        "        output_index = torch.argmax(output, dim=2)[-1].item()\n",
        "        output_word = ger_vocab.itos[output_index]\n",
        "        example_sentence_tgt = example_sentence_tgt + ' ' + output_word\n",
        "        print('Translated sentence so far:', example_sentence_tgt)\n",
        "        example_tensor_tgt = string_to_indices(\"GERMAN\", example_sentence_tgt).view(-1, 1)\n",
        "        tgt = example_tensor_tgt.to(device)\n",
        "        if output_word == '<END>':\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"<START> This is me <END> <PAD> <PAD> <PAD> <PAD>\"\n",
        "print(translate_english_to_german(model,example))"
      ],
      "metadata": {
        "id": "OkVzQoFJIh9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_NwP7CaKUc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3fc43966dd8a35b9bb4dacfb26d54ec70461d2f8773a70bf315d67d5e8c2bf14"
      }
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}