{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX9-XMUPeI2Z"
      },
      "source": [
        "#### About\n",
        "\n",
        "> Dependency Parsing\n",
        "\n",
        "Dependency parsing is a natural language processing (NLP) technique that involves analyzing the grammatical structure of a sentence by identifying the relationships or dependencies between the words in the sentence. It represents the syntactic structure of a sentence as a directed acyclic graph (DAG), where the words are the nodes and the dependencies between the words are the edges.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFRgWINveI2h"
      },
      "source": [
        "Example - \n",
        "\n",
        "For example, consider the sentence: \"The cat chased the mouse.\" The dependency parse tree for this sentence would have \"cat\" and \"mouse\" as dependent nodes, and \"chased\" as the governing node. The edge between \"cat\" and \"chased\" would be labeled as \"subject,\" indicating that \"cat\" is the subject of the verb \"chased.\" Similarly, the edge between \"mouse\" and \"chased\" would be labeled as \"object,\" indicating that \"mouse\" is the object of the verb \"chased.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_sL8YmdeI2k"
      },
      "source": [
        "Dataset - UniversalDependencies(https://universaldependencies.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K02VYdEefR4b"
      },
      "source": [
        "Using spacy for Dependency parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUnuVvHfTuC"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "#load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#input sentence\n",
        "sentence = \"The cat chased the mouse.\"\n",
        "\n",
        "# preprocess the sentence with spacy\n",
        "doc = nlp(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up1BgqqBfnxH",
        "outputId": "43b9aea6-740f-4ea1-cdaa-25f0811e79f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word >> The  >> Lemma >> the >>  POS tag:>> DET   Dependency:>> det   Head:>> cat\n",
            "Word >> cat  >> Lemma >> cat >>  POS tag:>> NOUN   Dependency:>> nsubj   Head:>> chased\n",
            "Word >> chased  >> Lemma >> chase >>  POS tag:>> VERB   Dependency:>> ROOT   Head:>> chased\n",
            "Word >> the  >> Lemma >> the >>  POS tag:>> DET   Dependency:>> det   Head:>> mouse\n",
            "Word >> mouse  >> Lemma >> mouse >>  POS tag:>> NOUN   Dependency:>> dobj   Head:>> chased\n",
            "Word >> .  >> Lemma >> . >>  POS tag:>> PUNCT   Dependency:>> punct   Head:>> chased\n"
          ]
        }
      ],
      "source": [
        "#extract the dependency parse tree\n",
        "\n",
        "for token in doc:\n",
        "  print(\"Word >>\", token.text,\" >> Lemma >>\", token.lemma_,\">>  POS tag:>>\", token.pos_, \"  Dependency:>>\", token.dep_, \"  Head:>>\", token.head.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3u3H01lhSMK"
      },
      "source": [
        "####  Training a custom dependency parsing model using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h-yMMpev4Ix",
        "outputId": "d11f142d-e584-43c3-95c4-85ea968b7c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp39-cp39-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (1.26.15)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch==1.8.0 torchtext==0.9.0\n",
        "\n",
        "# Reload environment\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgXga8cS0TXn"
      },
      "source": [
        "Dataset - https://github.com/UniversalDependencies/UD_English-EWT.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRqtFEKc-pVY"
      },
      "source": [
        "UAS (Unlabeled Attachment Score) and LAS (Labeled Attachment Score) are two common metrics used to evaluate the performance of a dependency parser.\n",
        "\n",
        "UAS measures the percentage of correct predictions for the head of each word, regardless of the type of dependency label. It is calculated by dividing the number of correctly predicted head words by the total number of words in the dataset.\n",
        "\n",
        "LAS, on the other hand, measures the percentage of correct predictions for both the head and the dependency label of each word. It is calculated by dividing the number of correctly predicted heads and labels by the total number of words in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "1gtW7EVUdFw7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "from conllu import parse_incr\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "r9XoCuPndrub"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for token_list in parse_incr(file):\n",
        "            sentence = []\n",
        "            label = []\n",
        "            for token in token_list:\n",
        "                sentence.append(token[\"form\"])\n",
        "                label.append(token[\"deprel\"])\n",
        "            sentences.append(sentence)\n",
        "            labels.append(label)\n",
        "\n",
        "    return sentences, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "-p8EjmO_eGHx"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "file_path = \"/content/en_ewt-ud-train.conllu\"\n",
        "sentences, labels = load_data(file_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "uqXJq3lveIjU"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sentences and labels\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(sentences)\n",
        "word_index = word_tokenizer.word_index\n",
        "\n",
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "label_index = label_tokenizer.word_index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "t2GQTLYLeJ6b"
      },
      "outputs": [],
      "source": [
        "# Convert sentences and labels to integer sequences\n",
        "sequences = word_tokenizer.texts_to_sequences(sentences)\n",
        "label_sequences = label_tokenizer.texts_to_sequences(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "rxZjKjaqeKYE"
      },
      "outputs": [],
      "source": [
        "# Pad the sequences\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=\"post\")\n",
        "padded_labels = pad_sequences(label_sequences, maxlen=max_length, padding=\"post\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "K0bPYuHueP2N"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, padded_labels, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "yKjFwCC0eSjd"
      },
      "outputs": [],
      "source": [
        "# Create the Keras model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=max_length),\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Dense(len(label_index) + 1, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGcUPJleeT2N",
        "outputId": "1637b25e-c7a4-483a-b7d9-63f78fb551b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "314/314 [==============================] - 65s 193ms/step - loss: 0.3894 - accuracy: 0.9098 - val_loss: 0.2567 - val_accuracy: 0.9346\n",
            "Epoch 2/20\n",
            "314/314 [==============================] - 12s 38ms/step - loss: 0.1679 - accuracy: 0.9557 - val_loss: 0.1120 - val_accuracy: 0.9701\n",
            "Epoch 3/20\n",
            "314/314 [==============================] - 10s 33ms/step - loss: 0.0882 - accuracy: 0.9759 - val_loss: 0.0772 - val_accuracy: 0.9787\n",
            "Epoch 4/20\n",
            "314/314 [==============================] - 11s 34ms/step - loss: 0.0583 - accuracy: 0.9840 - val_loss: 0.0648 - val_accuracy: 0.9818\n",
            "Epoch 5/20\n",
            "314/314 [==============================] - 9s 28ms/step - loss: 0.0432 - accuracy: 0.9882 - val_loss: 0.0595 - val_accuracy: 0.9834\n",
            "Epoch 6/20\n",
            "314/314 [==============================] - 8s 27ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.0579 - val_accuracy: 0.9840\n",
            "Epoch 7/20\n",
            "314/314 [==============================] - 8s 24ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.0579 - val_accuracy: 0.9844\n",
            "Epoch 8/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0574 - val_accuracy: 0.9848\n",
            "Epoch 9/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0592 - val_accuracy: 0.9848\n",
            "Epoch 10/20\n",
            "314/314 [==============================] - 9s 28ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0617 - val_accuracy: 0.9848\n",
            "Epoch 11/20\n",
            "314/314 [==============================] - 9s 29ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0639 - val_accuracy: 0.9846\n",
            "Epoch 12/20\n",
            "314/314 [==============================] - 9s 28ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0661 - val_accuracy: 0.9849\n",
            "Epoch 13/20\n",
            "314/314 [==============================] - 8s 27ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0687 - val_accuracy: 0.9849\n",
            "Epoch 14/20\n",
            "314/314 [==============================] - 9s 28ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0724 - val_accuracy: 0.9844\n",
            "Epoch 15/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 16/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0767 - val_accuracy: 0.9847\n",
            "Epoch 17/20\n",
            "314/314 [==============================] - 8s 27ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0800 - val_accuracy: 0.9846\n",
            "Epoch 18/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0825 - val_accuracy: 0.9846\n",
            "Epoch 19/20\n",
            "314/314 [==============================] - 9s 28ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0856 - val_accuracy: 0.9846\n",
            "Epoch 20/20\n",
            "314/314 [==============================] - 8s 26ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0876 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a061751f0>"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "0xK6N1tLeVRN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Save the model\n",
        "model.save(\"dependency_parsing_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "5bUjjO8heYIv"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "loaded_model = load_model(\"dependency_parsing_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "6DcT5Jb_eZk9"
      },
      "outputs": [],
      "source": [
        "# Preprocess the sample text\n",
        "sample_text = \"This is a demo of custom dependency parsing model trained in keras on the universal dependency dataset.\"\n",
        "tokenized_sample = word_tokenizer.texts_to_sequences([sample_text])\n",
        "padded_sample = pad_sequences(tokenized_sample, maxlen=max_length, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZfFdiq8eipV",
        "outputId": "dc0520bb-62e6-42aa-9ad3-c83a0a6da679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 742ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict the dependency relations\n",
        "predictions = loaded_model.predict(padded_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "fsdqnD2OelVd"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions to labels\n",
        "predicted_labels = np.argmax(predictions, axis=-1)\n",
        "label_sequences = label_tokenizer.sequences_to_texts(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0-FOu6fem7V",
        "outputId": "c9551573-8409-4bc9-b4eb-74592c25da75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample text: This is a demo of custom dependency parsing model trained in keras on the universal dependency dataset.\n",
            "Predicted dependency relations: nsubj cop det case amod compound nmod acl case case det amod obl\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print(\"Sample text:\", sample_text)\n",
        "print(\"Predicted dependency relations:\", label_sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL0aD-IBfBdV"
      },
      "source": [
        "Calculating UAS and LAS scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUuvESIaeo_K",
        "outputId": "3e82d2fc-d878-4de2-dd5c-256c58d01a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 12ms/step - loss: 0.0876 - accuracy: 0.9847\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LzLFbmfGao",
        "outputId": "5ed23046-3d0d-42a3-b786-4b2890bf6a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9846726655960083\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AePz3nm4fHuC",
        "outputId": "09818a9c-1434-4514-daa7-4b9869a3e8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "6ZxJrDl3fJMW"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions to labels\n",
        "predicted_labels = np.argmax(predictions, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "0QCAf3z2fLym"
      },
      "outputs": [],
      "source": [
        "# Convert the integer labels back to text labels\n",
        "predicted_labels = label_tokenizer.sequences_to_texts(predicted_labels)\n",
        "y_val_labels = label_tokenizer.sequences_to_texts(y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-vqbQFwNfNaG",
        "outputId": "3eabdc62-2a2f-44cb-b2d5-d84f16c3452f"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-295-492b760f9b6c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_val_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlabeled_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ],
      "source": [
        "# Calculate the UAS and LAS scores\n",
        "total = 0\n",
        "correct = 0\n",
        "labeled_correct = 0\n",
        "\n",
        "for i in range(len(predicted_labels)):\n",
        "    for j in range(len(predicted_labels[i])):\n",
        "        total += 1\n",
        "        if predicted_labels[i][j] == y_val_labels[i][j]:\n",
        "            correct += 1\n",
        "            labeled_correct += 1\n",
        "        if predicted_labels[i][j] != \"punct\" and predicted_labels[i][j] == y_val_labels[i][j]:\n",
        "            labeled_correct += 1\n",
        "\n",
        "UAS = correct / total\n",
        "LAS = labeled_correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e81fm9IBfPe3"
      },
      "outputs": [],
      "source": [
        "print(\"UAS:\", UAS)\n",
        "print(\"LAS:\", LAS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgboj9H7fRAf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
