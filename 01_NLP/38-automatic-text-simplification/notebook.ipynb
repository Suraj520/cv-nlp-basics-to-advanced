{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "> Text Simplification\n",
    "\n",
    "As the name suggests, It is used to simplify complex texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your text pairs for simplification\n",
    "text_pairs = [(\"The weather is nice today.\", \"The weather is good.\"),\n",
    "              (\"I am going to the store.\", \"I will go to the shop.\"),\n",
    "              (\"She is a very talented singer.\", \"She is a great singer.\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary from the text pairs\n",
    "vocabulary = set()\n",
    "for pair in text_pairs:\n",
    "    vocabulary.update(pair[0].split())\n",
    "    vocabulary.update(pair[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word-to-index and index-to-word mappings\n",
    "word2index = {word: index + 1 for index, word in enumerate(vocabulary)}\n",
    "index2word = {index + 1: word for index, word in enumerate(vocabulary)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text pairs to numerical sequences\n",
    "input_sequences = []\n",
    "target_sequences = []\n",
    "for pair in text_pairs:\n",
    "    input_seq = [word2index[word] for word in pair[0].split()]\n",
    "    target_seq = [word2index[word] for word in pair[1].split()]\n",
    "    input_sequences.append(input_seq)\n",
    "    target_sequences.append(target_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure equal length\n",
    "max_sequence_length = max(max(len(seq) for seq in input_sequences),\n",
    "                          max(len(seq) for seq in target_sequences))\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "vocab_size = len(vocabulary) + 1\n",
    "embedding_size = 100\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:30:58.628156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 17:30:58.630030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 17:30:58.631694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_sequence_length))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))  # Return sequences from LSTM layer\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:31:11.786725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 17:31:11.789738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 17:31:11.796511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-15 17:31:13.087861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 17:31:13.094956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 17:31:13.097691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 63ms/step - loss: 3.0906 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.0776 - accuracy: 0.3889\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.0649 - accuracy: 0.3889\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0523 - accuracy: 0.4444\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.0393 - accuracy: 0.4444\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.0243 - accuracy: 0.4444\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.0083 - accuracy: 0.4444\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9872 - accuracy: 0.4444\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9641 - accuracy: 0.3889\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9348 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e7855ddf0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "\n",
    "model.fit(input_sequences, np.expand_dims(target_sequences, -1), epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simplified text\n",
    "input_text = \"The weather is nice today.\"\n",
    "input_seq = [word2index[word] for word in input_text.split()]\n",
    "input_seq = pad_sequences([input_seq], maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "output_probs = model.predict(input_seq)\n",
    "output_seq = np.argmax(output_probs, axis=-1)\n",
    "simplified_text = ' '.join([index2word[index] for index in output_seq[0] if index != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  The weather is nice today.\n",
      "Simplified:  \n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \", input_text)\n",
    "print(\"Simplified: \", simplified_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase more training samples and retrain for better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
