{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "DeepNLP with PyTorch\n",
    "\n",
    "1. Representing Linguistic units.\n",
    "\n",
    "The task is to map each item in a text(Characters and words) into a vector that can be processed in PyTorch or equivalent deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mandatory imports\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import random\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(26, 3)\n"
     ]
    }
   ],
   "source": [
    "num_chars = 26\n",
    "dimension_char_vector = 3\n",
    "#generating embeddings by mapping them to embedding vector\n",
    "\n",
    "char_embeddings = nn.Embedding(num_chars,dimension_char_vector)\n",
    "print(char_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2744, -1.4286, -0.9463],\n",
      "         [-0.7210,  1.1087, -1.3602],\n",
      "         [-0.0595,  0.0340,  1.3645]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#'cab'\n",
    "char_sequence =  [2,0,1]\n",
    "#converting to tensor\n",
    "char_idxs = T.LongTensor([char_sequence])\n",
    "char_vector = char_embeddings(char_idxs)\n",
    "print(char_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Processing these via Recurrent Neural Networks (RNNs)\n",
    "\n",
    "- These neural networks help in learning the context of a time series by temporarily remembering the past.\n",
    "\n",
    "- Gated Reccurent Units(GRUs) and Long Short Term memory(LSTMs) are used to achieve this.\n",
    "\n",
    "- GRUs have one less GATE and faster training time. So, we will use it. \n",
    "- For each index in char vector i.e char, Let's have a unit and process further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_gru = 5\n",
    "num_layers= 1\n",
    "gru = nn.GRU(dimension_char_vector, dimension_gru, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectors, last_hidden_ids = gru(char_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2390, -0.0721,  0.1782, -0.4897,  0.0909],\n",
       "         [ 0.3331,  0.0687,  0.1149, -0.0594,  0.4009],\n",
       "         [-0.3206,  0.2261,  0.2416, -0.3540,  0.0245]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2390, -0.0721,  0.1782, -0.4897,  0.0909],\n",
       "        [ 0.3331,  0.0687,  0.1149, -0.0594,  0.4009],\n",
       "        [-0.3206,  0.2261,  0.2416, -0.3540,  0.0245]],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing all dimensions just to preserve one element\n",
    "context_vectors.squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn the context on both sides, too. For that, We will need to use Bidirectional flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_gru = nn.GRU(dimension_char_vector, dimension_gru, num_layers,bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_context_vectors, last_hidden_ids = bidirectional_gru(char_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1700, -0.3908,  0.3062,  0.1363, -0.1156, -0.3271, -0.3678,\n",
       "          -0.1393, -0.0938, -0.2658],\n",
       "         [ 0.2168,  0.0903,  0.2295,  0.1065, -0.2877,  0.2146,  0.2384,\n",
       "           0.2826,  0.0298, -0.1723],\n",
       "         [-0.1992,  0.2225, -0.2047,  0.2786,  0.1238, -0.3141,  0.0886,\n",
       "           0.3634,  0.2949, -0.2617]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectional_context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1700, -0.3908,  0.3062,  0.1363, -0.1156, -0.3271, -0.3678, -0.1393,\n",
       "         -0.0938, -0.2658],\n",
       "        [ 0.2168,  0.0903,  0.2295,  0.1065, -0.2877,  0.2146,  0.2384,  0.2826,\n",
       "          0.0298, -0.1723],\n",
       "        [-0.1992,  0.2225, -0.2047,  0.2786,  0.1238, -0.3141,  0.0886,  0.3634,\n",
       "          0.2949, -0.2617]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectional_context_vectors.squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension of context vector shall now be doubled when using bidirectional.\n",
    "\n",
    "- The more RNN layers we add, The more abstract representation of texts can be learnt like syllable, morpheme etc.\n",
    "\n",
    "- Like adding one more layer to n=1, we can learn syllable from char\n",
    "- Adding one more layer to n=2, we can learn morpheme from syllable levels.\n",
    "\n",
    "However, Adding layers come with a trade off for training time.\n",
    "\n",
    "Let's add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_gru_2 = nn.GRU(dimension_char_vector, dimension_gru, num_layers=2,bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_context_vectors2, last_hidden_ids = bidirectional_gru_2(char_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2284,  0.1906, -0.1641, -0.1026,  0.0951,  0.1044,  0.1135,\n",
       "           0.1801,  0.0754,  0.1298],\n",
       "         [-0.0714,  0.3674, -0.1182,  0.0193,  0.0399, -0.0024,  0.0944,\n",
       "           0.1611, -0.1253,  0.0265],\n",
       "         [-0.1115,  0.2815,  0.1032,  0.0078,  0.0823,  0.1562, -0.1154,\n",
       "           0.2552,  0.0586,  0.1108]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectional_context_vectors2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sequence Prediction.\n",
    "\n",
    "Assuming for a given string, It is statistically generated by a hidden sequence of state transitions i.e Hidden Markov Models.\n",
    "\n",
    "- It's mostly employed for the tasks of POS tagging, NER, Word segmentation.\n",
    "\n",
    "- NER where B = begin, I = intermediate, O = Outer.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Segmentation using GRUs.\n",
    "\n",
    "Dataset - https://www.kaggle.com/datasets/thedevastator/morphemic-segmentation-of-english-words?select=lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('/home/suraj/ClickUp/Jan-Feb/data/lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>later</td>\n",
       "      <td>late ##er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>years</td>\n",
       "      <td>year ##s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>used</td>\n",
       "      <td>use ##ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>being</td>\n",
       "      <td>be ##ing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united</td>\n",
       "      <td>unite ##ed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y           x\n",
       "0   later   late ##er\n",
       "1   years    year ##s\n",
       "2    used    use ##ed\n",
       "3   being    be ##ing\n",
       "4  united  unite ##ed"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df['y'].values.tolist()\n",
    "segmented_words = df['x'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['later', 'years', 'used', 'being', 'united']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['late ##er', 'year ##s', 'use ##ed', 'be ##ing', 'unite ##ed']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26, '#': 27}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet_mapper = {alphabet[i]:i for i in range(len(alphabet))}\n",
    "#adding extra for hashtag and blank\n",
    "alphabet_mapper[' ']=26\n",
    "alphabet_mapper['#'] =27\n",
    "print(alphabet_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding to 26 length\n",
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequences = []\n",
    "for word in words:\n",
    "    char_sequence = []\n",
    "    for char in list(word):\n",
    "        char_sequence.append(alphabet_mapper[char])\n",
    "    word_sequences.append(pad(char_sequence,0,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24,\n",
       " 4,\n",
       " 0,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_word_sequences = []\n",
    "for word in segmented_words:\n",
    "    char_sequence = []\n",
    "    for char in list(word):\n",
    "        char_sequence.append(alphabet_mapper[str(char)])\n",
    "    seg_word_sequences.append(pad(char_sequence,0,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seg_word_sequences[9][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = zip(word_sequences,seg_word_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ([11, 0, 19, 4, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [11, 0, 19, 4, 26, 27, 27, 4, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for word,segmented_words in enumerate(train_data):\n",
    "    print(word,segmented_words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(words)\n",
    "dimension_char_vector=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordSeg(nn.Module):\n",
    "    def __init__(self, num_chars,char_vector_dimension,dimension_gru,num_layers):\n",
    "        super().__init__()\n",
    "        self.character_embedding = nn.Embedding(num_chars,dimension_char_vector)\n",
    "        self.gru = nn.GRU(dimension_char_vector,dimension_gru,num_layers,bidirectional=True)\n",
    "        #adding activation\n",
    "        self.activation1 = nn.Tanh()\n",
    "        #adding hidden layer with 2 states\n",
    "        self.hidden_layer = nn.Linear(2*dimension_gru,28)\n",
    "        #adding softmax for predicting prob\n",
    "        self.activation2 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,char_sequence):\n",
    "        char_indices = T.LongTensor([char_sequence])\n",
    "        char_vector = self.character_embedding(char_indices)\n",
    "        context_vectors, last_hidden_ids = self.gru(char_vector)\n",
    "        context_vectors = context_vectors.squeeze()\n",
    "        state_vectors = self.hidden_layer(self.activation1(context_vectors))\n",
    "        return self.activation2(state_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_gru = 28\n",
    "model = WordSeg(28,dimension_char_vector,dimension_gru,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = T.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss() #negative log loss\n",
    "learning_rate =0.01\n",
    "optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30261/4065262011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcharseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmented_char\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30261/967367542.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, char_sequence)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mchar_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mchar_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacter_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mcontext_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mstate_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_dl/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    956\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(num_epochs)):\n",
    "    total_loss=0.0\n",
    "    for charseq, segmented_char in train_data:\n",
    "        targets = T.zeros(28,28).type(T.float32)\n",
    "        \n",
    "        \n",
    "        preds = model(charseq)\n",
    "        \n",
    "\n",
    "        \n",
    "        loss = loss_fn(preds,targets)\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch - {}, Loss - {}\".format(i,total_loss/num_samples))\n",
    "    losses.append(total_loss/num_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer the following table for a brief about various layer types implemented in PyTorch\n",
    "\n",
    "![Layers](Layers.png \"Layers\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc43966dd8a35b9bb4dacfb26d54ec70461d2f8773a70bf315d67d5e8c2bf14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
