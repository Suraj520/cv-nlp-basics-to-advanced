{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## **Architecture Overview**\n\n#### **T5**\n\n- At a high level, T5 is built using a transformer based architecture. It is different from other architectures like BERT, RoBERTa, GPT-2 and XLNET in several ways.\n\n- The building blocks of T5 are similar to those of other transformer based models. It consists of an encoder and a decoder. The encoder takes in the input seq and generates a hidden representation of the input. The decoder takes in the hidden representation and generates the output sequence.\n\n- The encoder and decoder are connected by an attention mechanism that allows the decoder to attend to different parts of the input sequence.\n\n- One of the key differences between T5 and other architectures like BERT,RoBERTa, GPT2 and XLNet is that T5 is a text to text model. This means that It can be trained on a wide range of nlp taks by simply changing the input and output format. \n\n- For example, It can be trained on machine translation by providing it with a source language sentence and a target language sentence as input-output pair. It can also be trained on summarization by providing it with a long document as input and short summary as output.\n\n- T5 uses a pretraining and fine tuning approach. During pre-training, T5 is trained on a large corpus of text using a masked language modelling objective whereas during the fine tuning stage, The pre-trained model is fine tuned on a specific task by providing it with task-specific input and output pairs.\n\n- T5 also uses a technique called task-specific prompts, which allows it to perform well on a wide range of tasks with minimal task specific training. The prompts are short text strings that are concatenated to the input sequence to provide task specific information to the model.\n\n</div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom transformers import T5Tokenizer, TFT5Model\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:00:54.538740Z","iopub.execute_input":"2023-05-25T00:00:54.539304Z","iopub.status.idle":"2023-05-25T00:01:11.367137Z","shell.execute_reply.started":"2023-05-25T00:00:54.539267Z","shell.execute_reply":"2023-05-25T00:01:11.366204Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the number of GPUs to use\nnum_gpus = 2\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:11.369353Z","iopub.execute_input":"2023-05-25T00:01:11.370184Z","iopub.status.idle":"2023-05-25T00:01:11.374503Z","shell.execute_reply.started":"2023-05-25T00:01:11.370149Z","shell.execute_reply":"2023-05-25T00:01:11.373298Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Load and Prepare Data: \nThe following code snippets loads the training and test data from CSV files using pandas and splits the training data into input (question + answer) and target variables.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest_data = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:11.376089Z","iopub.execute_input":"2023-05-25T00:01:11.376789Z","iopub.status.idle":"2023-05-25T00:01:11.790089Z","shell.execute_reply.started":"2023-05-25T00:01:11.376739Z","shell.execute_reply":"2023-05-25T00:01:11.789044Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Split the training data into input (question + answer) and target variables\nX = train_data['question_title'] + ' ' + train_data['question_body'] + ' ' + train_data['answer']\ny = train_data.iloc[:, 11:]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:11.792729Z","iopub.execute_input":"2023-05-25T00:01:11.793095Z","iopub.status.idle":"2023-05-25T00:01:11.822258Z","shell.execute_reply.started":"2023-05-25T00:01:11.793063Z","shell.execute_reply":"2023-05-25T00:01:11.821289Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Tokenize Input Data: \n\nThe input data is tokenized using the T5 tokenizer from the Transformers library. The tokenizer converts the text into a numerical representation suitable for input to the T5 model.</div>","metadata":{}},{"cell_type":"code","source":"# Tokenize the input data\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\nX_encoded = tokenizer.batch_encode_plus(\n    X.tolist(),\n    padding='longest',\n    truncation=True,\n    return_tensors='tf'\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:11.823712Z","iopub.execute_input":"2023-05-25T00:01:11.824447Z","iopub.status.idle":"2023-05-25T00:01:39.173475Z","shell.execute_reply.started":"2023-05-25T00:01:11.824406Z","shell.execute_reply":"2023-05-25T00:01:39.172457Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d881059028294ad0a1c1492caf25c785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f48c38c82d454295949f989c3ee5f9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Split Data into Training and Validation Sets: \nThe tokenized input data and target variables are split into training and validation sets using the train_test_split function from scikit-learn.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# Convert the tensor array to a numpy array of integers\nX_encoded_ids = np.array(X_encoded['input_ids'])\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_encoded_ids, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:39.175516Z","iopub.execute_input":"2023-05-25T00:01:39.176001Z","iopub.status.idle":"2023-05-25T00:01:39.196589Z","shell.execute_reply.started":"2023-05-25T00:01:39.175964Z","shell.execute_reply":"2023-05-25T00:01:39.195532Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Define T5 Model Architecture: \nThis snippet defines the architecture of the T5 model using the TFT5Model class from the Transformers library. The model takes the tokenized input IDs as input and produces a sequence of hidden states. The final hidden state corresponding to the first token is extracted and passed through a dense layer with sigmoid activation to obtain the model's output.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# Define the T5 model architecture\ninput_ids = Input(shape=(X_encoded['input_ids'].shape[1],), dtype='int32')\ndecoder_input_ids = Input(shape=(X_encoded['input_ids'].shape[1],), dtype='int32')\nt5_model = TFT5Model.from_pretrained('t5-base')\noutput = t5_model(input_ids=input_ids, decoder_input_ids=decoder_input_ids).last_hidden_state[:, 0, :]\noutput = Dense(y_train.shape[1], activation='sigmoid')(output)\nmodel = Model(inputs=[input_ids, decoder_input_ids], outputs=output)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:01:39.197940Z","iopub.execute_input":"2023-05-25T00:01:39.198422Z","iopub.status.idle":"2023-05-25T00:02:00.658933Z","shell.execute_reply.started":"2023-05-25T00:01:39.198386Z","shell.execute_reply":"2023-05-25T00:02:00.657899Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ffbbc8255346d78bea596be88a0622"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5Model.\n\nAll the weights of TFT5Model were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Compile and Train the Model: \nThe model is compiled with the Adam optimizer and binary cross-entropy loss. It is then trained on the training data using the fit method, with the validation data used for monitoring the model's performance during training.\n\n</div>","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:02:00.660566Z","iopub.execute_input":"2023-05-25T00:02:00.660963Z","iopub.status.idle":"2023-05-25T00:02:00.692614Z","shell.execute_reply.started":"2023-05-25T00:02:00.660919Z","shell.execute_reply":"2023-05-25T00:02:00.691667Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Define Distribution Strategy for Multi-GPU Training: \nA distribution strategy is defined to enable multi-GPU training. The MirroredStrategy from TensorFlow is used, which replicates the model across multiple GPUs and synchronizes their updates.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# Define the distribution strategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:02:00.693867Z","iopub.execute_input":"2023-05-25T00:02:00.694270Z","iopub.status.idle":"2023-05-25T00:02:01.014656Z","shell.execute_reply.started":"2023-05-25T00:02:00.694237Z","shell.execute_reply":"2023-05-25T00:02:01.013730Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Create and Compile Distributed Model: \nThe model is wrapped with the distribution strategy using the strategy.scope() context manager, which creates the distributed model and compiles it. This allows the model to be trained on multiple GPUs.\n\n\n   ","metadata":{}},{"cell_type":"code","source":"# Create and compile the distributed model\nwith strategy.scope():\n    distributed_model = model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:02:01.017754Z","iopub.execute_input":"2023-05-25T00:02:01.018208Z","iopub.status.idle":"2023-05-25T00:02:01.023169Z","shell.execute_reply.started":"2023-05-25T00:02:01.018174Z","shell.execute_reply":"2023-05-25T00:02:01.021997Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Compile and train the model\ndistributed_model.compile(optimizer='adam', loss='binary_crossentropy')\ndistributed_model.fit(\n    [X_train, X_train],\n    y_train,\n    validation_data=([X_val, X_val], y_val),\n    batch_size=1 * strategy.num_replicas_in_sync,\n    epochs=10\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Make Predictions on Test Data: \nThe test data is tokenized using the same tokenizer used for the training data. The tokenized input IDs are then passed to the trained distributed model to make predictions on the test data.","metadata":{}},{"cell_type":"code","source":"# Tokenize the test data\nX_test = test_data['question_title'] + ' ' + test_data['question_body'] + ' ' + test_data['answer']\nX_test_encoded = tokenizer.batch_encode_plus(\n    X_test.tolist(),\n    padding='longest',\n    truncation=True,\n    return_tensors='tf'\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:31:24.361512Z","iopub.execute_input":"2023-05-25T00:31:24.361898Z","iopub.status.idle":"2023-05-25T00:31:25.811727Z","shell.execute_reply.started":"2023-05-25T00:31:24.361866Z","shell.execute_reply":"2023-05-25T00:31:25.810590Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Convert the tensor array to a numpy array of integers\nX_test_encoded_ids = np.array(X_test_encoded['input_ids'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:31:31.310394Z","iopub.execute_input":"2023-05-25T00:31:31.310820Z","iopub.status.idle":"2023-05-25T00:31:31.316345Z","shell.execute_reply.started":"2023-05-25T00:31:31.310778Z","shell.execute_reply":"2023-05-25T00:31:31.315155Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\npredictions = distributed_model.predict([X_test_encoded_ids, X_test_encoded_ids])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:31:32.412331Z","iopub.execute_input":"2023-05-25T00:31:32.412802Z","iopub.status.idle":"2023-05-25T00:33:01.268376Z","shell.execute_reply.started":"2023-05-25T00:31:32.412743Z","shell.execute_reply":"2023-05-25T00:33:01.267224Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 49s 3s/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Create Submission DataFrame: \nThe predicted values are used to create a DataFrame for the submission file. The predictions are organized in columns corresponding to the target variables, and the qa_id column from the test data is included for identification.","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame for the submission file\nsubmission_df = pd.DataFrame(predictions, columns=y_train.columns)\nsubmission_df.insert(0, 'qa_id', test_data['qa_id'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:33:01.271349Z","iopub.execute_input":"2023-05-25T00:33:01.271798Z","iopub.status.idle":"2023-05-25T00:33:01.280886Z","shell.execute_reply.started":"2023-05-25T00:33:01.271741Z","shell.execute_reply":"2023-05-25T00:33:01.279822Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family: 'Arial', sans-serif; font-size: 18px; color: #5f5c9c;\">\n\n## Save Submission DataFrame to CSV: \nThe submission DataFrame is saved as a CSV file named \"submission.csv\" without including the index column.","metadata":{}},{"cell_type":"code","source":"# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:33:01.282516Z","iopub.execute_input":"2023-05-25T00:33:01.283050Z","iopub.status.idle":"2023-05-25T00:33:01.314574Z","shell.execute_reply.started":"2023-05-25T00:33:01.283012Z","shell.execute_reply":"2023-05-25T00:33:01.313596Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-05-25T00:33:07.071867Z","iopub.execute_input":"2023-05-25T00:33:07.072222Z","iopub.status.idle":"2023-05-25T00:33:07.111988Z","shell.execute_reply.started":"2023-05-25T00:33:07.072194Z","shell.execute_reply":"2023-05-25T00:33:07.110807Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"     qa_id  question_asker_intent_understanding  question_body_critical  \\\n0       39                             0.919736                0.720155   \n1       46                             0.852762                0.457538   \n2       70                             0.895918                0.696801   \n3      132                             0.860401                0.457747   \n4      200                             0.901813                0.569932   \n..     ...                                  ...                     ...   \n471   9569                             0.881836                0.534002   \n472   9590                             0.874853                0.519922   \n473   9597                             0.858172                0.453844   \n474   9623                             0.910676                0.725312   \n475   9640                             0.880555                0.550518   \n\n     question_conversational  question_expect_short_answer  \\\n0                   0.172387                      0.737997   \n1                   0.015420                      0.803854   \n2                   0.074210                      0.788232   \n3                   0.011842                      0.809626   \n4                   0.108243                      0.702484   \n..                       ...                           ...   \n471                 0.013219                      0.815507   \n472                 0.034245                      0.739269   \n473                 0.016616                      0.804158   \n474                 0.133036                      0.763369   \n475                 0.009709                      0.838175   \n\n     question_fact_seeking  question_has_commonly_accepted_answer  \\\n0                 0.693735                               0.758682   \n1                 0.731723                               0.884745   \n2                 0.724790                               0.814511   \n3                 0.736134                               0.894841   \n4                 0.703878                               0.750246   \n..                     ...                                    ...   \n471               0.743243                               0.886533   \n472               0.728903                               0.830708   \n473               0.735860                               0.880214   \n474               0.702743                               0.770729   \n475               0.747849                               0.902922   \n\n     question_interestingness_others  question_interestingness_self  \\\n0                           0.650969                       0.614660   \n1                           0.533372                       0.440967   \n2                           0.608176                       0.524826   \n3                           0.537488                       0.438102   \n4                           0.603424                       0.578567   \n..                               ...                            ...   \n471                         0.563547                       0.452329   \n472                         0.546320                       0.478859   \n473                         0.542408                       0.448858   \n474                         0.639397                       0.590993   \n475                         0.558206                       0.445559   \n\n     question_multi_intent  ...  question_well_written  answer_helpful  \\\n0                 0.217058  ...               0.864714        0.911911   \n1                 0.106015  ...               0.709771        0.950297   \n2                 0.178956  ...               0.849852        0.922942   \n3                 0.096054  ...               0.711140        0.956427   \n4                 0.218860  ...               0.770060        0.900358   \n..                     ...  ...                    ...             ...   \n471               0.103742  ...               0.757519        0.954384   \n472               0.163506  ...               0.758962        0.931827   \n473               0.112948  ...               0.698306        0.947991   \n474               0.204018  ...               0.862555        0.905421   \n475               0.083212  ...               0.765910        0.954054   \n\n     answer_level_of_information  answer_plausible  answer_relevance  \\\n0                       0.691923          0.948988          0.941793   \n1                       0.675851          0.970681          0.973296   \n2                       0.677749          0.952771          0.952158   \n3                       0.684720          0.974240          0.977973   \n4                       0.651802          0.945203          0.937745   \n..                           ...               ...               ...   \n471                     0.679831          0.973254          0.977064   \n472                     0.668114          0.958713          0.960989   \n473                     0.668020          0.970566          0.972866   \n474                     0.672075          0.944085          0.939848   \n475                     0.672823          0.973489          0.977741   \n\n     answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n0               0.860930                  0.102672               0.096489   \n1               0.884662                  0.776433               0.178853   \n2               0.863300                  0.329377               0.135897   \n3               0.892506                  0.820227               0.187396   \n4               0.833813                  0.194209               0.115866   \n..                   ...                       ...                    ...   \n471             0.891134                  0.803854               0.202071   \n472             0.861795                  0.573305               0.164343   \n473             0.881061                  0.746435               0.176517   \n474             0.849545                  0.168045               0.115110   \n475             0.891991                  0.851707               0.204345   \n\n     answer_type_reason_explanation  answer_well_written  \n0                          0.693883             0.903641  \n1                          0.372724             0.891988  \n2                          0.531592             0.893110  \n3                          0.346095             0.897584  \n4                          0.622912             0.896693  \n..                              ...                  ...  \n471                        0.312506             0.897262  \n472                        0.476341             0.891656  \n473                        0.367195             0.895275  \n474                        0.599056             0.895735  \n475                        0.257987             0.889542  \n\n[476 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qa_id</th>\n      <th>question_asker_intent_understanding</th>\n      <th>question_body_critical</th>\n      <th>question_conversational</th>\n      <th>question_expect_short_answer</th>\n      <th>question_fact_seeking</th>\n      <th>question_has_commonly_accepted_answer</th>\n      <th>question_interestingness_others</th>\n      <th>question_interestingness_self</th>\n      <th>question_multi_intent</th>\n      <th>...</th>\n      <th>question_well_written</th>\n      <th>answer_helpful</th>\n      <th>answer_level_of_information</th>\n      <th>answer_plausible</th>\n      <th>answer_relevance</th>\n      <th>answer_satisfaction</th>\n      <th>answer_type_instructions</th>\n      <th>answer_type_procedure</th>\n      <th>answer_type_reason_explanation</th>\n      <th>answer_well_written</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>0.919736</td>\n      <td>0.720155</td>\n      <td>0.172387</td>\n      <td>0.737997</td>\n      <td>0.693735</td>\n      <td>0.758682</td>\n      <td>0.650969</td>\n      <td>0.614660</td>\n      <td>0.217058</td>\n      <td>...</td>\n      <td>0.864714</td>\n      <td>0.911911</td>\n      <td>0.691923</td>\n      <td>0.948988</td>\n      <td>0.941793</td>\n      <td>0.860930</td>\n      <td>0.102672</td>\n      <td>0.096489</td>\n      <td>0.693883</td>\n      <td>0.903641</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>0.852762</td>\n      <td>0.457538</td>\n      <td>0.015420</td>\n      <td>0.803854</td>\n      <td>0.731723</td>\n      <td>0.884745</td>\n      <td>0.533372</td>\n      <td>0.440967</td>\n      <td>0.106015</td>\n      <td>...</td>\n      <td>0.709771</td>\n      <td>0.950297</td>\n      <td>0.675851</td>\n      <td>0.970681</td>\n      <td>0.973296</td>\n      <td>0.884662</td>\n      <td>0.776433</td>\n      <td>0.178853</td>\n      <td>0.372724</td>\n      <td>0.891988</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70</td>\n      <td>0.895918</td>\n      <td>0.696801</td>\n      <td>0.074210</td>\n      <td>0.788232</td>\n      <td>0.724790</td>\n      <td>0.814511</td>\n      <td>0.608176</td>\n      <td>0.524826</td>\n      <td>0.178956</td>\n      <td>...</td>\n      <td>0.849852</td>\n      <td>0.922942</td>\n      <td>0.677749</td>\n      <td>0.952771</td>\n      <td>0.952158</td>\n      <td>0.863300</td>\n      <td>0.329377</td>\n      <td>0.135897</td>\n      <td>0.531592</td>\n      <td>0.893110</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>132</td>\n      <td>0.860401</td>\n      <td>0.457747</td>\n      <td>0.011842</td>\n      <td>0.809626</td>\n      <td>0.736134</td>\n      <td>0.894841</td>\n      <td>0.537488</td>\n      <td>0.438102</td>\n      <td>0.096054</td>\n      <td>...</td>\n      <td>0.711140</td>\n      <td>0.956427</td>\n      <td>0.684720</td>\n      <td>0.974240</td>\n      <td>0.977973</td>\n      <td>0.892506</td>\n      <td>0.820227</td>\n      <td>0.187396</td>\n      <td>0.346095</td>\n      <td>0.897584</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>0.901813</td>\n      <td>0.569932</td>\n      <td>0.108243</td>\n      <td>0.702484</td>\n      <td>0.703878</td>\n      <td>0.750246</td>\n      <td>0.603424</td>\n      <td>0.578567</td>\n      <td>0.218860</td>\n      <td>...</td>\n      <td>0.770060</td>\n      <td>0.900358</td>\n      <td>0.651802</td>\n      <td>0.945203</td>\n      <td>0.937745</td>\n      <td>0.833813</td>\n      <td>0.194209</td>\n      <td>0.115866</td>\n      <td>0.622912</td>\n      <td>0.896693</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>471</th>\n      <td>9569</td>\n      <td>0.881836</td>\n      <td>0.534002</td>\n      <td>0.013219</td>\n      <td>0.815507</td>\n      <td>0.743243</td>\n      <td>0.886533</td>\n      <td>0.563547</td>\n      <td>0.452329</td>\n      <td>0.103742</td>\n      <td>...</td>\n      <td>0.757519</td>\n      <td>0.954384</td>\n      <td>0.679831</td>\n      <td>0.973254</td>\n      <td>0.977064</td>\n      <td>0.891134</td>\n      <td>0.803854</td>\n      <td>0.202071</td>\n      <td>0.312506</td>\n      <td>0.897262</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>9590</td>\n      <td>0.874853</td>\n      <td>0.519922</td>\n      <td>0.034245</td>\n      <td>0.739269</td>\n      <td>0.728903</td>\n      <td>0.830708</td>\n      <td>0.546320</td>\n      <td>0.478859</td>\n      <td>0.163506</td>\n      <td>...</td>\n      <td>0.758962</td>\n      <td>0.931827</td>\n      <td>0.668114</td>\n      <td>0.958713</td>\n      <td>0.960989</td>\n      <td>0.861795</td>\n      <td>0.573305</td>\n      <td>0.164343</td>\n      <td>0.476341</td>\n      <td>0.891656</td>\n    </tr>\n    <tr>\n      <th>473</th>\n      <td>9597</td>\n      <td>0.858172</td>\n      <td>0.453844</td>\n      <td>0.016616</td>\n      <td>0.804158</td>\n      <td>0.735860</td>\n      <td>0.880214</td>\n      <td>0.542408</td>\n      <td>0.448858</td>\n      <td>0.112948</td>\n      <td>...</td>\n      <td>0.698306</td>\n      <td>0.947991</td>\n      <td>0.668020</td>\n      <td>0.970566</td>\n      <td>0.972866</td>\n      <td>0.881061</td>\n      <td>0.746435</td>\n      <td>0.176517</td>\n      <td>0.367195</td>\n      <td>0.895275</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>9623</td>\n      <td>0.910676</td>\n      <td>0.725312</td>\n      <td>0.133036</td>\n      <td>0.763369</td>\n      <td>0.702743</td>\n      <td>0.770729</td>\n      <td>0.639397</td>\n      <td>0.590993</td>\n      <td>0.204018</td>\n      <td>...</td>\n      <td>0.862555</td>\n      <td>0.905421</td>\n      <td>0.672075</td>\n      <td>0.944085</td>\n      <td>0.939848</td>\n      <td>0.849545</td>\n      <td>0.168045</td>\n      <td>0.115110</td>\n      <td>0.599056</td>\n      <td>0.895735</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>9640</td>\n      <td>0.880555</td>\n      <td>0.550518</td>\n      <td>0.009709</td>\n      <td>0.838175</td>\n      <td>0.747849</td>\n      <td>0.902922</td>\n      <td>0.558206</td>\n      <td>0.445559</td>\n      <td>0.083212</td>\n      <td>...</td>\n      <td>0.765910</td>\n      <td>0.954054</td>\n      <td>0.672823</td>\n      <td>0.973489</td>\n      <td>0.977741</td>\n      <td>0.891991</td>\n      <td>0.851707</td>\n      <td>0.204345</td>\n      <td>0.257987</td>\n      <td>0.889542</td>\n    </tr>\n  </tbody>\n</table>\n<p>476 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}