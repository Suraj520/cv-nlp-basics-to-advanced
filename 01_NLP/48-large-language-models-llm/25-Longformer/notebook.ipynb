{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#5D73F2; color:#19180F; font-size:40px; font-family:Verdana; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Longformer </div>\n<div style=\"background-color:#A8B4F6; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Architecture Overview</div>\n<div style=\"background-color:#D5D9F2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F; border-radius:10px\">\n\n- Input Embeddings: The first stage of the Longformer architecture is represented by the Input Embeddings section. The input tokens are represented by the Input Tokens node, and their transformation into numerical embeddings is shown by the Embeddings node. These embeddings record the input tokens' semantic and contextual details.<br><br>\n- Encoder Layers: The Encoder Layer 1 and Encoder Layer 2 nodes show that the Encoder Layers section contains multiple encoder layers. As required, further encoder layers can be implemented. The input embeddings are processed successively by these encoder layers, which also record the input sequence's hierarchical representations.<br><br>\n- Self-Attention Mechanism: The relationships between various tokens in the input sequence are recorded in the Self-Attention section. The self-attention mechanism, which attends to all tokens and detects global dependencies, is represented by the Self-Attention node. The global attention mechanism and the local attention mechanism, respectively, are represented by the Global Attention and Local Attention nodes in the Self-Attention section. The model can effectively handle long-range dependencies because the global attention allows each token to attend to all other tokens while the local attention concentrates on a portion of nearby tokens.<br><br>\n- Feed-Forward Neural Network: The output of the self-attention mechanism is processed in the Feed-Forward Neural Network portion, which is represented by the Feed-Forward NN node. The token representations are subjected to non-linear transformations, enabling the recording of more intricate relationships.<br><br>\n- Residual Connections and Layer Normalization: The model's training stability and information flow are improved by the Residual Connections and Layer Normalisation part. The connections that transfer the output of one encoder layer directly to succeeding levels are identified by the Residual Connections node. As a result, lower-level token representations are preserved throughout training. The representations following each sub-layer are normalised by the Layer Normalisation node, which aids in the entire training process.<br><br>\n- Output Layers: The Output Layers section denotes the Longformer architecture's last phase. The model's output, denoted by the Output node, can be applied to a variety of downstream tasks, including categorization, question answering, and summarization.<br><br>\nThe information and computation flow is represented by the links between the nodes. As an illustration, the input tokens pass via the input embeddings before being successively processed by the encoder layers. The feed-forward neural network receives the output from the encoder layers after passing it through the self-attention mechanism. The output of the feed-forward neural network then passes through layer normalisation, residual connections, and the output layer.<br><br>\nDifferent elements of the Longformer architecture are designed to be visually distinguished using the colours used in the diagram. Each element has its own colour scheme, making it simpler to recognise and understand the diagram's components.<br><br></div>\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import SVG, display\n\n# Load the SVG file and display it\nsvg_file = '/kaggle/input/notebook-images/longformer.svg'\ndisplay(SVG(filename=svg_file))","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:03.548511Z","iopub.execute_input":"2023-06-22T14:33:03.548902Z","iopub.status.idle":"2023-06-22T14:33:03.575311Z","shell.execute_reply.started":"2023-06-22T14:33:03.548868Z","shell.execute_reply":"2023-06-22T14:33:03.574029Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1088pt\" height=\"211pt\" viewBox=\"0.00 0.00 1088.25 210.85\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206.8525)\">\n<title>Longformer</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-206.8525 1084.2514,-206.8525 1084.2514,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_input</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"327.9524,-117.8525 327.9524,-194.8525 623.8273,-194.8525 623.8273,-117.8525 327.9524,-117.8525\"/>\n<text text-anchor=\"middle\" x=\"475.8898\" y=\"-178.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Embeddings</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_encoders</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"681.9332,-117.8525 681.9332,-194.8525 964.3636,-194.8525 964.3636,-117.8525 681.9332,-117.8525\"/>\n<text text-anchor=\"middle\" x=\"823.1484\" y=\"-178.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layers</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_attention</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"8,-32.8525 8,-163.8525 266.5786,-163.8525 266.5786,-32.8525 8,-32.8525\"/>\n<text text-anchor=\"middle\" x=\"137.2893\" y=\"-147.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_ffnn</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"286.5786,-32.8525 286.5786,-109.8525 475.5892,-109.8525 475.5892,-32.8525 286.5786,-32.8525\"/>\n<text text-anchor=\"middle\" x=\"381.0839\" y=\"-93.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward Neural Network</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_residual</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"495.5892,-32.8525 495.5892,-109.8525 819.0788,-109.8525 819.0788,-32.8525 495.5892,-32.8525\"/>\n<text text-anchor=\"middle\" x=\"657.334\" y=\"-93.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Residual Connections and Layer Normalization</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_output</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"984.3636,-117.8525 984.3636,-194.8525 1080.2514,-194.8525 1080.2514,-117.8525 984.3636,-117.8525\"/>\n<text text-anchor=\"middle\" x=\"1032.3075\" y=\"-178.2525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output Layers</text>\n</g>\n<!-- inputs -->\n<g id=\"node1\" class=\"node\">\n<title>inputs</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#add8e6\" points=\"426.3473,-161.8525 335.8205,-161.8525 335.8205,-125.8525 426.3473,-125.8525 426.3473,-161.8525\"/>\n<text text-anchor=\"middle\" x=\"381.0839\" y=\"-139.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Tokens</text>\n</g>\n<!-- embeddings -->\n<g id=\"node2\" class=\"node\">\n<title>embeddings</title>\n<polygon fill=\"#add8e6\" stroke=\"#add8e6\" points=\"615.8238,-161.8525 529.8378,-161.8525 529.8378,-125.8525 615.8238,-125.8525 615.8238,-161.8525\"/>\n<text text-anchor=\"middle\" x=\"572.8308\" y=\"-139.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embeddings</text>\n</g>\n<!-- inputs&#45;&gt;embeddings -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs-&gt;embeddings</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M426.5252,-143.8525C454.4619,-143.8525 490.3851,-143.8525 519.6436,-143.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"519.6908,-147.3526 529.6908,-143.8525 519.6907,-140.3526 519.6908,-147.3526\"/>\n</g>\n<!-- enc1 -->\n<g id=\"node3\" class=\"node\">\n<title>enc1</title>\n<polygon fill=\"#ffffe0\" stroke=\"#add8e6\" points=\"799.3608,-161.8525 689.7904,-161.8525 689.7904,-125.8525 799.3608,-125.8525 799.3608,-161.8525\"/>\n<text text-anchor=\"middle\" x=\"744.5756\" y=\"-139.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layer 1</text>\n</g>\n<!-- embeddings&#45;&gt;enc1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>embeddings-&gt;enc1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M616.1693,-143.8525C635.3836,-143.8525 658.3989,-143.8525 679.6038,-143.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"679.8435,-147.3526 689.8435,-143.8525 679.8435,-140.3526 679.8435,-147.3526\"/>\n</g>\n<!-- enc2 -->\n<g id=\"node4\" class=\"node\">\n<title>enc2</title>\n<polygon fill=\"#ffffe0\" stroke=\"#add8e6\" points=\"956.5064,-161.8525 846.936,-161.8525 846.936,-125.8525 956.5064,-125.8525 956.5064,-161.8525\"/>\n<text text-anchor=\"middle\" x=\"901.7212\" y=\"-139.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layer 2</text>\n</g>\n<!-- enc1&#45;&gt;enc2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>enc1-&gt;enc2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M799.5375,-143.8525C811.5691,-143.8525 824.415,-143.8525 836.7946,-143.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"837.0557,-147.3526 847.0557,-143.8525 837.0557,-140.3526 837.0557,-147.3526\"/>\n</g>\n<!-- attention -->\n<g id=\"node5\" class=\"node\">\n<title>attention</title>\n<polygon fill=\"#ffffe0\" stroke=\"#add8e6\" points=\"112.1389,-76.8525 15.9537,-76.8525 15.9537,-40.8525 112.1389,-40.8525 112.1389,-76.8525\"/>\n<text text-anchor=\"middle\" x=\"64.0463\" y=\"-54.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<!-- enc2&#45;&gt;attention -->\n<g id=\"edge4\" class=\"edge\">\n<title>enc2-&gt;attention</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M894.6187,-125.581C883.1948,-98.9845 857.9969,-50.4321 819.0788,-28.8525 723.1626,24.3316 682.5051,-12.8525 572.8308,-12.8525 381.0839,-12.8525 381.0839,-12.8525 381.0839,-12.8525 277.1885,-12.8525 249.9967,-11.6087 148.0926,-31.8525 139.5736,-33.5449 130.7076,-35.8111 122.0657,-38.3142\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"120.9953,-34.9813 112.4343,-41.223 123.0192,-41.6823 120.9953,-34.9813\"/>\n</g>\n<!-- output -->\n<g id=\"node11\" class=\"node\">\n<title>output</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#add8e6\" points=\"1059.1954,-161.8525 1004.4196,-161.8525 1004.4196,-125.8525 1059.1954,-125.8525 1059.1954,-161.8525\"/>\n<text text-anchor=\"middle\" x=\"1031.8075\" y=\"-139.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- enc2&#45;&gt;output -->\n<g id=\"edge13\" class=\"edge\">\n<title>enc2-&gt;output</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M956.5125,-143.8525C969.1652,-143.8525 982.3488,-143.8525 994.0828,-143.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"994.3947,-147.3526 1004.3946,-143.8525 994.3946,-140.3526 994.3947,-147.3526\"/>\n</g>\n<!-- global -->\n<g id=\"node6\" class=\"node\">\n<title>global</title>\n<polygon fill=\"#ffffe0\" stroke=\"#add8e6\" points=\"258.8227,-76.8525 147.8485,-76.8525 147.8485,-40.8525 258.8227,-40.8525 258.8227,-76.8525\"/>\n<text text-anchor=\"middle\" x=\"203.3356\" y=\"-54.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Global Attention</text>\n</g>\n<!-- attention&#45;&gt;global -->\n<g id=\"edge5\" class=\"edge\">\n<title>attention-&gt;global</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M112.372,-58.8525C120.6174,-58.8525 129.304,-58.8525 137.9046,-58.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.9299,-62.3526 147.9299,-58.8525 137.9299,-55.3526 137.9299,-62.3526\"/>\n</g>\n<!-- local -->\n<g id=\"node7\" class=\"node\">\n<title>local</title>\n<polygon fill=\"#eedd82\" stroke=\"#add8e6\" points=\"255.5919,-130.8525 151.0793,-130.8525 151.0793,-94.8525 255.5919,-94.8525 255.5919,-130.8525\"/>\n<text text-anchor=\"middle\" x=\"203.3356\" y=\"-108.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Local Attention</text>\n</g>\n<!-- attention&#45;&gt;local -->\n<g id=\"edge6\" class=\"edge\">\n<title>attention-&gt;local</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.8151,-76.984C122.4145,-81.4808 134.9662,-86.3469 146.9712,-91.0011\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"145.8641,-94.3256 156.4531,-94.677 148.3945,-87.7989 145.8641,-94.3256\"/>\n</g>\n<!-- ffnn -->\n<g id=\"node8\" class=\"node\">\n<title>ffnn</title>\n<polygon fill=\"#ffa07a\" stroke=\"#add8e6\" points=\"440.5945,-76.8525 321.5733,-76.8525 321.5733,-40.8525 440.5945,-40.8525 440.5945,-76.8525\"/>\n<text text-anchor=\"middle\" x=\"381.0839\" y=\"-54.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<!-- global&#45;&gt;ffnn -->\n<g id=\"edge7\" class=\"edge\">\n<title>global-&gt;ffnn</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M258.6019,-58.8525C275.2994,-58.8525 293.853,-58.8525 311.3648,-58.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.5333,-62.3526 321.5332,-58.8525 311.5332,-55.3526 311.5333,-62.3526\"/>\n</g>\n<!-- local&#45;&gt;ffnn -->\n<g id=\"edge8\" class=\"edge\">\n<title>local-&gt;ffnn</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.7046,-96.9428C273.3198,-91.5913 293.2509,-85.5362 311.9534,-79.8544\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.052,-83.1787 321.6028,-76.9229 311.0172,-76.4809 313.052,-83.1787\"/>\n</g>\n<!-- residuals -->\n<g id=\"node9\" class=\"node\">\n<title>residuals</title>\n<polygon fill=\"#ffb6c1\" stroke=\"#add8e6\" points=\"642.3148,-76.8525 503.3468,-76.8525 503.3468,-40.8525 642.3148,-40.8525 642.3148,-76.8525\"/>\n<text text-anchor=\"middle\" x=\"572.8308\" y=\"-54.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Residual Connections</text>\n</g>\n<!-- ffnn&#45;&gt;residuals -->\n<g id=\"edge9\" class=\"edge\">\n<title>ffnn-&gt;residuals</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M440.7027,-58.8525C457.3367,-58.8525 475.6782,-58.8525 493.2654,-58.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"493.5148,-62.3526 503.5147,-58.8525 493.5147,-55.3526 493.5148,-62.3526\"/>\n</g>\n<!-- norm -->\n<g id=\"node10\" class=\"node\">\n<title>norm</title>\n<polygon fill=\"#f08080\" stroke=\"#add8e6\" points=\"811.082,-76.8525 678.0692,-76.8525 678.0692,-40.8525 811.082,-40.8525 811.082,-76.8525\"/>\n<text text-anchor=\"middle\" x=\"744.5756\" y=\"-54.6525\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Layer Normalization</text>\n</g>\n<!-- residuals&#45;&gt;norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>residuals-&gt;norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M642.1909,-58.8525C650.6889,-58.8525 659.4111,-58.8525 668.0074,-58.8525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"668.02,-62.3526 678.02,-58.8525 668.02,-55.3526 668.02,-62.3526\"/>\n</g>\n<!-- norm&#45;&gt;enc1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>norm-&gt;enc1</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"5,2\" d=\"M744.5756,-77.1143C744.5756,-89.868 744.5756,-102.6218 744.5756,-115.3755\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"741.0757,-115.6038 744.5756,-125.6038 748.0757,-115.6038 741.0757,-115.6038\"/>\n</g>\n<!-- norm&#45;&gt;enc2 -->\n<g id=\"edge12\" class=\"edge\">\n<title>norm-&gt;enc2</title>\n<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"5,2\" d=\"M777.9021,-76.8789C801.6534,-89.7259 833.7722,-107.099 859.345,-120.9312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"857.9818,-124.1731 868.4427,-125.8522 861.3121,-118.016 857.9818,-124.1731\"/>\n</g>\n</g>\n</svg>"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\n    Importing modules\n    </div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import LongformerTokenizer, LongformerForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:03.581330Z","iopub.execute_input":"2023-06-22T14:33:03.581685Z","iopub.status.idle":"2023-06-22T14:33:09.320738Z","shell.execute_reply.started":"2023-06-22T14:33:03.581652Z","shell.execute_reply":"2023-06-22T14:33:09.319580Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nSetting random seed for reproducibility    </div>","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:09.322926Z","iopub.execute_input":"2023-06-22T14:33:09.323314Z","iopub.status.idle":"2023-06-22T14:33:09.332905Z","shell.execute_reply.started":"2023-06-22T14:33:09.323277Z","shell.execute_reply":"2023-06-22T14:33:09.331730Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f4b84b06710>"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nReading dataframe and inspecting their columns    </div>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:09.336889Z","iopub.execute_input":"2023-06-22T14:33:09.337298Z","iopub.status.idle":"2023-06-22T14:33:24.216005Z","shell.execute_reply.started":"2023-06-22T14:33:09.337270Z","shell.execute_reply":"2023-06-22T14:33:24.215043Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.217528Z","iopub.execute_input":"2023-06-22T14:33:24.218276Z","iopub.status.idle":"2023-06-22T14:33:24.225724Z","shell.execute_reply.started":"2023-06-22T14:33:24.218240Z","shell.execute_reply":"2023-06-22T14:33:24.224845Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n       'other_sexual_orientation', 'physical_disability',\n       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n       'sad', 'likes', 'disagree', 'sexual_explicit',\n       'identity_annotator_count', 'toxicity_annotator_count'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.227020Z","iopub.execute_input":"2023-06-22T14:33:24.227798Z","iopub.status.idle":"2023-06-22T14:33:24.245397Z","shell.execute_reply.started":"2023-06-22T14:33:24.227767Z","shell.execute_reply":"2023-06-22T14:33:24.244473Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'comment_text'], dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nPreparing data for training    </div>","metadata":{}},{"cell_type":"code","source":"train_texts = train_df['comment_text'].tolist()\ntrain_labels = train_df['target'].astype(float).tolist()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.247079Z","iopub.execute_input":"2023-06-22T14:33:24.247540Z","iopub.status.idle":"2023-06-22T14:33:24.393071Z","shell.execute_reply.started":"2023-06-22T14:33:24.247387Z","shell.execute_reply":"2023-06-22T14:33:24.392098Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nSplitting the data into train and val sets. Here, we intentionally chunked the text samples to 100, feel free to remove it for complete training.    </div>","metadata":{}},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts[:100], train_labels[:100], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.394480Z","iopub.execute_input":"2023-06-22T14:33:24.395069Z","iopub.status.idle":"2023-06-22T14:33:24.444156Z","shell.execute_reply.started":"2023-06-22T14:33:24.395032Z","shell.execute_reply":"2023-06-22T14:33:24.443190Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nTokenizing the texts    </div>","metadata":{}},{"cell_type":"code","source":"tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=4096)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=4096)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.445495Z","iopub.execute_input":"2023-06-22T14:33:24.446306Z","iopub.status.idle":"2023-06-22T14:33:24.772031Z","shell.execute_reply.started":"2023-06-22T14:33:24.446271Z","shell.execute_reply":"2023-06-22T14:33:24.771014Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nCreating dataset class    </div>","metadata":{}},{"cell_type":"code","source":"class ToxicityDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    \n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n    \n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.773609Z","iopub.execute_input":"2023-06-22T14:33:24.774032Z","iopub.status.idle":"2023-06-22T14:33:24.782573Z","shell.execute_reply.started":"2023-06-22T14:33:24.773997Z","shell.execute_reply":"2023-06-22T14:33:24.781545Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nCreating train and val dataset    </div>","metadata":{}},{"cell_type":"code","source":"train_dataset = ToxicityDataset(train_encodings, train_labels)\nval_dataset = ToxicityDataset(val_encodings, val_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.784031Z","iopub.execute_input":"2023-06-22T14:33:24.784832Z","iopub.status.idle":"2023-06-22T14:33:24.792737Z","shell.execute_reply.started":"2023-06-22T14:33:24.784781Z","shell.execute_reply":"2023-06-22T14:33:24.791726Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nCreating train and val dataloaders and inspecting them    </div>","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.794054Z","iopub.execute_input":"2023-06-22T14:33:24.794453Z","iopub.status.idle":"2023-06-22T14:33:24.805851Z","shell.execute_reply.started":"2023-06-22T14:33:24.794421Z","shell.execute_reply":"2023-06-22T14:33:24.804776Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for batch in train_loader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.811043Z","iopub.execute_input":"2023-06-22T14:33:24.811929Z","iopub.status.idle":"2023-06-22T14:33:24.827015Z","shell.execute_reply.started":"2023-06-22T14:33:24.811897Z","shell.execute_reply":"2023-06-22T14:33:24.825986Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[    0,  2387,  1203,    12,   658,    95,   122,  1705,    75,    33,\n            57, 31675,   328,     2,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1],\n        [    0,  1106,    51,  1661,    10,  4573, 19995,  3130,  5309,  4193,\n            52,    74,    28,  6889,     6,    53,    77,    52,   553,    59,\n            24,     6,    51,    58,  1256, 37890,     9,     5,  1114,     4,\n          1437,  4557, 23106,  5682,    18,   159,     5,  2014,     8,   221,\n          6352,   636,  3938,    11,  4962,  5610,    13, 32727,  1735,     4,\n           166,   581,  4757,    19,   106,     4,     2,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([0., 0.])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nLoading the longformer model    </div>","metadata":{}},{"cell_type":"code","source":"model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:24.828577Z","iopub.execute_input":"2023-06-22T14:33:24.829387Z","iopub.status.idle":"2023-06-22T14:33:26.611311Z","shell.execute_reply.started":"2023-06-22T14:33:24.829356Z","shell.execute_reply":"2023-06-22T14:33:26.610248Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nSetting device to GPU and moving model to it.    </div>","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:26.613041Z","iopub.execute_input":"2023-06-22T14:33:26.613660Z","iopub.status.idle":"2023-06-22T14:33:29.216356Z","shell.execute_reply.started":"2023-06-22T14:33:26.613624Z","shell.execute_reply":"2023-06-22T14:33:29.215512Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"LongformerForSequenceClassification(\n  (longformer): LongformerModel(\n    (embeddings): LongformerEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n    )\n    (encoder): LongformerEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x LongformerLayer(\n          (attention): LongformerAttention(\n            (self): LongformerSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (query_global): Linear(in_features=768, out_features=768, bias=True)\n              (key_global): Linear(in_features=768, out_features=768, bias=True)\n              (value_global): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (output): LongformerSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LongformerIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LongformerOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): LongformerClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nSetting optimizer and learning rate    </div>","metadata":{}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-5)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:33:29.220746Z","iopub.execute_input":"2023-06-22T14:33:29.222923Z","iopub.status.idle":"2023-06-22T14:33:29.236156Z","shell.execute_reply.started":"2023-06-22T14:33:29.222889Z","shell.execute_reply":"2023-06-22T14:33:29.235190Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nPutting model to train and val.    </div>","metadata":{}},{"cell_type":"code","source":"# Training loop\nmodel.train()\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    train_loss = 0\n    val_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].unsqueeze(1).repeat(1, 2).to(device)  # Adjust the shape of labels\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    for batch in val_loader:\n        with torch.no_grad():\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].unsqueeze(1).repeat(1, 2).to(device)  # Adjust the shape of labels\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(val_loader)\n\n    print(f'Epoch {epoch+1}: Train Loss = {train_loss}, Val Loss = {val_loss}')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:34:34.612583Z","iopub.execute_input":"2023-06-22T14:34:34.613090Z","iopub.status.idle":"2023-06-22T14:35:35.312177Z","shell.execute_reply.started":"2023-06-22T14:34:34.613049Z","shell.execute_reply":"2023-06-22T14:35:35.311162Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 0.4916120771318674, Val Loss = 0.38194221034646036\nEpoch 2: Train Loss = 0.2907418064773083, Val Loss = 0.3769370909780264\nEpoch 3: Train Loss = 0.24229335533455015, Val Loss = 0.2917042512446642\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nInferencing to generate submission    </div>","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n# Test the model on the test set\ntest_texts = test_df['comment_text'].tolist()\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=4096)\ntest_dataset = ToxicityDataset(test_encodings, [0] * len(test_encodings))  # Placeholder labels\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n\nmodel.eval()\npredictions = []\nfor batch in tqdm(test_loader):\n    with torch.no_grad():\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        batch_predictions = torch.sigmoid(logits).cpu().numpy().flatten().tolist()\n        predictions.extend(batch_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:38:00.117696Z","iopub.execute_input":"2023-06-22T14:38:00.118319Z","iopub.status.idle":"2023-06-22T14:39:06.483444Z","shell.execute_reply.started":"2023-06-22T14:38:00.118288Z","shell.execute_reply":"2023-06-22T14:39:06.482381Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n📌\nGenerating submission    </div>","metadata":{}},{"cell_type":"code","source":"# Generate submission file\nsubmission_df = pd.DataFrame({'id': test_df['id'][:4], 'prediction': predictions})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:44:56.309654Z","iopub.execute_input":"2023-06-22T14:44:56.310032Z","iopub.status.idle":"2023-06-22T14:44:56.331376Z","shell.execute_reply.started":"2023-06-22T14:44:56.310001Z","shell.execute_reply":"2023-06-22T14:44:56.330403Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:45:01.497693Z","iopub.execute_input":"2023-06-22T14:45:01.498414Z","iopub.status.idle":"2023-06-22T14:45:01.517629Z","shell.execute_reply.started":"2023-06-22T14:45:01.498376Z","shell.execute_reply":"2023-06-22T14:45:01.515752Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        id  prediction\n0  7097320    0.104767\n1  7097321    0.112205\n2  7097322    0.092554\n3  7097323    0.102792","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7097320</td>\n      <td>0.104767</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7097321</td>\n      <td>0.112205</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7097322</td>\n      <td>0.092554</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7097323</td>\n      <td>0.102792</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}