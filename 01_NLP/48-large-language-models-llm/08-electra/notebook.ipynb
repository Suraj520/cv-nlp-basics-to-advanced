{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#035FCA; color:#19180F; font-size:40px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\"> Electra </div>\n\n<div style=\"background-color:#568FD1; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">üîßArchitecture Overview‚öôÔ∏è\n </div>\n <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\n\nIt is a neural network architecture that belongs to the hierarchy of transformers family.<br>\n\nThe building blocks of Electra is explained below<br>\n\n1. Transformer architecture - Similar to other models like BERT, GPT2, It is built upon the transformer architecture which utilize self attention mechanisms to capture the relationships b/w words in a sentence and enable parallel procesing.<br>\n\n2. Pre-training and Fine tuning : Like BERT and GPT2, Electra also follows a two step process. It undergoes pre-training and fine-tuning. In the pre-training phase, the model is trained over a large corpus of unlabeled text to learn the language patterns and representations. In the fine tuning phase, the model is further trained on a smaller labeled dataset for specific downstream tasks like text classification or NER.<br>\n\n3. Masked Language Modelling vs. Discriminative Training : In BERT, a technique known as MLM is used where random words are masked and the model is asked to predict them. In contrast, Electra employs Discriminative training. Instead of masking words, It replaces some of them with plausible alternatives and tasks the model with distinguishing the original word from the replacement. This way, Electra learns to discriminate b/w real and generated tokens resulting in more efficient training.<br>\n\n4. Generator and Discriminator: Electra consists of two components, The generator and the discriminator. The generator takes in a sentence as input and tries to predict the replaced words whereas the discriminator aims to determine whether the replaced words are real or generated. These two components work in synchronicity during training with the Discriminator providing feedback to improve generator's performance.\n<br>\n5. Model size and training efficiency- Electra is designed to be computationally more efficient compared to some other models. For instance, models like BERT and GPT2 are known for their large size, which makes training and deployment challenging. Electra whreas achieves similar performance with smaller memory footprints.<br>\n\n    <b> Key differences in the architecture of Electra and other models.</b><br>\n\n- With respect to ALBERT : ALBERT uses parameter sharing to reduce model size and training time whreas Electra although smaller, focuses on the Discriminative Training approach for efficiency.<br>\n\n- With respect to ROBERTA- ROBERTA uses large batch size and corpus to train but Electra achieves similar performance with smaller resources.<br>\n\n- With respect to T5 - T5 is a versatile model for various NLP tasks while Electra's fine tuning also makes it capable for a wide number of NLP tasks.<br>\n<div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#568FD1; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\"> üè¢ Architecture Diagram.\n </div>\n<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\n\n1. Input Layer: The architecture is given input tokens that reflect the input sequence.<br>\n\n2. Encoder Layers: After that, the input tokens are routed via a number of encoder layers. Each encoder layer is made up of the following elements:<br>\n\n   a. Self-Attention Mechanism: This component uses self-attention operations to detect relationships between distinct places in the input tokens. It is made up of three vectors: query (Q), key (K), and value (V). The self-attention mechanism computes attention scores for each token in respect to all other tokens, allowing it to balance the significance of each token's information in relation to the others. This component aids the model in comprehending the context and connections between various tokens.<br>\n\n   b. Feed-Forward Neural Network (FFNN): The output is sent via a feed-forward neural network after self-attention. This network is made up of numerous completely linked layers that alter and enhance token representations. To capture complicated patterns and relationships in data, the FFNN employs non-linear transformations.<br>\n\n   c. Add and Normalise: The self-attention mechanism and feed-forward neural network outputs are added element by element, followed by a layer normalisation procedure. This technique aids in the stabilisation of the training process by integrating the learnt representations from both components and normalising the outputs.<br>\n\n   The methods outlined above are repeated for each encoder layer in the architecture, allowing the model to capture increasingly sophisticated and abstract representations of the input sequence.<br>\n\n3. Output Layer: The final output tokens are acquired once the input tokens have been processed through all of the encoder levels. The improved and altered representations of the input sequence are represented by these output tokens.<br>\n\nThe diagram's linkages between components depict the flow of information and transformations that occur in the Electra Transformer architecture. The input tokens are embedded initially and then transmitted via numerous encoder layers, which perform self-attention, feed-forward neural networks, and normalisation operations. Finally, the revised representations are fed into a linear mapping to generate the output tokens.<br>\n\n</div>\n\n\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import SVG, display\n\n# Load the SVG file and display it\nsvg_file = '/kaggle/input/notebook-images/electra.svg'\ndisplay(SVG(filename=svg_file))","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:31:34.324473Z","iopub.execute_input":"2023-06-10T21:31:34.324849Z","iopub.status.idle":"2023-06-10T21:31:34.357239Z","shell.execute_reply.started":"2023-06-10T21:31:34.324821Z","shell.execute_reply":"2023-06-10T21:31:34.356295Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1290pt\" height=\"386pt\" viewBox=\"0.00 0.00 1289.69 386.40\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 382.4)\">\n<title>ElectraTransformer</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-382.4 1285.6948,-382.4 1285.6948,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_input</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"544,0 544,-64.8 633.36,-64.8 633.36,0 544,0\"/>\n<text text-anchor=\"middle\" x=\"588.68\" y=\"-48.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Layer</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_encoder</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"0,-68 0,-378.4 1179,-378.4 1179,-68 0,-68\"/>\n<text text-anchor=\"middle\" x=\"589.5\" y=\"-361.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_encoder1</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"2,-110 2,-351.6 391,-351.6 391,-110 2,-110\"/>\n<text text-anchor=\"middle\" x=\"196.5\" y=\"-335\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layer 1</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_self_attention1</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"4,-220 4,-324.8 212,-324.8 212,-220 4,-220\"/>\n<text text-anchor=\"middle\" x=\"108\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_ffnn1</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"216,-220 216,-324.8 389,-324.8 389,-220 216,-220\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_add_norm1</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"24,-112 24,-216.8 192,-216.8 192,-112 24,-112\"/>\n<text text-anchor=\"middle\" x=\"108\" y=\"-200.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_encoder2</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"395,-110 395,-351.6 784,-351.6 784,-110 395,-110\"/>\n<text text-anchor=\"middle\" x=\"589.5\" y=\"-335\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layer 2</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_self_attention2</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"397,-220 397,-324.8 605,-324.8 605,-220 397,-220\"/>\n<text text-anchor=\"middle\" x=\"501\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_ffnn2</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"609,-220 609,-324.8 782,-324.8 782,-220 609,-220\"/>\n<text text-anchor=\"middle\" x=\"695.5\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_add_norm2</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"417,-112 417,-216.8 585,-216.8 585,-112 417,-112\"/>\n<text text-anchor=\"middle\" x=\"501\" y=\"-200.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_encoderN</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"788,-110 788,-351.6 1177,-351.6 1177,-110 788,-110\"/>\n<text text-anchor=\"middle\" x=\"982.5\" y=\"-335\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Layer N</text>\n</g>\n<g id=\"clust12\" class=\"cluster\">\n<title>cluster_self_attentionN</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"790,-220 790,-324.8 998,-324.8 998,-220 790,-220\"/>\n<text text-anchor=\"middle\" x=\"894\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<g id=\"clust13\" class=\"cluster\">\n<title>cluster_ffnnN</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"1002,-220 1002,-324.8 1175,-324.8 1175,-220 1002,-220\"/>\n<text text-anchor=\"middle\" x=\"1088.5\" y=\"-308.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<g id=\"clust14\" class=\"cluster\">\n<title>cluster_add_normN</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"810,-112 810,-216.8 978,-216.8 978,-112 810,-112\"/>\n<text text-anchor=\"middle\" x=\"894\" y=\"-200.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<g id=\"clust15\" class=\"cluster\">\n<title>cluster_output</title>\n<polygon fill=\"none\" stroke=\"#d3d3d3\" points=\"1183,-191 1183,-255.8 1281.6948,-255.8 1281.6948,-191 1183,-191\"/>\n<text text-anchor=\"middle\" x=\"1232.3474\" y=\"-239.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output Layer</text>\n</g>\n<!-- input_tokens -->\n<g id=\"node1\" class=\"node\">\n<title>input_tokens</title>\n<path fill=\"#add8e6\" stroke=\"#000000\" d=\"M619.5408,-38C619.5408,-38 557.8192,-38 557.8192,-38 551.8192,-38 545.8192,-32 545.8192,-26 545.8192,-26 545.8192,-14 545.8192,-14 545.8192,-8 551.8192,-2 557.8192,-2 557.8192,-2 619.5408,-2 619.5408,-2 625.5408,-2 631.5408,-8 631.5408,-14 631.5408,-14 631.5408,-26 631.5408,-26 631.5408,-32 625.5408,-38 619.5408,-38\"/>\n<text text-anchor=\"middle\" x=\"588.68\" y=\"-16.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input Tokens</text>\n</g>\n<!-- add_norm_input1 -->\n<g id=\"node10\" class=\"node\">\n<title>add_norm_input1</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M178,-190C178,-190 148,-190 148,-190 142,-190 136,-184 136,-178 136,-178 136,-166 136,-166 136,-160 142,-154 148,-154 148,-154 178,-154 178,-154 184,-154 190,-160 190,-166 190,-166 190,-178 190,-178 190,-184 184,-190 178,-190\"/>\n<text text-anchor=\"middle\" x=\"163\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- input_tokens&#45;&gt;add_norm_input1 -->\n<g id=\"edge34\" class=\"edge\">\n<title>input_tokens-&gt;add_norm_input1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M545.9152,-35.2703C462.2102,-65.1593 278.0768,-130.9089 199.596,-158.9325\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.3627,-155.6563 190.1221,-162.3154 200.7167,-162.2487 198.3627,-155.6563\"/>\n<text text-anchor=\"middle\" x=\"347.4701\" y=\"-100.1014\" font-family=\"Arial\" font-size=\"10.00\" fill=\"#000000\">Embedding</text>\n</g>\n<!-- self_att_q1 -->\n<g id=\"node2\" class=\"node\">\n<title>self_att_q1</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M198,-298C198,-298 168,-298 168,-298 162,-298 156,-292 156,-286 156,-286 156,-274 156,-274 156,-268 162,-262 168,-262 168,-262 198,-262 198,-262 204,-262 210,-268 210,-274 210,-274 210,-286 210,-286 210,-292 204,-298 198,-298\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Q</text>\n</g>\n<!-- self_attention1 -->\n<g id=\"node5\" class=\"node\">\n<title>self_attention1</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M82.0288,-298C82.0288,-298 17.9904,-298 17.9904,-298 11.9904,-298 5.9904,-292 5.9904,-286 5.9904,-286 5.9904,-274 5.9904,-274 5.9904,-268 11.9904,-262 17.9904,-262 17.9904,-262 82.0288,-262 82.0288,-262 88.0288,-262 94.0288,-268 94.0288,-274 94.0288,-274 94.0288,-286 94.0288,-286 94.0288,-292 88.0288,-298 82.0288,-298\"/>\n<text text-anchor=\"middle\" x=\"50.0096\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<!-- self_att_q1&#45;&gt;self_attention1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>self_att_q1-&gt;self_attention1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M155.7665,-280C140.9652,-280 122.1204,-280 104.4505,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.2221,-276.5001 94.222,-280 104.222,-283.5001 104.2221,-276.5001\"/>\n</g>\n<!-- self_att_k1 -->\n<g id=\"node3\" class=\"node\">\n<title>self_att_k1</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M140,-298C140,-298 110,-298 110,-298 104,-298 98,-292 98,-286 98,-286 98,-274 98,-274 98,-268 104,-262 110,-262 110,-262 140,-262 140,-262 146,-262 152,-268 152,-274 152,-274 152,-286 152,-286 152,-292 146,-298 140,-298\"/>\n<text text-anchor=\"middle\" x=\"125\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">K</text>\n</g>\n<!-- self_att_k1&#45;&gt;self_attention1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>self_att_k1-&gt;self_attention1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M97.9267,-280C97.7694,-280 97.6118,-280 97.454,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.1063,-276.5003 94.1062,-280 104.1061,-283.5003 104.1063,-276.5003\"/>\n</g>\n<!-- self_att_v1 -->\n<g id=\"node4\" class=\"node\">\n<title>self_att_v1</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M65,-258C65,-258 35,-258 35,-258 29,-258 23,-252 23,-246 23,-246 23,-234 23,-234 23,-228 29,-222 35,-222 35,-222 65,-222 65,-222 71,-222 77,-228 77,-234 77,-234 77,-246 77,-246 77,-252 71,-258 65,-258\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">V</text>\n</g>\n<!-- self_att_v1&#45;&gt;self_attention1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>self_att_v1-&gt;self_attention1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.0044,-258.1274C50.0044,-258.2721 50.0044,-258.417 50.0045,-258.5619\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"46.5025,-251.6107 50.0052,-261.6098 53.5025,-251.6088 46.5025,-251.6107\"/>\n</g>\n<!-- self_att_output1 -->\n<g id=\"node6\" class=\"node\">\n<title>self_att_output1</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M140,-258C140,-258 110,-258 110,-258 104,-258 98,-252 98,-246 98,-246 98,-234 98,-234 98,-228 104,-222 110,-222 110,-222 140,-222 140,-222 146,-222 152,-228 152,-234 152,-234 152,-246 152,-246 152,-252 146,-258 140,-258\"/>\n<text text-anchor=\"middle\" x=\"125\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- self_attention1&#45;&gt;self_att_output1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>self_attention1-&gt;self_att_output1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M83.9942,-261.8726C85.5928,-261.0199 87.1999,-260.1626 88.8039,-259.3071\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"90.6977,-262.2637 97.8737,-254.4692 87.4032,-256.0874 90.6977,-262.2637\"/>\n</g>\n<!-- self_att_output1&#45;&gt;add_norm_input1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>self_att_output1-&gt;add_norm_input1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M135.1833,-221.7772C139.0594,-214.841 143.5646,-206.7791 147.806,-199.1893\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"150.9656,-200.7099 152.7886,-190.2731 144.855,-197.2951 150.9656,-200.7099\"/>\n</g>\n<!-- ffnn_input1 -->\n<g id=\"node7\" class=\"node\">\n<title>ffnn_input1</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M375,-298C375,-298 345,-298 345,-298 339,-298 333,-292 333,-286 333,-286 333,-274 333,-274 333,-268 339,-262 345,-262 345,-262 375,-262 375,-262 381,-262 387,-268 387,-274 387,-274 387,-286 387,-286 387,-292 381,-298 375,-298\"/>\n<text text-anchor=\"middle\" x=\"360\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- ffnn1 -->\n<g id=\"node8\" class=\"node\">\n<title>ffnn1</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M317.991,-298C317.991,-298 230.003,-298 230.003,-298 224.003,-298 218.003,-292 218.003,-286 218.003,-286 218.003,-274 218.003,-274 218.003,-268 224.003,-262 230.003,-262 230.003,-262 317.991,-262 317.991,-262 323.991,-262 329.991,-268 329.991,-274 329.991,-274 329.991,-286 329.991,-286 329.991,-292 323.991,-298 317.991,-298\"/>\n<text text-anchor=\"middle\" x=\"273.997\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<!-- ffnn_input1&#45;&gt;ffnn1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>ffnn_input1-&gt;ffnn1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M332.7881,-280C332.6774,-280 332.5665,-280 332.4555,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"340.1015,-276.5004 330.1014,-280 340.1012,-283.5004 340.1015,-276.5004\"/>\n</g>\n<!-- ffnn_output1 -->\n<g id=\"node9\" class=\"node\">\n<title>ffnn_output1</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M288,-258C288,-258 258,-258 258,-258 252,-258 246,-252 246,-246 246,-246 246,-234 246,-234 246,-228 252,-222 258,-222 258,-222 288,-222 288,-222 294,-222 300,-228 300,-234 300,-234 300,-246 300,-246 300,-252 294,-258 288,-258\"/>\n<text text-anchor=\"middle\" x=\"273\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- ffnn1&#45;&gt;ffnn_output1 -->\n<g id=\"edge6\" class=\"edge\">\n<title>ffnn1-&gt;ffnn_output1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M273.5452,-261.8726C273.5416,-261.7279 273.538,-261.583 273.5343,-261.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.2068,-268.2998 273.4584,-258.3902 270.209,-268.4744 277.2068,-268.2998\"/>\n</g>\n<!-- ffnn_output1&#45;&gt;add_norm_input1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>ffnn_output1-&gt;add_norm_input1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M245.809,-223.191C231.6622,-214.4457 214.1843,-203.6412 198.937,-194.2156\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.6058,-191.1325 190.2594,-188.8513 196.925,-197.0866 200.6058,-191.1325\"/>\n</g>\n<!-- add_norm1 -->\n<g id=\"node11\" class=\"node\">\n<title>add_norm1</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M120.0108,-190C120.0108,-190 37.9964,-190 37.9964,-190 31.9964,-190 25.9964,-184 25.9964,-178 25.9964,-178 25.9964,-166 25.9964,-166 25.9964,-160 31.9964,-154 37.9964,-154 37.9964,-154 120.0108,-154 120.0108,-154 126.0108,-154 132.0108,-160 132.0108,-166 132.0108,-166 132.0108,-178 132.0108,-178 132.0108,-184 126.0108,-190 120.0108,-190\"/>\n<text text-anchor=\"middle\" x=\"79.0036\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<!-- add_norm_input1&#45;&gt;add_norm1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>add_norm_input1-&gt;add_norm1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M135.9607,-172C135.8048,-172 135.6486,-172 135.4921,-172\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"142.1646,-168.5003 132.1644,-172 142.1643,-175.5003 142.1646,-168.5003\"/>\n</g>\n<!-- add_norm_output1 -->\n<g id=\"node12\" class=\"node\">\n<title>add_norm_output1</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M94,-150C94,-150 64,-150 64,-150 58,-150 52,-144 52,-138 52,-138 52,-126 52,-126 52,-120 58,-114 64,-114 64,-114 94,-114 94,-114 100,-114 106,-120 106,-126 106,-126 106,-138 106,-138 106,-144 100,-150 94,-150\"/>\n<text text-anchor=\"middle\" x=\"79\" y=\"-128.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- add_norm1&#45;&gt;add_norm_output1 -->\n<g id=\"edge10\" class=\"edge\">\n<title>add_norm1-&gt;add_norm_output1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M79.002,-153.8726C79.002,-153.7279 79.0019,-153.583 79.0019,-153.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.5029,-160.3898 79.0017,-150.3902 75.5029,-160.3907 82.5029,-160.3898\"/>\n</g>\n<!-- add_norm_input2 -->\n<g id=\"node21\" class=\"node\">\n<title>add_norm_input2</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M571,-190C571,-190 541,-190 541,-190 535,-190 529,-184 529,-178 529,-178 529,-166 529,-166 529,-160 535,-154 541,-154 541,-154 571,-154 571,-154 577,-154 583,-160 583,-166 583,-166 583,-178 583,-178 583,-184 577,-190 571,-190\"/>\n<text text-anchor=\"middle\" x=\"556\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- add_norm_output1&#45;&gt;add_norm_input2 -->\n<!-- self_att_q2 -->\n<g id=\"node13\" class=\"node\">\n<title>self_att_q2</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M591,-298C591,-298 561,-298 561,-298 555,-298 549,-292 549,-286 549,-286 549,-274 549,-274 549,-268 555,-262 561,-262 561,-262 591,-262 591,-262 597,-262 603,-268 603,-274 603,-274 603,-286 603,-286 603,-292 597,-298 591,-298\"/>\n<text text-anchor=\"middle\" x=\"576\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Q</text>\n</g>\n<!-- self_attention2 -->\n<g id=\"node16\" class=\"node\">\n<title>self_attention2</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M475.0288,-298C475.0288,-298 410.9904,-298 410.9904,-298 404.9904,-298 398.9904,-292 398.9904,-286 398.9904,-286 398.9904,-274 398.9904,-274 398.9904,-268 404.9904,-262 410.9904,-262 410.9904,-262 475.0288,-262 475.0288,-262 481.0288,-262 487.0288,-268 487.0288,-274 487.0288,-274 487.0288,-286 487.0288,-286 487.0288,-292 481.0288,-298 475.0288,-298\"/>\n<text text-anchor=\"middle\" x=\"443.0096\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<!-- self_att_q2&#45;&gt;self_attention2 -->\n<g id=\"edge11\" class=\"edge\">\n<title>self_att_q2-&gt;self_attention2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M548.7665,-280C533.9652,-280 515.1204,-280 497.4505,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"497.2221,-276.5001 487.222,-280 497.222,-283.5001 497.2221,-276.5001\"/>\n</g>\n<!-- self_att_k2 -->\n<g id=\"node14\" class=\"node\">\n<title>self_att_k2</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M533,-298C533,-298 503,-298 503,-298 497,-298 491,-292 491,-286 491,-286 491,-274 491,-274 491,-268 497,-262 503,-262 503,-262 533,-262 533,-262 539,-262 545,-268 545,-274 545,-274 545,-286 545,-286 545,-292 539,-298 533,-298\"/>\n<text text-anchor=\"middle\" x=\"518\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">K</text>\n</g>\n<!-- self_att_k2&#45;&gt;self_attention2 -->\n<g id=\"edge12\" class=\"edge\">\n<title>self_att_k2-&gt;self_attention2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M490.9267,-280C490.7694,-280 490.6118,-280 490.454,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"497.1063,-276.5003 487.1062,-280 497.1061,-283.5003 497.1063,-276.5003\"/>\n</g>\n<!-- self_att_v2 -->\n<g id=\"node15\" class=\"node\">\n<title>self_att_v2</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M458,-258C458,-258 428,-258 428,-258 422,-258 416,-252 416,-246 416,-246 416,-234 416,-234 416,-228 422,-222 428,-222 428,-222 458,-222 458,-222 464,-222 470,-228 470,-234 470,-234 470,-246 470,-246 470,-252 464,-258 458,-258\"/>\n<text text-anchor=\"middle\" x=\"443\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">V</text>\n</g>\n<!-- self_att_v2&#45;&gt;self_attention2 -->\n<g id=\"edge13\" class=\"edge\">\n<title>self_att_v2-&gt;self_attention2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.0044,-258.1274C443.0044,-258.2721 443.0044,-258.417 443.0045,-258.5619\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.5025,-251.6107 443.0052,-261.6098 446.5025,-251.6088 439.5025,-251.6107\"/>\n</g>\n<!-- self_att_output2 -->\n<g id=\"node17\" class=\"node\">\n<title>self_att_output2</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M533,-258C533,-258 503,-258 503,-258 497,-258 491,-252 491,-246 491,-246 491,-234 491,-234 491,-228 497,-222 503,-222 503,-222 533,-222 533,-222 539,-222 545,-228 545,-234 545,-234 545,-246 545,-246 545,-252 539,-258 533,-258\"/>\n<text text-anchor=\"middle\" x=\"518\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- self_attention2&#45;&gt;self_att_output2 -->\n<g id=\"edge14\" class=\"edge\">\n<title>self_attention2-&gt;self_att_output2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M476.9942,-261.8726C478.5928,-261.0199 480.1999,-260.1626 481.8039,-259.3071\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"483.6977,-262.2637 490.8737,-254.4692 480.4032,-256.0874 483.6977,-262.2637\"/>\n</g>\n<!-- self_att_output2&#45;&gt;add_norm_input2 -->\n<g id=\"edge17\" class=\"edge\">\n<title>self_att_output2-&gt;add_norm_input2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M528.1833,-221.7772C532.0594,-214.841 536.5646,-206.7791 540.806,-199.1893\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"543.9656,-200.7099 545.7886,-190.2731 537.855,-197.2951 543.9656,-200.7099\"/>\n</g>\n<!-- ffnn_input2 -->\n<g id=\"node18\" class=\"node\">\n<title>ffnn_input2</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M768,-298C768,-298 738,-298 738,-298 732,-298 726,-292 726,-286 726,-286 726,-274 726,-274 726,-268 732,-262 738,-262 738,-262 768,-262 768,-262 774,-262 780,-268 780,-274 780,-274 780,-286 780,-286 780,-292 774,-298 768,-298\"/>\n<text text-anchor=\"middle\" x=\"753\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- ffnn2 -->\n<g id=\"node19\" class=\"node\">\n<title>ffnn2</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M710.991,-298C710.991,-298 623.003,-298 623.003,-298 617.003,-298 611.003,-292 611.003,-286 611.003,-286 611.003,-274 611.003,-274 611.003,-268 617.003,-262 623.003,-262 623.003,-262 710.991,-262 710.991,-262 716.991,-262 722.991,-268 722.991,-274 722.991,-274 722.991,-286 722.991,-286 722.991,-292 716.991,-298 710.991,-298\"/>\n<text text-anchor=\"middle\" x=\"666.997\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<!-- ffnn_input2&#45;&gt;ffnn2 -->\n<g id=\"edge15\" class=\"edge\">\n<title>ffnn_input2-&gt;ffnn2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M725.7881,-280C725.6774,-280 725.5665,-280 725.4555,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"733.1015,-276.5004 723.1014,-280 733.1012,-283.5004 733.1015,-276.5004\"/>\n</g>\n<!-- ffnn_output2 -->\n<g id=\"node20\" class=\"node\">\n<title>ffnn_output2</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M681,-258C681,-258 651,-258 651,-258 645,-258 639,-252 639,-246 639,-246 639,-234 639,-234 639,-228 645,-222 651,-222 651,-222 681,-222 681,-222 687,-222 693,-228 693,-234 693,-234 693,-246 693,-246 693,-252 687,-258 681,-258\"/>\n<text text-anchor=\"middle\" x=\"666\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- ffnn2&#45;&gt;ffnn_output2 -->\n<g id=\"edge16\" class=\"edge\">\n<title>ffnn2-&gt;ffnn_output2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M666.5452,-261.8726C666.5416,-261.7279 666.538,-261.583 666.5343,-261.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"670.2068,-268.2998 666.4584,-258.3902 663.209,-268.4744 670.2068,-268.2998\"/>\n</g>\n<!-- ffnn_output2&#45;&gt;add_norm_input2 -->\n<g id=\"edge18\" class=\"edge\">\n<title>ffnn_output2-&gt;add_norm_input2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M638.809,-223.191C624.6622,-214.4457 607.1843,-203.6412 591.937,-194.2156\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"593.6058,-191.1325 583.2594,-188.8513 589.925,-197.0866 593.6058,-191.1325\"/>\n</g>\n<!-- add_norm2 -->\n<g id=\"node22\" class=\"node\">\n<title>add_norm2</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M513.0108,-190C513.0108,-190 430.9964,-190 430.9964,-190 424.9964,-190 418.9964,-184 418.9964,-178 418.9964,-178 418.9964,-166 418.9964,-166 418.9964,-160 424.9964,-154 430.9964,-154 430.9964,-154 513.0108,-154 513.0108,-154 519.0108,-154 525.0108,-160 525.0108,-166 525.0108,-166 525.0108,-178 525.0108,-178 525.0108,-184 519.0108,-190 513.0108,-190\"/>\n<text text-anchor=\"middle\" x=\"472.0036\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<!-- add_norm_input2&#45;&gt;add_norm2 -->\n<g id=\"edge19\" class=\"edge\">\n<title>add_norm_input2-&gt;add_norm2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M528.9607,-172C528.8048,-172 528.6486,-172 528.4921,-172\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"535.1646,-168.5003 525.1644,-172 535.1643,-175.5003 535.1646,-168.5003\"/>\n</g>\n<!-- add_norm_output2 -->\n<g id=\"node23\" class=\"node\">\n<title>add_norm_output2</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M487,-150C487,-150 457,-150 457,-150 451,-150 445,-144 445,-138 445,-138 445,-126 445,-126 445,-120 451,-114 457,-114 457,-114 487,-114 487,-114 493,-114 499,-120 499,-126 499,-126 499,-138 499,-138 499,-144 493,-150 487,-150\"/>\n<text text-anchor=\"middle\" x=\"472\" y=\"-128.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- add_norm2&#45;&gt;add_norm_output2 -->\n<g id=\"edge20\" class=\"edge\">\n<title>add_norm2-&gt;add_norm_output2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M472.002,-153.8726C472.002,-153.7279 472.0019,-153.583 472.0019,-153.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"475.5029,-160.3898 472.0017,-150.3902 468.5029,-160.3907 475.5029,-160.3898\"/>\n</g>\n<!-- add_norm_input3 -->\n<g id=\"node35\" class=\"node\">\n<title>add_norm_input3</title>\n<path fill=\"#ffffe0\" stroke=\"#000000\" d=\"M238.5496,-106C238.5496,-106 152.8164,-106 152.8164,-106 146.8164,-106 140.8164,-100 140.8164,-94 140.8164,-94 140.8164,-82 140.8164,-82 140.8164,-76 146.8164,-70 152.8164,-70 152.8164,-70 238.5496,-70 238.5496,-70 244.5496,-70 250.5496,-76 250.5496,-82 250.5496,-82 250.5496,-94 250.5496,-94 250.5496,-100 244.5496,-106 238.5496,-106\"/>\n<text text-anchor=\"middle\" x=\"195.683\" y=\"-84.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">add_norm_input3</text>\n</g>\n<!-- add_norm_output2&#45;&gt;add_norm_input3 -->\n<!-- self_att_qN -->\n<g id=\"node24\" class=\"node\">\n<title>self_att_qN</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M984,-298C984,-298 954,-298 954,-298 948,-298 942,-292 942,-286 942,-286 942,-274 942,-274 942,-268 948,-262 954,-262 954,-262 984,-262 984,-262 990,-262 996,-268 996,-274 996,-274 996,-286 996,-286 996,-292 990,-298 984,-298\"/>\n<text text-anchor=\"middle\" x=\"969\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Q</text>\n</g>\n<!-- self_attentionN -->\n<g id=\"node27\" class=\"node\">\n<title>self_attentionN</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M868.0288,-298C868.0288,-298 803.9904,-298 803.9904,-298 797.9904,-298 791.9904,-292 791.9904,-286 791.9904,-286 791.9904,-274 791.9904,-274 791.9904,-268 797.9904,-262 803.9904,-262 803.9904,-262 868.0288,-262 868.0288,-262 874.0288,-262 880.0288,-268 880.0288,-274 880.0288,-274 880.0288,-286 880.0288,-286 880.0288,-292 874.0288,-298 868.0288,-298\"/>\n<text text-anchor=\"middle\" x=\"836.0096\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Self-Attention</text>\n</g>\n<!-- self_att_qN&#45;&gt;self_attentionN -->\n<g id=\"edge21\" class=\"edge\">\n<title>self_att_qN-&gt;self_attentionN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M941.7665,-280C926.9652,-280 908.1204,-280 890.4505,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"890.2221,-276.5001 880.222,-280 890.222,-283.5001 890.2221,-276.5001\"/>\n</g>\n<!-- self_att_kN -->\n<g id=\"node25\" class=\"node\">\n<title>self_att_kN</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M926,-298C926,-298 896,-298 896,-298 890,-298 884,-292 884,-286 884,-286 884,-274 884,-274 884,-268 890,-262 896,-262 896,-262 926,-262 926,-262 932,-262 938,-268 938,-274 938,-274 938,-286 938,-286 938,-292 932,-298 926,-298\"/>\n<text text-anchor=\"middle\" x=\"911\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">K</text>\n</g>\n<!-- self_att_kN&#45;&gt;self_attentionN -->\n<g id=\"edge22\" class=\"edge\">\n<title>self_att_kN-&gt;self_attentionN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M883.9267,-280C883.7694,-280 883.6118,-280 883.454,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"890.1063,-276.5003 880.1062,-280 890.1061,-283.5003 890.1063,-276.5003\"/>\n</g>\n<!-- self_att_vN -->\n<g id=\"node26\" class=\"node\">\n<title>self_att_vN</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M851,-258C851,-258 821,-258 821,-258 815,-258 809,-252 809,-246 809,-246 809,-234 809,-234 809,-228 815,-222 821,-222 821,-222 851,-222 851,-222 857,-222 863,-228 863,-234 863,-234 863,-246 863,-246 863,-252 857,-258 851,-258\"/>\n<text text-anchor=\"middle\" x=\"836\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">V</text>\n</g>\n<!-- self_att_vN&#45;&gt;self_attentionN -->\n<g id=\"edge23\" class=\"edge\">\n<title>self_att_vN-&gt;self_attentionN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M836.0044,-258.1274C836.0044,-258.2721 836.0044,-258.417 836.0045,-258.5619\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"832.5025,-251.6107 836.0052,-261.6098 839.5025,-251.6088 832.5025,-251.6107\"/>\n</g>\n<!-- self_att_outputN -->\n<g id=\"node28\" class=\"node\">\n<title>self_att_outputN</title>\n<path fill=\"#ffa07a\" stroke=\"#000000\" d=\"M926,-258C926,-258 896,-258 896,-258 890,-258 884,-252 884,-246 884,-246 884,-234 884,-234 884,-228 890,-222 896,-222 896,-222 926,-222 926,-222 932,-222 938,-228 938,-234 938,-234 938,-246 938,-246 938,-252 932,-258 926,-258\"/>\n<text text-anchor=\"middle\" x=\"911\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- self_attentionN&#45;&gt;self_att_outputN -->\n<g id=\"edge24\" class=\"edge\">\n<title>self_attentionN-&gt;self_att_outputN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M869.9942,-261.8726C871.5928,-261.0199 873.1999,-260.1626 874.8039,-259.3071\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"876.6977,-262.2637 883.8737,-254.4692 873.4032,-256.0874 876.6977,-262.2637\"/>\n</g>\n<!-- add_norm_inputN -->\n<g id=\"node32\" class=\"node\">\n<title>add_norm_inputN</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M964,-190C964,-190 934,-190 934,-190 928,-190 922,-184 922,-178 922,-178 922,-166 922,-166 922,-160 928,-154 934,-154 934,-154 964,-154 964,-154 970,-154 976,-160 976,-166 976,-166 976,-178 976,-178 976,-184 970,-190 964,-190\"/>\n<text text-anchor=\"middle\" x=\"949\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- self_att_outputN&#45;&gt;add_norm_inputN -->\n<g id=\"edge27\" class=\"edge\">\n<title>self_att_outputN-&gt;add_norm_inputN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M921.1833,-221.7772C925.0594,-214.841 929.5646,-206.7791 933.806,-199.1893\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"936.9656,-200.7099 938.7886,-190.2731 930.855,-197.2951 936.9656,-200.7099\"/>\n</g>\n<!-- ffnn_inputN -->\n<g id=\"node29\" class=\"node\">\n<title>ffnn_inputN</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M1161,-298C1161,-298 1131,-298 1131,-298 1125,-298 1119,-292 1119,-286 1119,-286 1119,-274 1119,-274 1119,-268 1125,-262 1131,-262 1131,-262 1161,-262 1161,-262 1167,-262 1173,-268 1173,-274 1173,-274 1173,-286 1173,-286 1173,-292 1167,-298 1161,-298\"/>\n<text text-anchor=\"middle\" x=\"1146\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- ffnnN -->\n<g id=\"node30\" class=\"node\">\n<title>ffnnN</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M1103.991,-298C1103.991,-298 1016.003,-298 1016.003,-298 1010.003,-298 1004.003,-292 1004.003,-286 1004.003,-286 1004.003,-274 1004.003,-274 1004.003,-268 1010.003,-262 1016.003,-262 1016.003,-262 1103.991,-262 1103.991,-262 1109.991,-262 1115.991,-268 1115.991,-274 1115.991,-274 1115.991,-286 1115.991,-286 1115.991,-292 1109.991,-298 1103.991,-298\"/>\n<text text-anchor=\"middle\" x=\"1059.997\" y=\"-276.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Feed-Forward NN</text>\n</g>\n<!-- ffnn_inputN&#45;&gt;ffnnN -->\n<g id=\"edge25\" class=\"edge\">\n<title>ffnn_inputN-&gt;ffnnN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1118.7881,-280C1118.6774,-280 1118.5665,-280 1118.4555,-280\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1126.1015,-276.5004 1116.1014,-280 1126.1012,-283.5004 1126.1015,-276.5004\"/>\n</g>\n<!-- ffnn_outputN -->\n<g id=\"node31\" class=\"node\">\n<title>ffnn_outputN</title>\n<path fill=\"#ffb6c1\" stroke=\"#000000\" d=\"M1074,-258C1074,-258 1044,-258 1044,-258 1038,-258 1032,-252 1032,-246 1032,-246 1032,-234 1032,-234 1032,-228 1038,-222 1044,-222 1044,-222 1074,-222 1074,-222 1080,-222 1086,-228 1086,-234 1086,-234 1086,-246 1086,-246 1086,-252 1080,-258 1074,-258\"/>\n<text text-anchor=\"middle\" x=\"1059\" y=\"-236.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- ffnnN&#45;&gt;ffnn_outputN -->\n<g id=\"edge26\" class=\"edge\">\n<title>ffnnN-&gt;ffnn_outputN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1059.5452,-261.8726C1059.5416,-261.7279 1059.538,-261.583 1059.5343,-261.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1063.2068,-268.2998 1059.4584,-258.3902 1056.209,-268.4744 1063.2068,-268.2998\"/>\n</g>\n<!-- ffnn_outputN&#45;&gt;add_norm_inputN -->\n<g id=\"edge28\" class=\"edge\">\n<title>ffnn_outputN-&gt;add_norm_inputN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1031.809,-223.191C1017.6622,-214.4457 1000.1843,-203.6412 984.937,-194.2156\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"986.6058,-191.1325 976.2594,-188.8513 982.925,-197.0866 986.6058,-191.1325\"/>\n</g>\n<!-- add_normN -->\n<g id=\"node33\" class=\"node\">\n<title>add_normN</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M906.0108,-190C906.0108,-190 823.9964,-190 823.9964,-190 817.9964,-190 811.9964,-184 811.9964,-178 811.9964,-178 811.9964,-166 811.9964,-166 811.9964,-160 817.9964,-154 823.9964,-154 823.9964,-154 906.0108,-154 906.0108,-154 912.0108,-154 918.0108,-160 918.0108,-166 918.0108,-166 918.0108,-178 918.0108,-178 918.0108,-184 912.0108,-190 906.0108,-190\"/>\n<text text-anchor=\"middle\" x=\"865.0036\" y=\"-168.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Add &amp; Normalize</text>\n</g>\n<!-- add_norm_inputN&#45;&gt;add_normN -->\n<g id=\"edge29\" class=\"edge\">\n<title>add_norm_inputN-&gt;add_normN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M921.9607,-172C921.8048,-172 921.6486,-172 921.4921,-172\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"928.1646,-168.5003 918.1644,-172 928.1643,-175.5003 928.1646,-168.5003\"/>\n</g>\n<!-- add_norm_outputN -->\n<g id=\"node34\" class=\"node\">\n<title>add_norm_outputN</title>\n<path fill=\"#d3d3d3\" stroke=\"#000000\" d=\"M880,-150C880,-150 850,-150 850,-150 844,-150 838,-144 838,-138 838,-138 838,-126 838,-126 838,-120 844,-114 850,-114 850,-114 880,-114 880,-114 886,-114 892,-120 892,-126 892,-126 892,-138 892,-138 892,-144 886,-150 880,-150\"/>\n<text text-anchor=\"middle\" x=\"865\" y=\"-128.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- add_normN&#45;&gt;add_norm_outputN -->\n<g id=\"edge30\" class=\"edge\">\n<title>add_normN-&gt;add_norm_outputN</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M865.002,-153.8726C865.002,-153.7279 865.0019,-153.583 865.0019,-153.4381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"868.5029,-160.3898 865.0017,-150.3902 861.5029,-160.3907 868.5029,-160.3898\"/>\n</g>\n<!-- output_tokens -->\n<g id=\"node37\" class=\"node\">\n<title>output_tokens</title>\n<path fill=\"#add8e6\" stroke=\"#000000\" d=\"M1267.5427,-229C1267.5427,-229 1197.1521,-229 1197.1521,-229 1191.1521,-229 1185.1521,-223 1185.1521,-217 1185.1521,-217 1185.1521,-205 1185.1521,-205 1185.1521,-199 1191.1521,-193 1197.1521,-193 1197.1521,-193 1267.5427,-193 1267.5427,-193 1273.5427,-193 1279.5427,-199 1279.5427,-205 1279.5427,-205 1279.5427,-217 1279.5427,-217 1279.5427,-223 1273.5427,-229 1267.5427,-229\"/>\n<text text-anchor=\"middle\" x=\"1232.3474\" y=\"-207.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">Output Tokens</text>\n</g>\n<!-- add_norm_outputN&#45;&gt;output_tokens -->\n<g id=\"edge35\" class=\"edge\">\n<title>add_norm_outputN-&gt;output_tokens</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M892.0119,-137.8091C951.4391,-150.5892 1094.6144,-181.3798 1175.0438,-198.6765\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1174.4954,-202.1386 1185.0078,-200.8194 1175.9672,-195.295 1174.4954,-202.1386\"/>\n<text text-anchor=\"middle\" x=\"1067.9808\" y=\"-171.2428\" font-family=\"Arial\" font-size=\"10.00\" fill=\"#000000\">Linear Mapping</text>\n</g>\n<!-- &#45;1 -->\n<g id=\"node36\" class=\"node\">\n<title>-1</title>\n<path fill=\"#ffffe0\" stroke=\"#000000\" d=\"M604,-106C604,-106 574,-106 574,-106 568,-106 562,-100 562,-94 562,-94 562,-82 562,-82 562,-76 568,-70 574,-70 574,-70 604,-70 604,-70 610,-70 616,-76 616,-82 616,-82 616,-94 616,-94 616,-100 610,-106 604,-106\"/>\n<text text-anchor=\"middle\" x=\"589\" y=\"-84.4\" font-family=\"Arial\" font-size=\"12.00\" fill=\"#000000\">-1</text>\n</g>\n<!-- &#45;1&#45;&gt;add_norm_inputN -->\n</g>\n</svg>"},"metadata":{}}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nExtracting the train and test sets using 7z command line tool</div>","metadata":{}},{"cell_type":"code","source":"!7z x /kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z\n!7z x /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:14:46.831020Z","iopub.execute_input":"2023-06-10T21:14:46.831311Z","iopub.status.idle":"2023-06-10T21:14:57.431837Z","shell.execute_reply.started":"2023-06-10T21:14:46.831285Z","shell.execute_reply":"2023-06-10T21:14:57.430618Z"},"_kg_hide-output":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n\nScanning the drive for archives:\n  0M Scan /kaggle/input/mercari-price-suggestion-challenge                                                          1 file, 35617013 bytes (34 MiB)\n\nExtracting archive: /kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z\n--\nPath = /kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z\nType = 7z\nPhysical Size = 35617013\nHeaders Size = 122\nMethod = LZMA2:24\nSolid = -\nBlocks = 1\n\n      8% - test.ts               14% - test.ts               21% - test.ts               32% - test.ts               40% - test.ts               48% - test.ts               57% - test.ts               64% - test.ts               73% - test.ts               81% - test.ts               87% - test.ts               94% - test.ts              Everything is Ok\n\nSize:       154222160\nCompressed: 35617013\n\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n\nScanning the drive for archives:\n  0M Scan /kaggle/input/mercari-price-suggestion-challenge                                                          1 file, 77912192 bytes (75 MiB)\n\nExtracting archive: /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z\n--\nPath = /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z\nType = 7z\nPhysical Size = 77912192\nHeaders Size = 122\nMethod = LZMA2:24\nSolid = -\nBlocks = 1\n\n      2% - train.t                6% - train.t                9% - train.t               13% - train.t               17% - train.t               21% - train.t               24% - train.t               29% - train.t               32% - train.t               36% - train.t               39% - train.t               43% - train.t               48% - train.t               52% - train.t               55% - train.t               60% - train.t               64% - train.t               68% - train.t               72% - train.t               75% - train.t               80% - train.t               84% - train.t               88% - train.t               92% - train.t               96% - train.t              Everything is Ok\n\nSize:       337809843\nCompressed: 77912192\n","output_type":"stream"}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nThis code snippet imports the necessary libraries and modules for deep learning model training using Electra.</div>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import ElectraTokenizer, ElectraForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:14:57.434149Z","iopub.execute_input":"2023-06-10T21:14:57.434477Z","iopub.status.idle":"2023-06-10T21:15:11.373059Z","shell.execute_reply.started":"2023-06-10T21:14:57.434448Z","shell.execute_reply":"2023-06-10T21:15:11.372113Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nThese lines of code set the random seed for reproducibility.</div>","metadata":{}},{"cell_type":"code","source":"# Set the random seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:11.374390Z","iopub.execute_input":"2023-06-10T21:15:11.374715Z","iopub.status.idle":"2023-06-10T21:15:11.383870Z","shell.execute_reply.started":"2023-06-10T21:15:11.374685Z","shell.execute_reply":"2023-06-10T21:15:11.382981Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nThese lines of code load the train and test sets</div>","metadata":{}},{"cell_type":"code","source":"# Load the training and test data\ntrain_df = pd.read_csv('/kaggle/working/train.tsv', delimiter='\\t')\ntest_df = pd.read_csv('/kaggle/working/test.tsv', delimiter='\\t')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:11.386588Z","iopub.execute_input":"2023-06-10T21:15:11.387503Z","iopub.status.idle":"2023-06-10T21:15:19.587891Z","shell.execute_reply.started":"2023-06-10T21:15:11.387468Z","shell.execute_reply":"2023-06-10T21:15:19.586897Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nRemoving rows with missing values </div>","metadata":{}},{"cell_type":"code","source":"train_df = train_df.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:19.589494Z","iopub.execute_input":"2023-06-10T21:15:19.589857Z","iopub.status.idle":"2023-06-10T21:15:21.339507Z","shell.execute_reply.started":"2023-06-10T21:15:19.589824Z","shell.execute_reply":"2023-06-10T21:15:21.338542Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nSplit the data into training and validation sets\n </div>","metadata":{}},{"cell_type":"code","source":"train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=seed)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:21.342074Z","iopub.execute_input":"2023-06-10T21:15:21.342459Z","iopub.status.idle":"2023-06-10T21:15:21.622392Z","shell.execute_reply.started":"2023-06-10T21:15:21.342424Z","shell.execute_reply":"2023-06-10T21:15:21.621406Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nDefining the tokenizer\n </div>","metadata":{}},{"cell_type":"code","source":"tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:21.623915Z","iopub.execute_input":"2023-06-10T21:15:21.624357Z","iopub.status.idle":"2023-06-10T21:15:22.718813Z","shell.execute_reply.started":"2023-06-10T21:15:21.624322Z","shell.execute_reply":"2023-06-10T21:15:22.717926Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"085c061435f34ef79d5bbe313a296667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d349f76e1b114521a7aceae2b28893d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ac0db1d521a43da885b41ee21c29586"}},"metadata":{}}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nFunction to tokenize the data\n </div>","metadata":{}},{"cell_type":"code","source":"def tokenize_data(text):\n    return tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=256,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:22.720145Z","iopub.execute_input":"2023-06-10T21:15:22.720618Z","iopub.status.idle":"2023-06-10T21:15:22.727562Z","shell.execute_reply.started":"2023-06-10T21:15:22.720584Z","shell.execute_reply":"2023-06-10T21:15:22.726658Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nCreating dataset class for training and validation split </div>","metadata":{}},{"cell_type":"code","source":"class MercariDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        text = row['name'] + ' ' + row['item_description']\n        inputs = tokenize_data(text)\n        label = row['price']\n        return {\n            'input_ids': inputs['input_ids'].squeeze(),\n            'attention_mask': inputs['attention_mask'].squeeze(),\n            'label': torch.tensor(label, dtype=torch.float32)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:22.728857Z","iopub.execute_input":"2023-06-10T21:15:22.729763Z","iopub.status.idle":"2023-06-10T21:15:22.738802Z","shell.execute_reply.started":"2023-06-10T21:15:22.729730Z","shell.execute_reply":"2023-06-10T21:15:22.737765Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nDefining batch size and dataloaders </div>","metadata":{}},{"cell_type":"code","source":"batch_size = 32\ntrain_dataset = MercariDataset(train_data)\nval_dataset = MercariDataset(val_data)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:22.742425Z","iopub.execute_input":"2023-06-10T21:15:22.742707Z","iopub.status.idle":"2023-06-10T21:15:22.751071Z","shell.execute_reply.started":"2023-06-10T21:15:22.742685Z","shell.execute_reply":"2023-06-10T21:15:22.749998Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nPerforming sanity check of the dataloaders </div>","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:22.752505Z","iopub.execute_input":"2023-06-10T21:15:22.752890Z","iopub.status.idle":"2023-06-10T21:15:22.977302Z","shell.execute_reply.started":"2023-06-10T21:15:22.752859Z","shell.execute_reply":"2023-06-10T21:15:22.976347Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[  101,  2417,  2152,  ...,     0,     0,     0],\n        [  101,  6954,  2072,  ...,     0,     0,     0],\n        [  101, 21994, 19457,  ...,     0,     0,     0],\n        ...,\n        [  101,  2047,  2141,  ...,     0,     0,     0],\n        [  101,  1038,  2989,  ...,     0,     0,     0],\n        [  101,  9212,  2884,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([ 46.,   3.,  30.,  37.,  20.,  17.,  10.,  31.,  10., 895.,  19.,  61.,\n         14.,  96.,  90.,  23.,  13.,  74.,  19.,  26., 525.,  41.,   8.,  11.,\n         24.,  16.,  30.,  46.,  20.,  20.,  26.,  50.])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nInstantiating the Electra model </div>","metadata":{}},{"cell_type":"code","source":"model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:22.978746Z","iopub.execute_input":"2023-06-10T21:15:22.979296Z","iopub.status.idle":"2023-06-10T21:15:26.600617Z","shell.execute_reply.started":"2023-06-10T21:15:22.979260Z","shell.execute_reply":"2023-06-10T21:15:26.599575Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf251a65359479a8df73ec5bd06e67b"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nDefining the loss function and optimizer </div>","metadata":{}},{"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:26.602284Z","iopub.execute_input":"2023-06-10T21:15:26.602925Z","iopub.status.idle":"2023-06-10T21:15:26.610823Z","shell.execute_reply.started":"2023-06-10T21:15:26.602886Z","shell.execute_reply":"2023-06-10T21:15:26.609779Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nChecking the length of dataloaders to estimate number of steps per epoch </div>","metadata":{}},{"cell_type":"code","source":"len(train_loader), len(val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:26.612268Z","iopub.execute_input":"2023-06-10T21:15:26.613352Z","iopub.status.idle":"2023-06-10T21:15:26.627007Z","shell.execute_reply.started":"2023-06-10T21:15:26.613315Z","shell.execute_reply":"2023-06-10T21:15:26.626022Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(21175, 5294)"},"metadata":{}}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nThis code block trains a model using a loop that iterates over a specified number of epochs. It uses the tqdm library to display a progress bar during training. The model is trained on a GPU if available; otherwise, it falls back to CPU.<br>\n\nWithin each epoch, the code iterates over the train_loader to process batches of training data. It moves the input data and labels to the appropriate device (GPU or CPU) and performs forward and backward passes through the model. The optimizer is used to update the model's parameters based on the computed gradients. The training loss is accumulated and averaged over the entire training dataset.<br>\n\nAfter each epoch's training, the code enters the evaluation phase on the validation set (val_loader). It iterates over the validation batches, performs forward passes through the model, and calculates the loss. The validation loss is accumulated and averaged over the entire validation dataset.<br>\n\nAt the end of each epoch, the code prints the epoch number, the training loss, and the validation loss.<br></div>","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Train the model\nnum_epochs = 1\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    for step,batch in tqdm(enumerate(train_loader)):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        print(step)\n        if step%500==0:\n            print(\"Step-{}, Loss-{}\".format(step,loss.item()))\n            break # breaking the training at 500th step since 1 iteration may take around 5 hrs, Uncomment this during full training\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * input_ids.size(0)\n    \n    train_loss /= len(train_dataset)\n    \n    # Evaluate on the validation set\n    model.eval()\n    val_loss = 0.0\n    \n    with torch.no_grad():\n        for step,batch in tqdm(enumerate(val_loader)):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            \n            val_loss += loss.item() * input_ids.size(0)\n    \n    val_loss /= len(val_dataset)\n    \n    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}')\n\n#intentional keyboard interrupt since training will take long, Train more as per your need.","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:15:26.628784Z","iopub.execute_input":"2023-06-10T21:15:26.629208Z","iopub.status.idle":"2023-06-10T21:28:43.359954Z","shell.execute_reply.started":"2023-06-10T21:15:26.629166Z","shell.execute_reply":"2023-06-10T21:28:43.358444Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"0it [00:01, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"0\nStep-0, Loss-1081.6334228515625\n","output_type":"stream"},{"name":"stderr","text":"2592it [13:08,  3.29it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     43\u001b[0m         loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 45\u001b[0m         val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m val_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_dataset)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":" <div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nThe code provided is used to generate predictions on the test set using a pre-trained model and create a submission file for a competition.<br>\n    \nFirstly, a dataset class for test set is created by removing the labels.<br>\n\nThe model is then put into evaluation mode using `model.eval()`, and predictions are generated for each batch in the test loader. The input tensors (`input_ids` and `attention_mask`) are moved to the appropriate device using `.to(device)`.<br>\n\nThe model's forward pass is executed with the input tensors, and the output logits are obtained from `outputs.logits`. The logits are then flattened, converted to NumPy arrays on the CPU, and appended to the `predictions` list.<br>\n\nOnce all the predictions are generated, a submission DataFrame is created with columns for `test_id` (assuming it's available in `test_df`) and `price`, using the `predictions` list. Finally, the submission DataFrame is saved as a CSV file called 'submission.csv' without including an index.<br></div>\n\n","metadata":{}},{"cell_type":"code","source":"# Create PyTorch DataLoader for test sets\nclass MercariTestDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        text = row['name'] + ' ' + row['item_description']\n        inputs = tokenize_data(text)\n        return {\n            'input_ids': inputs['input_ids'].squeeze(),\n            'attention_mask': inputs['attention_mask'].squeeze(),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:30:21.920487Z","iopub.execute_input":"2023-06-10T21:30:21.920876Z","iopub.status.idle":"2023-06-10T21:30:21.928884Z","shell.execute_reply.started":"2023-06-10T21:30:21.920843Z","shell.execute_reply":"2023-06-10T21:30:21.927935Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Load the test data and create a DataLoader\ntest_dataset = MercariTestDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128*8)\n\n# Generate predictions on the test set\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        predictions.extend(logits.flatten().cpu().numpy())\n\n\n#intentional keyboard interrupt since training will take long\n# Create the submission file\nsubmission_df = pd.DataFrame({'test_id': test_df['test_id'], 'price': predictions})\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:30:27.449189Z","iopub.execute_input":"2023-06-10T21:30:27.449649Z","iopub.status.idle":"2023-06-10T21:31:17.707720Z","shell.execute_reply.started":"2023-06-10T21:30:27.449613Z","shell.execute_reply":"2023-06-10T21:31:17.706426Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"  1%|          | 4/678 [00:50<2:20:54, 12.54s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m     15\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m---> 17\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create the submission file\u001b[39;00m\n\u001b[1;32m     20\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_id\u001b[39m\u001b[38;5;124m'\u001b[39m: test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions})\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}