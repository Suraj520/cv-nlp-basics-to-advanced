{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#035FCA; color:#19180F; font-size:40px; font-family:Verdana; padding:10px; border: 1px solid #19180F; border-radius:10px\"> ProphetNet </div>\n\n<div style=\"background-color:#BFD4F3; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 1px solid #19180F;border-radius:10px\">üîß Architecture Overview‚öôÔ∏è</div>\n </div>\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 1px solid #19180F;border-radius:10px\">\nThe architecture consists of two main components: the encoder and the decoder.<br>\n    1. <b>Encoder</b>: The encoder analyses an input sequence, often a source language sequence, to collect contextual information. The \"enc_input\" sequence in the figure represents the input sequence, which might be tokenized text or any other sequential data. The encoder then encodes the data, as indicated by the arrow pointing from \"enc_input\" to \"enc_output.\" To capture hierarchical and contextual information, the input sequence is processed through various layers of neural network units, such as transformers or recurrent neural networks (RNNs). The \"enc_output\" variable represents the encoder's final output, which contains the encoded representation of the input sequence.<br><br>\n2. <b>Decoder</b>: The decoder takes the encoded representation from the encoder and creates an output sequence, which is often the target language sequence or a model-generated sequence. The \"dec_input\" in the figure indicates the decoder's input, which is normally a specific token signifying the start of the sequence. The decoder subsequently decodes the data, as indicated by the arrow pointing from \"dec_input\" to \"dec_output.\" Similar to the encoder, this stage includes processing the input sequence via numerous layers of neural network units with the goal of creating the target sequence. The \"dec_output\" variable represents the decoder's final output, which contains the created or translated sequence.<br><br>\nAdditionally, there are some additional components and connections in the architecture:<br>\n- <b>Input Data and Output Data</b>: These nodes reflect the ProphetNet model's input and output data. The \"input_data\" node represents the sequence or data supplied into the encoder, while the \"output_data\" node represents the decoder's created or translated sequence.<br>\n- <b>Future N-gram prediction</b>: This component, represented by the \"future_ngram\" node, represents the model's capacity to anticipate future tokens based on context. It takes the encoded representation from the encoder and predicts tokens, which are subsequently supplied into the decoder during the decoding process.<br>\n<br>\nOverall, the ProphetNet architecture uses the encoding and decoding phases, as well as future token prediction, to construct high-quality and contextually coherent sequences for different sequence-to-sequence activities such as language production and translation.</div>\n\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import SVG, display\n\n# Load the SVG file and display it\nsvg_file = '/kaggle/input/notebook-images/prophetnet.svg'\ndisplay(SVG(filename=svg_file))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T09:36:34.616215Z","iopub.execute_input":"2023-06-17T09:36:34.616506Z","iopub.status.idle":"2023-06-17T09:36:34.641959Z","shell.execute_reply.started":"2023-06-17T09:36:34.616479Z","shell.execute_reply":"2023-06-17T09:36:34.641113Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"204pt\" height=\"707pt\" viewBox=\"0.00 0.00 203.97 707.40\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 703.4)\">\n<title>prophetnet</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-703.4 199.97,-703.4 199.97,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"97.985\" y=\"-8.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ProphetNet Architecture</text>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_encoder</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"19.3128,-417 19.3128,-620.6 141.3128,-620.6 141.3128,-417 19.3128,-417\"/>\n<text text-anchor=\"middle\" x=\"80.3128\" y=\"-604\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_decoder</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"20.3128,-105.6 20.3128,-309.2 142.3128,-309.2 142.3128,-105.6 20.3128,-105.6\"/>\n<text text-anchor=\"middle\" x=\"81.3128\" y=\"-292.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Decoder</text>\n</g>\n<!-- enc_input -->\n<g id=\"node1\" class=\"node\">\n<title>enc_input</title>\n<path fill=\"#e8f6ff\" stroke=\"#000000\" d=\"M94.3128,-587.8C94.3128,-587.8 64.3128,-587.8 64.3128,-587.8 58.3128,-587.8 52.3128,-581.8 52.3128,-575.8 52.3128,-575.8 52.3128,-563.8 52.3128,-563.8 52.3128,-557.8 58.3128,-551.8 64.3128,-551.8 64.3128,-551.8 94.3128,-551.8 94.3128,-551.8 100.3128,-551.8 106.3128,-557.8 106.3128,-563.8 106.3128,-563.8 106.3128,-575.8 106.3128,-575.8 106.3128,-581.8 100.3128,-587.8 94.3128,-587.8\"/>\n<text text-anchor=\"middle\" x=\"79.3128\" y=\"-565.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- enc_output -->\n<g id=\"node2\" class=\"node\">\n<title>enc_output</title>\n<path fill=\"#e8f6ff\" stroke=\"#000000\" d=\"M120.843,-461C120.843,-461 39.7826,-461 39.7826,-461 33.7826,-461 27.7826,-455 27.7826,-449 27.7826,-449 27.7826,-437 27.7826,-437 27.7826,-431 33.7826,-425 39.7826,-425 39.7826,-425 120.843,-425 120.843,-425 126.843,-425 132.843,-431 132.843,-437 132.843,-437 132.843,-449 132.843,-449 132.843,-455 126.843,-461 120.843,-461\"/>\n<text text-anchor=\"middle\" x=\"80.3128\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoder Output</text>\n</g>\n<!-- enc_input&#45;&gt;enc_output -->\n<g id=\"edge1\" class=\"edge\">\n<title>enc_input-&gt;enc_output</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M79.4561,-551.6327C79.6217,-530.6352 79.8962,-495.8261 80.0898,-471.279\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.5907,-471.161 80.1698,-461.1336 76.5909,-471.1057 83.5907,-471.161\"/>\n<text text-anchor=\"middle\" x=\"106.1417\" y=\"-502.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Encoding</text>\n</g>\n<!-- future_ngram -->\n<g id=\"node7\" class=\"node\">\n<title>future_ngram</title>\n<path fill=\"#ffe082\" stroke=\"#000000\" d=\"M148.4388,-388C148.4388,-388 12.1868,-388 12.1868,-388 6.1868,-388 .1868,-382 .1868,-376 .1868,-376 .1868,-364 .1868,-364 .1868,-358 6.1868,-352 12.1868,-352 12.1868,-352 148.4388,-352 148.4388,-352 154.4388,-352 160.4388,-358 160.4388,-364 160.4388,-364 160.4388,-376 160.4388,-376 160.4388,-382 154.4388,-388 148.4388,-388\"/>\n<text text-anchor=\"middle\" x=\"80.3128\" y=\"-365.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Future N-gram Prediction</text>\n</g>\n<!-- enc_output&#45;&gt;future_ngram -->\n<g id=\"edge5\" class=\"edge\">\n<title>enc_output-&gt;future_ngram</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M80.3128,-424.9551C80.3128,-416.8828 80.3128,-407.1764 80.3128,-398.1817\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.8129,-398.0903 80.3128,-388.0904 76.8129,-398.0904 83.8129,-398.0903\"/>\n</g>\n<!-- dec_input -->\n<g id=\"node3\" class=\"node\">\n<title>dec_input</title>\n<path fill=\"#e8f6ff\" stroke=\"#000000\" d=\"M95.3128,-276.4C95.3128,-276.4 65.3128,-276.4 65.3128,-276.4 59.3128,-276.4 53.3128,-270.4 53.3128,-264.4 53.3128,-264.4 53.3128,-252.4 53.3128,-252.4 53.3128,-246.4 59.3128,-240.4 65.3128,-240.4 65.3128,-240.4 95.3128,-240.4 95.3128,-240.4 101.3128,-240.4 107.3128,-246.4 107.3128,-252.4 107.3128,-252.4 107.3128,-264.4 107.3128,-264.4 107.3128,-270.4 101.3128,-276.4 95.3128,-276.4\"/>\n<text text-anchor=\"middle\" x=\"80.3128\" y=\"-254.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input</text>\n</g>\n<!-- dec_output -->\n<g id=\"node4\" class=\"node\">\n<title>dec_output</title>\n<path fill=\"#e8f6ff\" stroke=\"#000000\" d=\"M122.1118,-149.6C122.1118,-149.6 40.5138,-149.6 40.5138,-149.6 34.5138,-149.6 28.5138,-143.6 28.5138,-137.6 28.5138,-137.6 28.5138,-125.6 28.5138,-125.6 28.5138,-119.6 34.5138,-113.6 40.5138,-113.6 40.5138,-113.6 122.1118,-113.6 122.1118,-113.6 128.1118,-113.6 134.1118,-119.6 134.1118,-125.6 134.1118,-125.6 134.1118,-137.6 134.1118,-137.6 134.1118,-143.6 128.1118,-149.6 122.1118,-149.6\"/>\n<text text-anchor=\"middle\" x=\"81.3128\" y=\"-127.4\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Decoder Output</text>\n</g>\n<!-- dec_input&#45;&gt;dec_output -->\n<g id=\"edge2\" class=\"edge\">\n<title>dec_input-&gt;dec_output</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M80.4561,-240.2327C80.6217,-219.2352 80.8962,-184.4261 81.0898,-159.879\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5907,-159.761 81.1698,-149.7336 77.5909,-159.7057 84.5907,-159.761\"/>\n<text text-anchor=\"middle\" x=\"107.526\" y=\"-190.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Decoding</text>\n</g>\n<!-- output_data -->\n<g id=\"node6\" class=\"node\">\n<title>output_data</title>\n<path fill=\"#b3e5fc\" stroke=\"#000000\" d=\"M111.6272,-60.8C111.6272,-60.8 50.9984,-60.8 50.9984,-60.8 44.9984,-60.8 38.9984,-54.8 38.9984,-48.8 38.9984,-48.8 38.9984,-36.8 38.9984,-36.8 38.9984,-30.8 44.9984,-24.8 50.9984,-24.8 50.9984,-24.8 111.6272,-24.8 111.6272,-24.8 117.6272,-24.8 123.6272,-30.8 123.6272,-36.8 123.6272,-36.8 123.6272,-48.8 123.6272,-48.8 123.6272,-54.8 117.6272,-60.8 111.6272,-60.8\"/>\n<text text-anchor=\"middle\" x=\"81.3128\" y=\"-38.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output Data</text>\n</g>\n<!-- dec_output&#45;&gt;output_data -->\n<g id=\"edge4\" class=\"edge\">\n<title>dec_output-&gt;output_data</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M81.3128,-113.2006C81.3128,-101.0949 81.3128,-85.0076 81.3128,-71.2674\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.8129,-70.872 81.3128,-60.872 77.8129,-70.8721 84.8129,-70.872\"/>\n<text text-anchor=\"middle\" x=\"138.6414\" y=\"-83\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Generated Sequence</text>\n</g>\n<!-- input_data -->\n<g id=\"node5\" class=\"node\">\n<title>input_data</title>\n<path fill=\"#b3e5fc\" stroke=\"#000000\" d=\"M105.2919,-699.4C105.2919,-699.4 53.3337,-699.4 53.3337,-699.4 47.3337,-699.4 41.3337,-693.4 41.3337,-687.4 41.3337,-687.4 41.3337,-675.4 41.3337,-675.4 41.3337,-669.4 47.3337,-663.4 53.3337,-663.4 53.3337,-663.4 105.2919,-663.4 105.2919,-663.4 111.2919,-663.4 117.2919,-669.4 117.2919,-675.4 117.2919,-675.4 117.2919,-687.4 117.2919,-687.4 117.2919,-693.4 111.2919,-699.4 105.2919,-699.4\"/>\n<text text-anchor=\"middle\" x=\"79.3128\" y=\"-677.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Data</text>\n</g>\n<!-- input_data&#45;&gt;enc_input -->\n<g id=\"edge3\" class=\"edge\">\n<title>input_data-&gt;enc_input</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M79.3128,-662.9715C79.3128,-645.339 79.3128,-618.4924 79.3128,-598.1391\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.8129,-597.8855 79.3128,-587.8856 75.8129,-597.8856 82.8129,-597.8855\"/>\n<text text-anchor=\"middle\" x=\"127.3195\" y=\"-632.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Source Sequence</text>\n</g>\n<!-- future_ngram&#45;&gt;dec_input -->\n<g id=\"edge6\" class=\"edge\">\n<title>future_ngram-&gt;dec_input</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M80.3128,-351.5715C80.3128,-333.939 80.3128,-307.0924 80.3128,-286.7391\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.8129,-286.4855 80.3128,-276.4856 76.8129,-286.4856 83.8129,-286.4855\"/>\n<text text-anchor=\"middle\" x=\"129.1028\" y=\"-321.4\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Predicted Tokens</text>\n</g>\n</g>\n</svg>"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Importing modules\n    </div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, ProphetNetModel, AdamW\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:34.757681Z","iopub.execute_input":"2023-06-17T04:46:34.759765Z","iopub.status.idle":"2023-06-17T04:46:40.385011Z","shell.execute_reply.started":"2023-06-17T04:46:34.759734Z","shell.execute_reply":"2023-06-17T04:46:40.384081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Defining the dataset class with train and test modes along with train function and instantiating the model and tokenizer\n    </div>","metadata":{}},{"cell_type":"code","source":"class DisasterTweetDataset(Dataset):\n    def __init__(self, data_path, tokenizer,mode=\"Train\"):\n        self.data = pd.read_csv(data_path)\n        self.tokenizer = tokenizer\n        self.mode = mode\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        tweet = self.data.loc[index, 'text']\n        if self.mode == \"Train\":\n            target = self.data.loc[index, 'target']\n            encoding = self.tokenizer(tweet, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n            input_ids = encoding['input_ids'].squeeze()\n            attention_mask = encoding['attention_mask'].squeeze()\n            return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target': target}\n        elif self.mode==\"Test\":\n            encoding = self.tokenizer(tweet, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n            input_ids = encoding['input_ids'].squeeze()\n            attention_mask = encoding['attention_mask'].squeeze()\n            return {'input_ids': input_ids, 'attention_mask': attention_mask}\n            \n# Define the training function\ndef train(model, train_dataloader, optimizer, device):\n    model.train()\n    total_loss = 0\n    for step,batch in tqdm(enumerate(train_dataloader)):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['target'].to(device)\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=torch.zeros_like(input_ids))\n        logits = outputs.last_hidden_state[:, 0, :]  # Use the first token's representation\n        predictions = torch.argmax(logits, dim=1)\n        \n        loss = criterion(logits, targets)\n        total_loss += loss.item()\n        if step%100==0:\n            print(\"Step-{},Loss-{}\".format(step,loss.item()))\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return total_loss\n\n# Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\nmodel = ProphetNetModel.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:12:24.346476Z","iopub.execute_input":"2023-06-17T06:12:24.346847Z","iopub.status.idle":"2023-06-17T06:12:28.252480Z","shell.execute_reply.started":"2023-06-17T06:12:24.346813Z","shell.execute_reply":"2023-06-17T06:12:28.251439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Setting device\n    </div>","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:44.996168Z","iopub.execute_input":"2023-06-17T04:46:44.996606Z","iopub.status.idle":"2023-06-17T04:46:45.028055Z","shell.execute_reply.started":"2023-06-17T04:46:44.996572Z","shell.execute_reply":"2023-06-17T04:46:45.026863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Loading the dataset\n    </div>","metadata":{}},{"cell_type":"code","source":"train_dataset = DisasterTweetDataset(\"/kaggle/input/nlp-getting-started/train.csv\", tokenizer,mode=\"Train\")\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:45.029556Z","iopub.execute_input":"2023-06-17T04:46:45.029902Z","iopub.status.idle":"2023-06-17T04:46:45.063573Z","shell.execute_reply.started":"2023-06-17T04:46:45.029869Z","shell.execute_reply":"2023-06-17T04:46:45.062661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Checking the length of trainloader to figure out the number of steps per epoch with current batch size.\n    </div>","metadata":{}},{"cell_type":"code","source":"print(len(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:45.065203Z","iopub.execute_input":"2023-06-17T04:46:45.065563Z","iopub.status.idle":"2023-06-17T04:46:45.071035Z","shell.execute_reply.started":"2023-06-17T04:46:45.065531Z","shell.execute_reply":"2023-06-17T04:46:45.069928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Sanity check of the dataloader\n    </div>","metadata":{}},{"cell_type":"code","source":"for batch in train_dataloader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:45.072657Z","iopub.execute_input":"2023-06-17T04:46:45.072994Z","iopub.status.idle":"2023-06-17T04:46:45.143775Z","shell.execute_reply.started":"2023-06-17T04:46:45.072963Z","shell.execute_reply":"2023-06-17T04:46:45.142830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Initialising the optimizer and loss function along with training the model for 5 epochs\n    </div>","metadata":{}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# Train the model\nmodel.to(device)\nfor epoch in range(10):\n    loss = train(model, train_dataloader, optimizer, device)\n    print(f\"Epoch: {epoch+1}, Loss: {loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-17T04:46:45.145114Z","iopub.execute_input":"2023-06-17T04:46:45.145409Z","iopub.status.idle":"2023-06-17T06:09:03.477238Z","shell.execute_reply.started":"2023-06-17T04:46:45.145380Z","shell.execute_reply":"2023-06-17T06:09:03.476245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Train more for better results ! The loss is decreasing across epochs but shall take time !\n    </div>","metadata":{}},{"cell_type":"code","source":"# Save the trained model\nmodel.save_pretrained(\"ProphetNet\")","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:10:13.626351Z","iopub.execute_input":"2023-06-17T06:10:13.626773Z","iopub.status.idle":"2023-06-17T06:10:17.173297Z","shell.execute_reply.started":"2023-06-17T06:10:13.626737Z","shell.execute_reply":"2023-06-17T06:10:17.171251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Loading the test dataset and creating the dataloader\n    </div>","metadata":{}},{"cell_type":"code","source":"# Load the test dataset\ntest_dataset = DisasterTweetDataset(\"/kaggle/input/nlp-getting-started/test.csv\", tokenizer,mode=\"Test\")\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:30:05.568626Z","iopub.execute_input":"2023-06-17T06:30:05.569008Z","iopub.status.idle":"2023-06-17T06:30:05.585907Z","shell.execute_reply.started":"2023-06-17T06:30:05.568977Z","shell.execute_reply":"2023-06-17T06:30:05.585005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in test_dataloader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:26:37.070926Z","iopub.execute_input":"2023-06-17T06:26:37.071291Z","iopub.status.idle":"2023-06-17T06:26:37.081596Z","shell.execute_reply.started":"2023-06-17T06:26:37.071262Z","shell.execute_reply":"2023-06-17T06:26:37.080528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Generating predictions via trained model\n    </div>","metadata":{}},{"cell_type":"code","source":"# Switch to evaluation mode\nmodel.to(device)\nmodel.eval()\n\npredictions = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_dataloader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=torch.zeros_like(input_ids))\n        logits = outputs.last_hidden_state[:, 0, :]  # Use the first token's representation\n        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-17T06:35:35.971696Z","iopub.execute_input":"2023-06-17T06:35:35.972573Z","iopub.status.idle":"2023-06-17T06:38:12.576738Z","shell.execute_reply.started":"2023-06-17T06:35:35.972538Z","shell.execute_reply":"2023-06-17T06:38:12.575284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå CUDA out of memory error, On cpu it takes too much time.\n    </div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nüìå Creating submission file\n    </div>","metadata":{}},{"cell_type":"code","source":"# Create the submission dataframe\nsubmission_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsubmission_df['target'] = predictions\n\n# Save the submission dataframe to a CSV file\nsubmission_df[['id', 'target']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:09:06.140087Z","iopub.status.idle":"2023-06-17T06:09:06.140757Z","shell.execute_reply.started":"2023-06-17T06:09:06.140508Z","shell.execute_reply":"2023-06-17T06:09:06.140532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}