{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#035FCA; color:#19180F; font-size:40px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\"> XLNet(eXtreme Lite Transformer) </div>\n<div style=\"background-color:#568FD1; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\"> üìù Architectural Overview.\n </div>\n<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\n- It is a state of the art llm developed by CMU and Google AI. It is based on transformer architecture and was designed to overcome the limitations of prev language models such as BERT and GPT2.<br>\n- The architecture of XLNet is similar to BERT with some key diff. The main diff being XLNet uses a permutation based training approach which allows it to model dependencies between all tokens in a sequence rather than just the tokens that come before the current token.<br>\n <br>\nThe block diagram of XLNet consists of three main components.\n<br>\n- Input embedding layer - This layer takes the input text and converts it into a vector representation that can be processed by the model. The input embedding layer uses a pretrained word embedding model to convert each word in the input text into a vector.<br>\n- Transformer encoder layers - The transformer encoder layers are the core buiding blocks of the model. They use self attn mechanism to process the input text and generate a contextualised representation of each word in the text. The transformer encoder layers are stacked on top of each other to create a deep neural network.<br>\n- Permutation based training - XLNet uses a permutation based training approach which allows it to model dependencies between all tokens in a sequence rather than just the tokens that come before the current token. This is achieved by randomly permuting the input seq during training and using a modified loss function that takes into account all possible permutations of the input sequence<br>\n<br>\nThe advantages of XLNet are<br>\n1. Improved modeling of dependencies. - It is able to model dependencies between all tokens in a sequence rather than just the tokens that come before it. It yields better and coherent text.<br>\n2. It performs better on Question-answering, sentiment analysis and text classification in comparision to bert and GPT2.<br>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#568FD1; color:#19180F; font-size:30px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\"> üè¢ Architecture Diagram.\n </div>\n<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\n1. Input Layer:<br>\n   - The diagram starts with the \"Input Layer\" represented by the `input` node. It represents the input text that is fed into the XLNet model for processing.\n<br>\n2. Segment Embeddings:<br>\n   - The input text is passed through the \"Segment Embeddings\" layer, represented by the `segment` node. This layer assigns different embeddings to different segments or parts of the input text.\n<br>\n3. Position Embeddings:<br>\n   - The input text is also passed through the \"Position Embeddings\" layer, represented by the `position` node. This layer assigns embeddings based on the position or order of the words in the input text.\n<br>\n4. Attention Layer:<br>\n   - The segment embeddings and position embeddings are combined and fed into the \"Attention Layer,\" represented by the `attention` node. The attention layer performs self-attention, allowing the model to focus on different parts of the input text while considering the dependencies between words.\n<br>\n5. Feed-Forward Layer:<br>\n   - The output from the attention layer is passed through the \"Feed-Forward Layer,\" represented by the `feed_forward` node. This layer applies a neural network with multiple layers and nonlinear transformations to capture complex patterns in the data.\n<br>\n6. Residual Connections and Layer Normalization:<br>\n   - To facilitate better information flow and mitigate the vanishing gradient problem, \"Residual Connections\" are added between the attention layer and feed-forward layer. The \"Add & Layer Norm\" operations, represented by `add_norm_1` and `add_norm_2`, respectively, combine the output of the previous layer with its input and apply layer normalization.\n<br>\n7. Output Layer:<br>\n   - Finally, the output from the feed-forward layer passes through the \"Output Layer,\" represented by the `output` node, to generate the final output of the XLNet model.<br>\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import SVG, display\n\n# Load the SVG file and display it\nsvg_file = '/kaggle/input/notebook-images/xlnet.svg'\ndisplay(SVG(filename=svg_file))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:17:06.946819Z","iopub.execute_input":"2023-06-09T01:17:06.947832Z","iopub.status.idle":"2023-06-09T01:17:06.967158Z","shell.execute_reply.started":"2023-06-09T01:17:06.947796Z","shell.execute_reply":"2023-06-09T01:17:06.966248Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"436pt\" height=\"372pt\" viewBox=\"0.00 0.00 436.00 372.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 368)\">\n<title>xlnet</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-368 432,-368 432,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_input</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"8,-279.2 8,-356 98,-356 98,-279.2 8,-279.2\"/>\n<text text-anchor=\"middle\" x=\"53\" y=\"-339.4\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Layer</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_segment</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"106,-279.2 106,-356 260,-356 260,-279.2 106,-279.2\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-339.4\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Segment Embeddings</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_position</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"268,-279.2 268,-356 420,-356 420,-279.2 268,-279.2\"/>\n<text text-anchor=\"middle\" x=\"344\" y=\"-339.4\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Position Embeddings</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_attention</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"124,-194.4 124,-271.2 229,-271.2 229,-194.4 124,-194.4\"/>\n<text text-anchor=\"middle\" x=\"176.5\" y=\"-254.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Attention Layer</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_ff</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"243,-194.4 243,-271.2 407,-271.2 407,-194.4 243,-194.4\"/>\n<text text-anchor=\"middle\" x=\"325\" y=\"-254.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward Layer</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_residual</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"112,-92.8 112,-186.4 399,-186.4 399,-92.8 112,-92.8\"/>\n<text text-anchor=\"middle\" x=\"255.5\" y=\"-169.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Residual Connections</text>\n<text text-anchor=\"middle\" x=\"255.5\" y=\"-153\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and Layer Normalization</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_output</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"283,-8 283,-84.8 374,-84.8 374,-8 283,-8\"/>\n<text text-anchor=\"middle\" x=\"328.5\" y=\"-68.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output Layer</text>\n</g>\n<!-- input -->\n<g id=\"node1\" class=\"node\">\n<title>input</title>\n<text text-anchor=\"middle\" x=\"53\" y=\"-301\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Input Text</text>\n</g>\n<!-- attention -->\n<g id=\"node4\" class=\"node\">\n<title>attention</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"217.3837,-238.4 148.6163,-238.4 148.6163,-202.4 217.3837,-202.4 217.3837,-238.4\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-216.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Attention</text>\n</g>\n<!-- input&#45;&gt;attention -->\n<g id=\"edge1\" class=\"edge\">\n<title>input-&gt;attention</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M80.8883,-287.0083C100.0807,-274.4889 125.7648,-257.735 146.5721,-244.1622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"148.6945,-246.9566 155.1579,-238.5616 144.87,-241.0937 148.6945,-246.9566\"/>\n</g>\n<!-- segment -->\n<g id=\"node2\" class=\"node\">\n<title>segment</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"252.4869,-323.2 113.5131,-323.2 113.5131,-287.2 252.4869,-287.2 252.4869,-323.2\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-301\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Segment Embeddings</text>\n</g>\n<!-- segment&#45;&gt;attention -->\n<g id=\"edge3\" class=\"edge\">\n<title>segment-&gt;attention</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M183,-286.7997C183,-275.6112 183,-261.0983 183,-248.4954\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.5001,-248.4731 183,-238.4731 179.5001,-248.4731 186.5001,-248.4731\"/>\n</g>\n<!-- position -->\n<g id=\"node3\" class=\"node\">\n<title>position</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"411.8926,-323.2 276.1074,-323.2 276.1074,-287.2 411.8926,-287.2 411.8926,-323.2\"/>\n<text text-anchor=\"middle\" x=\"344\" y=\"-301\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Position Embeddings</text>\n</g>\n<!-- position&#45;&gt;attention -->\n<g id=\"edge4\" class=\"edge\">\n<title>position-&gt;attention</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M288.4938,-287.1246C280.283,-284.4612 271.9225,-281.755 264,-279.2 252.897,-275.6193 249.1053,-277.0293 239,-271.2 227.1571,-264.3684 215.6811,-254.6866 206.2337,-245.6048\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.6766,-243.098 199.1239,-238.5159 203.7342,-248.0551 208.6766,-243.098\"/>\n</g>\n<!-- add_norm_1 -->\n<g id=\"node6\" class=\"node\">\n<title>add_norm_1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"246.2976,-136.8 119.7024,-136.8 119.7024,-100.8 246.2976,-100.8 246.2976,-136.8\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-114.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Add &amp; Layer Norm</text>\n</g>\n<!-- attention&#45;&gt;add_norm_1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>attention-&gt;add_norm_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M183,-202.236C183,-186.9213 183,-164.7442 183,-147.1029\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.5001,-146.8068 183,-136.8068 179.5001,-146.8068 186.5001,-146.8068\"/>\n</g>\n<!-- feed_forward -->\n<g id=\"node5\" class=\"node\">\n<title>feed_forward</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"398.7766,-238.4 251.2234,-238.4 251.2234,-202.4 398.7766,-202.4 398.7766,-238.4\"/>\n<text text-anchor=\"middle\" x=\"325\" y=\"-216.2\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Feed-Forward Network</text>\n</g>\n<!-- add_norm_2 -->\n<g id=\"node7\" class=\"node\">\n<title>add_norm_2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"391.2976,-136.8 264.7024,-136.8 264.7024,-100.8 391.2976,-100.8 391.2976,-136.8\"/>\n<text text-anchor=\"middle\" x=\"328\" y=\"-114.6\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Add &amp; Layer Norm</text>\n</g>\n<!-- feed_forward&#45;&gt;add_norm_2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>feed_forward-&gt;add_norm_2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M325.5363,-202.236C325.9885,-186.9213 326.6434,-164.7442 327.1643,-147.1029\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"330.6715,-146.9058 327.4683,-136.8068 323.6746,-146.6991 330.6715,-146.9058\"/>\n</g>\n<!-- add_norm_1&#45;&gt;feed_forward -->\n<g id=\"edge5\" class=\"edge\">\n<title>add_norm_1-&gt;feed_forward</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M199.7682,-137.0082C213.8287,-151.5839 234.9361,-171.9144 256,-186.4 261.6927,-190.3148 267.9024,-194.0359 274.1878,-197.4817\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"272.9191,-200.7689 283.3992,-202.3237 276.1761,-194.5727 272.9191,-200.7689\"/>\n</g>\n<!-- output -->\n<g id=\"node8\" class=\"node\">\n<title>output</title>\n<text text-anchor=\"middle\" x=\"328\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Output</text>\n</g>\n<!-- add_norm_2&#45;&gt;output -->\n<g id=\"edge7\" class=\"edge\">\n<title>add_norm_2-&gt;output</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M328,-100.3997C328,-89.2112 328,-74.6983 328,-62.0954\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.5001,-62.0731 328,-52.0731 324.5001,-62.0731 331.5001,-62.0731\"/>\n</g>\n</g>\n</svg>"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe import the required libraries including PyTorch, XLNetForSequenceClassification, XLNetTokenizer from the transformers package, and pandas for data handling.</div>\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom transformers import XLNetForSequenceClassification, XLNetTokenizer\nfrom sklearn.metrics import f1_score\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T00:54:20.009229Z","iopub.execute_input":"2023-06-09T00:54:20.009801Z","iopub.status.idle":"2023-06-09T00:54:30.793979Z","shell.execute_reply.started":"2023-06-09T00:54:20.009768Z","shell.execute_reply":"2023-06-09T00:54:30.792785Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe check if a GPU is available and set the device accordingly. This enables GPU acceleration if available.</div>","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T00:54:30.796360Z","iopub.execute_input":"2023-06-09T00:54:30.796749Z","iopub.status.idle":"2023-06-09T00:54:30.825169Z","shell.execute_reply.started":"2023-06-09T00:54:30.796717Z","shell.execute_reply":"2023-06-09T00:54:30.823743Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe initialize the XLNet model for sequence classification and its corresponding tokenizer. We use the 'xlnet-base-cased' pre-trained model.</div>","metadata":{}},{"cell_type":"code","source":"# Define XLNet model and tokenizer\nmodel = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\ntokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T00:54:30.826713Z","iopub.execute_input":"2023-06-09T00:54:30.827656Z","iopub.status.idle":"2023-06-09T00:54:51.235407Z","shell.execute_reply.started":"2023-06-09T00:54:30.827619Z","shell.execute_reply":"2023-06-09T00:54:51.234422Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d5864d230054afd875c8508d2a944a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b91012dd5b4fca8b6dd1bafa79bb93"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ea7d3f813a467da1e8b9d8ea14b861"}},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe read the Quora Insincere Question Classification dataset from CSV files using pandas.</div>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')\ntest_df = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T00:54:51.237844Z","iopub.execute_input":"2023-06-09T00:54:51.238175Z","iopub.status.idle":"2023-06-09T00:54:56.690640Z","shell.execute_reply.started":"2023-06-09T00:54:51.238142Z","shell.execute_reply":"2023-06-09T00:54:56.689583Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe tokenize and encode the question texts using the XLNet tokenizer. The encoded sequences include input IDs, attention masks, and the target labels for the training dataset.</div>","metadata":{}},{"cell_type":"code","source":"train_encoded = tokenizer.batch_encode_plus(train_df['question_text'].tolist(),\n                                            add_special_tokens=True,\n                                            padding='longest',\n                                            truncation=True,\n                                            return_tensors='pt', max_length=64) #increase max length to 512 if there are no memory restrictions","metadata":{"execution":{"iopub.status.busy":"2023-06-09T00:54:56.692054Z","iopub.execute_input":"2023-06-09T00:54:56.692423Z","iopub.status.idle":"2023-06-09T01:00:34.848509Z","shell.execute_reply.started":"2023-06-09T00:54:56.692390Z","shell.execute_reply":"2023-06-09T01:00:34.847510Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_encoded = tokenizer.batch_encode_plus(test_df['question_text'].tolist(),\n                                           add_special_tokens=True,\n                                           padding='longest',\n                                           truncation=True,\n                                           return_tensors='pt',max_length=64)#increase max length to 512 if there are no memory restrictions\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:00:34.850057Z","iopub.execute_input":"2023-06-09T01:00:34.850598Z","iopub.status.idle":"2023-06-09T01:02:14.404155Z","shell.execute_reply.started":"2023-06-09T01:00:34.850558Z","shell.execute_reply":"2023-06-09T01:02:14.403131Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe create data loaders for both the training and test datasets using the encoded sequences. </div>","metadata":{}},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(train_encoded['input_ids'],\n                                               train_encoded['attention_mask'],\n                                               torch.tensor(train_df['target'].tolist()))\ntest_dataset = torch.utils.data.TensorDataset(test_encoded['input_ids'], test_encoded['attention_mask'])\ntrain_loader = DataLoader(train_dataset, batch_size=16*4, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16*4, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:14.405816Z","iopub.execute_input":"2023-06-09T01:02:14.406177Z","iopub.status.idle":"2023-06-09T01:02:14.842095Z","shell.execute_reply.started":"2023-06-09T01:02:14.406144Z","shell.execute_reply":"2023-06-09T01:02:14.841027Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nPerformed sanity check of the dataloaders</div","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:14.843789Z","iopub.execute_input":"2023-06-09T01:02:14.844459Z","iopub.status.idle":"2023-06-09T01:02:14.980077Z","shell.execute_reply.started":"2023-06-09T01:02:14.844421Z","shell.execute_reply":"2023-06-09T01:02:14.979123Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[tensor([[ 5,  5,  5,  ..., 82,  4,  3],\n        [ 5,  5,  5,  ..., 82,  4,  3],\n        [ 5,  5,  5,  ..., 82,  4,  3],\n        ...,\n        [ 5,  5,  5,  ..., 82,  4,  3],\n        [ 5,  5,  5,  ..., 82,  4,  3],\n        [ 5,  5,  5,  ..., 82,  4,  3]]), tensor([[0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1],\n        ...,\n        [0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe define the number of training epochs and the learning rate.</div","metadata":{}},{"cell_type":"code","source":"num_epochs = 1\nlearning_rate = 2e-5\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:14.981471Z","iopub.execute_input":"2023-06-09T01:02:14.982010Z","iopub.status.idle":"2023-06-09T01:02:14.986623Z","shell.execute_reply.started":"2023-06-09T01:02:14.981975Z","shell.execute_reply":"2023-06-09T01:02:14.985585Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe specify the loss function (cross-entropy loss) and the optimizer (AdamW) for model training.</div>","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:14.990528Z","iopub.execute_input":"2023-06-09T01:02:14.991129Z","iopub.status.idle":"2023-06-09T01:02:14.998036Z","shell.execute_reply.started":"2023-06-09T01:02:14.991095Z","shell.execute_reply":"2023-06-09T01:02:14.997104Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe moved the model to device and put it to train.</div>","metadata":{}},{"cell_type":"code","source":"model.to(device)\nmodel.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:14.999554Z","iopub.execute_input":"2023-06-09T01:02:14.999973Z","iopub.status.idle":"2023-06-09T01:02:19.599220Z","shell.execute_reply.started":"2023-06-09T01:02:14.999936Z","shell.execute_reply":"2023-06-09T01:02:19.598199Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"XLNetForSequenceClassification(\n  (transformer): XLNetModel(\n    (word_embedding): Embedding(32000, 768)\n    (layer): ModuleList(\n      (0-11): 12 x XLNetLayer(\n        (rel_attn): XLNetRelativeAttention(\n          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ff): XLNetFeedForward(\n          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (activation_function): GELUActivation()\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (sequence_summary): SequenceSummary(\n    (summary): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n    (first_dropout): Identity()\n    (last_dropout): Dropout(p=0.1, inplace=False)\n  )\n  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe train the XLNet model by iterating over the training data loader. The model is set to train mode, and the optimizer is zeroed before computing and backpropagating the loss.</div>","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for step, (inputs, masks, targets) in enumerate(tqdm(train_loader)):\n        inputs, masks, targets = inputs.to(device), masks.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids=inputs, attention_mask=masks)[0]\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        if step%1000==0:\n            print(\"Step - {}, Loss - {}\".format(step, loss.item()))\n            break\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:19.601363Z","iopub.execute_input":"2023-06-09T01:02:19.602179Z","iopub.status.idle":"2023-06-09T01:02:21.517637Z","shell.execute_reply.started":"2023-06-09T01:02:19.602141Z","shell.execute_reply":"2023-06-09T01:02:21.516698Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"  0%|          | 0/20409 [00:01<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Step - 0, Loss - 0.8209980726242065\nEpoch 1/1, Loss: 0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe intentionally trained for few steps of epoch 0, you should train more !</div>","metadata":{}},{"cell_type":"code","source":"model.eval()\npredictions = []\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:21.519124Z","iopub.execute_input":"2023-06-09T01:02:21.519719Z","iopub.status.idle":"2023-06-09T01:02:21.526725Z","shell.execute_reply.started":"2023-06-09T01:02:21.519683Z","shell.execute_reply":"2023-06-09T01:02:21.525684Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nWe switch the model to evaluation mode and iterate over the test data loader to make predictions on the test dataset.</div>","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    for inputs, masks in tqdm(test_loader):\n        inputs, masks = inputs.to(device), masks.to(device)\n        outputs = model(input_ids=inputs, attention_mask=masks)[0]\n        _, predicted_labels = torch.max(outputs, 1)\n        predictions.extend(predicted_labels.tolist())","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:02:21.528201Z","iopub.execute_input":"2023-06-09T01:02:21.528574Z","iopub.status.idle":"2023-06-09T01:17:05.797147Z","shell.execute_reply.started":"2023-06-09T01:02:21.528541Z","shell.execute_reply":"2023-06-09T01:17:05.796142Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5872/5872 [14:44<00:00,  6.64it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#A7C6F5; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 5px solid #19180F;\">\nsubmission.csv generated</div>","metadata":{}},{"cell_type":"code","source":"submission_df = pd.DataFrame({'qid': test_df['qid'], 'prediction': predictions})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:17:05.798749Z","iopub.execute_input":"2023-06-09T01:17:05.799738Z","iopub.status.idle":"2023-06-09T01:17:06.945504Z","shell.execute_reply.started":"2023-06-09T01:17:05.799698Z","shell.execute_reply":"2023-06-09T01:17:06.944534Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-06-09T01:18:25.460758Z","iopub.execute_input":"2023-06-09T01:18:25.461139Z","iopub.status.idle":"2023-06-09T01:18:25.479460Z","shell.execute_reply.started":"2023-06-09T01:18:25.461107Z","shell.execute_reply":"2023-06-09T01:18:25.478330Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                         qid  prediction\n0       0000163e3ea7c7a74cd7           0\n1       00002bd4fb5d505b9161           0\n2       00007756b4a147d2b0b3           0\n3       000086e4b7e1c7146103           0\n4       0000c4c3fbe8785a3090           0\n...                      ...         ...\n375801  ffff7fa746bd6d6197a9           0\n375802  ffffa1be31c43046ab6b           0\n375803  ffffae173b6ca6bfa563           0\n375804  ffffb1f7f1a008620287           0\n375805  fffff85473f4699474b0           0\n\n[375806 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000163e3ea7c7a74cd7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002bd4fb5d505b9161</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007756b4a147d2b0b3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000086e4b7e1c7146103</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000c4c3fbe8785a3090</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>375801</th>\n      <td>ffff7fa746bd6d6197a9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>375802</th>\n      <td>ffffa1be31c43046ab6b</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>375803</th>\n      <td>ffffae173b6ca6bfa563</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>375804</th>\n      <td>ffffb1f7f1a008620287</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>375805</th>\n      <td>fffff85473f4699474b0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>375806 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}