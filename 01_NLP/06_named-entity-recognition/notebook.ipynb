{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "Named-entity-recognition seeks to locate and classify named entities in unstructred text into pre-defined categories like person name, organisation etc. \n",
    "\n",
    "This facilitates a lot of information retrieval tasks in Natural Language Understanding. \n",
    "\n",
    "* Spacy has a ner pipeline that can be used to do the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is first and its label is ORDINAL\n",
      "The text is NER and its label is ORG\n",
      "The text is VSCode and its label is ORG\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, This is our first example about NER on VSCode, Hope we cover the concepts in detail.\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"The text is {} and its label is {}\".format(ent.text, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is Suraj and its label is PERSON \n",
      "The text is India and its label is GPE \n",
      "The text is 4th April and its label is DATE \n"
     ]
    }
   ],
   "source": [
    "text2 = \"Suraj is a resident of India, born on 4th April.\"\n",
    "doc1 = nlp(text2)\n",
    "for ent in doc1.ents:\n",
    "        print(\"The text is {} and its label is {} \".format(ent.text, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can understand unknown labels via spacy.explain\n",
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of various NER Tags.\n",
    "| Type     | Description      | Example     |\n",
    "| ------------- | ------------- | -------- |\n",
    "| NORP         | Nationalities or religious or political groups         | \"The Congress\", \"BJP\"  |\n",
    "| PERSON           | People name including fictional         | Mercury Hannon  |\n",
    "| FAC           | Buildings, airports, highways, bridges etc         | Chatrapati Shivaji Terminus |\n",
    "| ORG           | Companies, agencies, Institutions etc         | Apple, Microsoft, Google, META, Tesla  |\n",
    "| GPE           | Countries, Cities, States         | India, Mumbai,Maharastra, Bengaluru  |\n",
    "| LOC           | Non-GPE locations, mountain ranges, bodies of water         | Southern Africa, Nile River  |\n",
    "| PRODUCT           | Objects, vehicles, foods etc(not services)         | Printer  |\n",
    "| EVENT           | Named hurricanes, battles, wars, sports events, etc         | Olympic Games  |\n",
    "| WORK_OF_ART           | Titles of books, songs etc         | The Mona Lisa  |\n",
    "| LAW           | Named documents made into laws         | Roe. v. Wade  |\n",
    "| LANGUAGE           | Any named language         | English  |\n",
    "| DATE           | Absolute or relative dates or periods         | 4 April 1996  |\n",
    "| TIME           | Times smaller than a day         | Eight minutes, six hours |\n",
    "| PERCENT           | Percentage, including %         | Eight percent |\n",
    "| MONEY           | Monetary values, including unit         | Twenty cents |\n",
    "| QUANTITY           | Measurements, as of weight or distance         | Several kilometers,100 kg |\n",
    "| ORDINAL           | fourth, eighteenth         | 8th, 2nd |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to add a custom named entity.\n",
    "We add all such named entity to a span. The following steps are incorporated to add one such NER to spacy.\n",
    "\n",
    "Let's have a look at the start and end of each NER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"This is Suraj and we want to show you some books on the topic- Gravitational Force\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is Suraj and its label is PERSON - It's start is 8, End is 13 and It's start word index 2 + end word index is 3 \n",
      "The text is Gravitational Force and its label is ORG - It's start is 63, End is 82 and It's start word index 14 + end word index is 16 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc2 = nlp(text3)\n",
    "for ent in doc2.ents:\n",
    "        print(\"The text is {} and its label is {} - It's start is {}, End is {} and It's start word index {} + end word index is {} \".format(ent.text, ent.label_, ent.start_char,ent.end_char, ent.start, ent.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at an example where we are required to add a custom NER\n",
    "text4 = \"Suraj to build a github repository for maintenance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is Suraj and its label is PERSON - It's start is 0, End is 5 and It's start word index 0 + end word index is 1 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc3 = nlp(text4)\n",
    "for ent in doc3.ents:\n",
    "        print(\"The text is {} and its label is {} - It's start is {}, End is {} and It's start word index {} + end word index is {} \".format(ent.text, ent.label_, ent.start_char,ent.end_char, ent.start, ent.end))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, github repository is needed to be added as a product. In all such cases we will use <a href=\"https://ner.pythonhumanities.com/02_01_spaCy_Entity_Ruler.html\"> Entity Ruler </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's add\n",
    "#Create the EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#List of Entities and Patterns\n",
    "patterns = [\n",
    "                {\"label\": \"PRODUCT\", \"pattern\": \"github repository\"}\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is Suraj and its label is PERSON - It's start is 0, End is 5 and It's start word index 0 + end word index is 1 \n",
      "The text is github repository and its label is PRODUCT - It's start is 17, End is 34 and It's start word index 4 + end word index is 6 \n"
     ]
    }
   ],
   "source": [
    "# let's find the updated one\n",
    "doc3 = nlp(text4)\n",
    "for ent in doc3.ents:\n",
    "        print(\"The text is {} and its label is {} - It's start is {}, End is {} and It's start word index {} + end word index is {} \".format(ent.text, ent.label_, ent.start_char,ent.end_char, ent.start, ent.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let;s check if this works on multiple instances of same unknown word\n",
    "\n",
    "text5 = \"This is a flute and we are looking for an E sharp flute, Can you please check all the flutes in your inventory ?\"\n",
    "doc4 = nlp(text5)\n",
    "for ent in doc4.ents:\n",
    "        print(\"The text is {} and its label is {} - It's start is {}, End is {} and It's start word index {} + end word index is {} \".format(ent.text, ent.label_, ent.start_char,ent.end_char, ent.start, ent.end))\n",
    "\n",
    "# the o/p of the cell came after re-running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's add via ruler\n",
    "#Create the EntityRuler\n",
    "\n",
    "#List of Entities and Patterns\n",
    "patterns = [\n",
    "                {\"label\": \"PRODUCT\", \"pattern\": \"flute\"}\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is flute and its label is PRODUCT - It's start is 10, End is 15 and It's start word index 3 + end word index is 4 \n",
      "The text is flute and its label is PRODUCT - It's start is 50, End is 55 and It's start word index 12 + end word index is 13 \n"
     ]
    }
   ],
   "source": [
    "# let's check\n",
    "doc4 = nlp(text5)\n",
    "for ent in doc4.ents:\n",
    "        print(\"The text is {} and its label is {} - It's start is {}, End is {} and It's start word index {} + end word index is {} \".format(ent.text, ent.label_, ent.start_char,ent.end_char, ent.start, ent.end))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - No, It doesn't add NER to all matching spans. It missed flutes. Let's do that via PhraseMatcher for a more complex example.\n",
    "\n",
    "Refer <a href=\"https://stackabuse.com/python-for-nlp-vocabulary-and-phrase-matching-with-spacy/\"> Link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "m_tool = Matcher(nlp.vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [{'LOWER':'flute'}, {'LOWER':'flutes'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_tool.add('flute',[patterns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(u'This is a flute and we are looking for an E sharp flute, Can you please check all the flutes in your inventory ?')\n",
    "matches = m_tool(sentence)\n",
    "print(matches)\n",
    "# let's match\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun Chunks\n",
    "These are base noun phrases. They are token spans that include noun and words describing the noun. They cannot be nested, cannot overlap and don't involve prepositional phrases or relative clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We-We-nsubj-looking\n",
      "agile developers-developers-pobj-for\n",
      "who-who-nsubj-fasttrack\n",
      "project development-development-dobj-fasttrack\n",
      "our organisation-organisation-pobj-in\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'We are looking for agile developers who can fasttrack project development in our organisation')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text +'-'+ chunk.root.text + '-'+ chunk.root.dep_ +'-'+ chunk.root.head.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.noun_chunks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This is visualisation of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " module that will assist software developers in the domain of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in their company on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Earth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('This is visualisation of NER module that will assist software developers in the domain of NLP in their company on Earth')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This is visualisation of \n",
       "<mark class=\"entity\" style=\"background: radial-gradient(yellow,cyan); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " module that will assist software developers in the domain of \n",
       "<mark class=\"entity\" style=\"background: radial-gradient(yellow,cyan); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in their company on \n",
       "<mark class=\"entity\" style=\"background: radial-gradient(pink,blue); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Earth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can even specify colors and effects to displacy\n",
    "colors = {'ORG':'radial-gradient(yellow,cyan)','LOC':'radial-gradient(pink,blue)'}\n",
    "options = {'ents':['ORG','LOC'], 'colors':colors}\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "We can train our own custom NER model via <a href=\"https://github.com/deeppavlov/ner/blob/master/training_example.ipynb\"> Link 1 </a> or <a href= \"https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\" > Link 2 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50052c996937e9a0e161d422489677fdaadc23d756ac209b7397e80e5ea8cea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
