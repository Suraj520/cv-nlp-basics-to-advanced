{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form. <a href=\"https://en.wikipedia.org/wiki/Lemmatisation\"> Link </a>\n",
    "\n",
    "For eg - \n",
    "Worked - Work\n",
    "Working - Work\n",
    "Works - Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why do we need Lemmatisation ?\n",
    "\n",
    "- We need lemmatisation to reach the base form of a word in a sentence. Decreasing computational overload can also be regarded as its use case. Suppose a text has work, works, worked, working in it then since NLP converts each text into a vector so, we will have 4 vectors for the text but through lemmatisation, we can end up having just one for the base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/anaconda3/envs/dl/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-01-14 21:30:22.403301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-14 21:31:10.936315: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-14 21:31:10.938629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-14 21:31:10.944068: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-01-14 21:31:10.944121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: suraj\n",
      "2023-01-14 21:31:10.944133: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: suraj\n",
      "2023-01-14 21:31:10.944382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.226.0\n",
      "2023-01-14 21:31:10.944428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.226.0\n",
      "2023-01-14 21:31:10.944440: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.226.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The boy was going for a trip where he could say that he hiked, danced, sung, swam, surfed and cooked.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text - The and its lemma is the\n",
      "Text - boy and its lemma is boy\n",
      "Text - was and its lemma is be\n",
      "Text - going and its lemma is go\n",
      "Text - for and its lemma is for\n",
      "Text - a and its lemma is a\n",
      "Text - trip and its lemma is trip\n",
      "Text - where and its lemma is where\n",
      "Text - he and its lemma is he\n",
      "Text - could and its lemma is could\n",
      "Text - say and its lemma is say\n",
      "Text - that and its lemma is that\n",
      "Text - he and its lemma is he\n",
      "Text - hiked and its lemma is hike\n",
      "Text - , and its lemma is ,\n",
      "Text - danced and its lemma is dance\n",
      "Text - , and its lemma is ,\n",
      "Text - sung and its lemma is sung\n",
      "Text - , and its lemma is ,\n",
      "Text - swam and its lemma is swam\n",
      "Text - , and its lemma is ,\n",
      "Text - surfed and its lemma is surfed\n",
      "Text - and and its lemma is and\n",
      "Text - cooked and its lemma is cook\n",
      "Text - . and its lemma is .\n"
     ]
    }
   ],
   "source": [
    "output = nlp(text)\n",
    "for token in output:\n",
    "    print(\"Text - {} and its lemma is {}\".format(token.text, token.lemma_))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For much better accuracy, We can use LemmInflect which has outperformed its accuracy with respect to various lemmatisers in NLTK,Spacy,Stanford CoreNLP and CLiPS.\n",
    "\n",
    "<a href=\"https://github.com/bjascob/LemmInflect\"> Link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lemminflect\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/suraj/anaconda3/envs/dl/lib/python3.7/site-packages (from lemminflect) (1.21.6)\n",
      "Installing collected packages: lemminflect\n",
      "Successfully installed lemminflect-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lemminflect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's integrated with Spacy, too.\n",
    "<a href=\"https://spacy.io/universe/project/lemminflect\"> Link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text - He and its lemma is He\n",
      "Text - went and its lemma is go\n",
      "Text - to and its lemma is to\n",
      "Text - a and its lemma is a\n",
      "Text - trip and its lemma is trip\n",
      "Text - to and its lemma is to\n",
      "Text - later and its lemma is later\n",
      "Text - brag and its lemma is brag\n",
      "Text - that and its lemma is that\n",
      "Text - he and its lemma is he\n",
      "Text - hiked and its lemma is hike\n",
      "Text - , and its lemma is ,\n",
      "Text - swam and its lemma is swam\n",
      "Text - , and its lemma is ,\n",
      "Text - danced and its lemma is dance\n",
      "Text - , and its lemma is ,\n",
      "Text - sang and its lemma is sang\n",
      "Text - , and its lemma is ,\n",
      "Text - ran and its lemma is run\n",
      "Text - and and its lemma is and\n",
      "Text - cooked and its lemma is cook\n",
      "Text - . and its lemma is .\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate an example\n",
    "\n",
    "import lemminflect\n",
    "doc = nlp('He went to a trip to later brag that he hiked, swam, danced, sang, ran and cooked.')\n",
    "\n",
    "for token in doc:\n",
    "    print(\"Text - {} and its lemma is {}\".format(token.text, token._.lemma()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50052c996937e9a0e161d422489677fdaadc23d756ac209b7397e80e5ea8cea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
