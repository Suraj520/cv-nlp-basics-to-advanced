{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## About\n\nThe Cornell Movie Dialog Corpus is a dataset that contains conversations between characters from over 600 movies. Our task is to classify the dialogues into different categories based on their intent or emotion, such as happy, sad, angry, etc.\n\n","metadata":{}},{"cell_type":"markdown","source":"Importing modules","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:09.543797Z","iopub.execute_input":"2023-05-11T06:49:09.544406Z","iopub.status.idle":"2023-05-11T06:49:11.451559Z","shell.execute_reply.started":"2023-05-11T06:49:09.544373Z","shell.execute_reply":"2023-05-11T06:49:11.450321Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Declaring the file paths in the following snippet","metadata":{}},{"cell_type":"code","source":"# Define the path to the data files\nmetadata_path = \"/kaggle/input/cornell-moviedialog-corpus/movie_characters_metadata.txt\"\nconversations_path = \"/kaggle/input/cornell-moviedialog-corpus/movie_conversations.txt\"\nlines_path = \"/kaggle/input/cornell-moviedialog-corpus/movie_lines.txt\"\ntitles_path = \"/kaggle/input/cornell-moviedialog-corpus/movie_titles_metadata.txt\"\nraw_script_urls_path = \"/kaggle/input/cornell-moviedialog-corpus/raw_script_urls.txt\"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:11.452858Z","iopub.execute_input":"2023-05-11T06:49:11.453470Z","iopub.status.idle":"2023-05-11T06:49:11.459461Z","shell.execute_reply.started":"2023-05-11T06:49:11.453422Z","shell.execute_reply":"2023-05-11T06:49:11.458338Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The following code defines a function called `load_lines` that loads individual lines of dialogue from a file specified by `file_path`. If `line_ids` is provided, only the specified lines will be returned; otherwise, all lines will be returned. \n\nThe function reads in the file using `open()`, and then iterates over each line using a `for` loop. Each line is stripped of whitespace and split on the string `\" +++$+++ \"`, which separates the line ID from the actual line of dialogue. If `line_ids` is `None` or the current line ID is in `line_ids`, the line is added to a dictionary called `lines` with the ID as the key and the actual line of dialogue as the value.\n\nIf `line_ids` is not `None` and the number of lines in `lines` is equal to the length of `line_ids`, the function breaks out of the loop. Finally, the function either returns a list of the values in `lines` (if `line_ids` is `None`) or a list of the values in `lines` corresponding to the IDs in `line_ids`.\n\nThe function then returns the first 100 lines of dialogue using Python's slice notation `[:100]`.\n\nWe're training on 100 samples intentionally out here","metadata":{}},{"cell_type":"code","source":"def load_lines(file_path, line_ids=None):\n    \"\"\"\n    Load individual lines of dialogue from the given file path.\n    If line_ids is provided, only the specified lines will be returned.\n    \"\"\"\n    lines = {}\n    with open(file_path, 'r', encoding='iso-8859-1') as f:\n        for line in f:\n            line = line.strip().split(' +++$+++ ')\n            if line_ids is None or line[0] in line_ids:\n                lines[line[0]] = line[-1]\n                if line_ids is not None and len(lines) == len(line_ids):\n                    break\n    if line_ids is not None:\n        lines = [lines[line_id] for line_id in line_ids]\n    else:\n        lines = list(lines.values())\n    return lines[:100]","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:11.477644Z","iopub.execute_input":"2023-05-11T06:49:11.478064Z","iopub.status.idle":"2023-05-11T06:49:11.488710Z","shell.execute_reply.started":"2023-05-11T06:49:11.478028Z","shell.execute_reply":"2023-05-11T06:49:11.487414Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The following code snippet defines a function called `load_conversations` that takes in a file path as input. The function reads the data from the file located at the given file path. The file contains a list of conversations, where each conversation is represented by a series of lines of dialogue. \n\nThe function creates an empty list called `conversations` to store the loaded conversations. It then loops through each line of the file and processes it. For each line, it extracts the list of line IDs that belong to a single conversation. It then loads the text for each of those lines using the `load_lines` function, and appends those lines to the `conversation` list. Once all lines of a conversation have been processed, the entire conversation is appended to the `conversations` list.\n\nNote that the function stops after loading the first 100 conversations in the file, using the condition `if len(conversations) >= 100: break`, to limit the number of conversations to load.\n\nThe function returns the list of loaded conversations.","metadata":{}},{"cell_type":"code","source":"def load_conversations(file_path):\n    \"\"\"\n    Load conversation data from the given file path.\n    \"\"\"\n    conversations = []\n    with open(file_path, 'r', encoding='iso-8859-1') as f:\n        for line in f:\n            if len(conversations) >= 100:\n                break\n            conversation = []\n            line = line.strip().split(' +++$+++ ')\n            line_ids = line[-1][1:-1].replace(\"'\", \"\").split(\", \")\n            for line_id in line_ids:\n                line_text = load_lines(lines_path, [line_id])[0]\n                conversation.append(line_text)\n            conversations.append(conversation)\n    return conversations","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:11.490058Z","iopub.execute_input":"2023-05-11T06:49:11.490503Z","iopub.status.idle":"2023-05-11T06:49:11.502524Z","shell.execute_reply.started":"2023-05-11T06:49:11.490462Z","shell.execute_reply":"2023-05-11T06:49:11.501413Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"The following code defines a function `load_labels` that takes in two arguments:\n- `file_path`: a string representing the file path to a file containing movie information.\n- `conversation_ids`: a list of strings representing IDs of conversations whose labels need to be loaded.\n\nThe function reads the file line by line and extracts the movie ID and genre list from each line. It then checks if the movie ID is present in the `conversation_ids` list. If it is, it checks if the genre list contains the word 'romance'. If it does, it sets the label for that movie to 1, otherwise it sets the label to 0. Finally, it returns a dictionary where the keys are movie IDs and the values are the corresponding labels. \n\nThe `eval()` function is used to convert the genre list from a string to a list. It is assumed that the genre list is stored in the file as a Python list literal, i.e., enclosed in square brackets.","metadata":{}},{"cell_type":"code","source":"def load_labels(file_path, conversation_ids):\n    labels = {}\n    with open(file_path, 'r', encoding='iso-8859-1') as f:\n        for line in f:\n            # Split line by ' +++$+++ ' and extract the movie ID and genre list\n            parts = line.strip().split(' +++$+++ ')\n            movie_id = parts[0]\n            if movie_id in conversation_ids:\n                genres = eval(parts[-1])\n                # Set label to 1 if 'romance' is in the genre list, else set label to 0\n                if 'romance' in genres:\n                    label = 1\n                else:\n                    label = 0\n                labels[movie_id] = label\n    return labels\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:11.504370Z","iopub.execute_input":"2023-05-11T06:49:11.505282Z","iopub.status.idle":"2023-05-11T06:49:11.514753Z","shell.execute_reply.started":"2023-05-11T06:49:11.505249Z","shell.execute_reply":"2023-05-11T06:49:11.513445Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"In the following code, `conversations` are loaded from the file path specified in `conversations_path` using the `load_conversations()` function. `conversation_ids` are generated by creating a list of strings, with each string representing the ID of a conversation, from 'm0' to 'mN-1', where N is the total number of conversations loaded. \n\n`labels` are loaded using the `load_labels()` function which takes two arguments: the file path of the titles file and the list of conversation IDs. The function extracts the labels from the file and returns a dictionary with keys as conversation IDs and values as the corresponding labels. In this case, only the labels for the first 100 conversations are loaded and stored in the `labels` variable.","metadata":{}},{"cell_type":"code","source":"conversations = load_conversations(conversations_path)\n# Get the IDs of the conversations\nconversation_ids = ['m' + str(i) for i in range(len(conversations))]\n\n# Load only the labels for the first 100 conversations\nlabels = load_labels(titles_path, conversation_ids)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:53:41.988538Z","iopub.execute_input":"2023-05-11T06:53:41.989051Z","iopub.status.idle":"2023-05-11T06:53:42.225710Z","shell.execute_reply.started":"2023-05-11T06:53:41.989011Z","shell.execute_reply":"2023-05-11T06:53:42.224578Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"In the following snippet, We are importing modules that will be helpful for our next steps","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:11.844461Z","iopub.execute_input":"2023-05-11T06:49:11.845411Z","iopub.status.idle":"2023-05-11T06:49:15.127372Z","shell.execute_reply.started":"2023-05-11T06:49:11.845368Z","shell.execute_reply":"2023-05-11T06:49:15.126186Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The following code creates a numpy array train_labels by selecting values from a dictionary labels using a for loop that iterates from 0 to len(conversations) (exclusive).\n\nWithin the for loop, it accesses the dictionary using the key m+i where i is the current value of the loop index. This will extract a value from the dictionary where the key matches the string \"m\" concatenated with the current value of i. The extracted value is then added to the train_labels array.","metadata":{}},{"cell_type":"code","source":"train_labels = np.array([labels['m'+str(i)] for i in range(len(conversations))])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:55:09.567662Z","iopub.execute_input":"2023-05-11T06:55:09.568139Z","iopub.status.idle":"2023-05-11T06:55:09.574027Z","shell.execute_reply.started":"2023-05-11T06:55:09.568080Z","shell.execute_reply":"2023-05-11T06:55:09.572963Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"The following code uses the Keras `Tokenizer` class to convert the list of conversations to sequences of integers. The `Tokenizer` class is initialized with a set of filters that specify which characters should be ignored during tokenization. In this case, the filters include various special characters and white space. \n\nThe `fit_on_texts` method is then called on the `Tokenizer` object with the list of conversations as the argument. This method updates the tokenizer's internal vocabulary based on the words in the input texts. \n\nFinally, the `texts_to_sequences` method is called on the `Tokenizer` object with the `conversations` list as the argument. This method converts each conversation to a sequence of integers based on the tokenizer's vocabulary. The resulting sequences can be used as input to a deep learning model.","metadata":{}},{"cell_type":"code","source":"# Convert conversations to sequences\ntokenizer = Tokenizer(filters='\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n')\ntokenizer.fit_on_texts(conversations)\nsequences = tokenizer.texts_to_sequences(conversations)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:15.140850Z","iopub.execute_input":"2023-05-11T06:49:15.141384Z","iopub.status.idle":"2023-05-11T06:49:15.156500Z","shell.execute_reply.started":"2023-05-11T06:49:15.141339Z","shell.execute_reply":"2023-05-11T06:49:15.155144Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The following code is preparing the sequences of text for training the neural network by padding each sequence with zeros so that they all have the same length. The `pad_sequences` function from Keras is used for this purpose. \n\nIn this case, the sequences are padded to a maximum length of 40 words, which means that any sequence that has less than 40 words will be padded with zeros at the end to make it 40 words long. If a sequence has more than 40 words, it will be truncated to 40 words. \n\nThe padding type is set to 'post', which means that the padding will be added at the end of each sequence. This ensures that the actual text content of the sequence comes first and the padding comes at the end. \n\nThe resulting padded_sequences variable will be a numpy array of shape `(number of sequences, max_len)` where `max_len` is the maximum length of the sequences after padding.","metadata":{}},{"cell_type":"code","source":"# Pad sequences to a maximum length of 40 words\nmax_len = 40\npadded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:28.591595Z","iopub.execute_input":"2023-05-11T06:49:28.592017Z","iopub.status.idle":"2023-05-11T06:49:28.598998Z","shell.execute_reply.started":"2023-05-11T06:49:28.591985Z","shell.execute_reply":"2023-05-11T06:49:28.597798Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The followig code snippet uses the `train_test_split` function from the `sklearn` library to split the input `padded_sequences` and `train_labels` into training and testing sets. The `train_test_split` function takes four arguments: \n\n- `padded_sequences`: The input sequences that have been padded to a fixed length.\n- `train_labels`: The corresponding labels for each input sequence.\n- `test_size`: The proportion of the data to be allocated for testing (in this case 20%).\n- `random_state`: A seed value for the random number generator used in the split.\n\nThe function returns four output variables:\n\n- `train_sequences`: A subset of the `padded_sequences` used for training.\n- `test_sequences`: A subset of the `padded_sequences` used for testing.\n- `train_targets`: The corresponding labels for `train_sequences`.\n- `test_targets`: The corresponding labels for `test_sequences`.\n\nThese subsets of the data can then be used to train and evaluate the performance of a machine learning model.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split data into training and testing sets\ntrain_sequences, test_sequences, train_targets, test_targets = train_test_split(padded_sequences, train_labels, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:29.406879Z","iopub.execute_input":"2023-05-11T06:49:29.408131Z","iopub.status.idle":"2023-05-11T06:49:29.728710Z","shell.execute_reply.started":"2023-05-11T06:49:29.408061Z","shell.execute_reply":"2023-05-11T06:49:29.727414Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Doing sanity check of the splits by printing the shapes","metadata":{}},{"cell_type":"code","source":"train_sequences.shape, train_targets.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:29.858556Z","iopub.execute_input":"2023-05-11T06:49:29.858976Z","iopub.status.idle":"2023-05-11T06:49:29.869282Z","shell.execute_reply.started":"2023-05-11T06:49:29.858944Z","shell.execute_reply":"2023-05-11T06:49:29.867673Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((80, 40), (80,))"},"metadata":{}}]},{"cell_type":"markdown","source":"Defining the model architecture is performed in the following snippet of code.\n\nModel architecture can be summarized as follows\n\nFirstly,an instance of the sequential model is created using Sequential().\n\nThe next step adds an embedding layer to the model using model.add(Embedding(len(tokenizer.word_index) + 1, 64, input_length=max_len)). The embedding layer is used to map each word in the input text to a high-dimensional vector representation, with each dimension representing a feature of the word. The len(tokenizer.word_index) + 1 argument specifies the input dimension of the embedding layer, which is the number of unique words in the tokenizer plus one for out of vocabulary words. The 64 argument specifies the size of the vector space in which words will be embedded, and the input_length argument specifies the length of each input sequence.\n\nThe next line adds an LSTM layer to the model using model.add(LSTM(64, dropout=0.1)). The 64 argument specifies the number of output units in the LSTM layer, and the dropout=0.1 argument specifies the dropout rate to reduce overfitting.\n\nFinally, a dense output layer is added to the model using model.add(Dense(1, activation='sigmoid')). The output layer contains a single neuron with a sigmoid activation function to produce a binary classification output indicating the positive(Romantic) or negative sentiment of the input text.\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Define model architecture\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n# Build the model\nmodel = Sequential()\nmodel.add(Embedding(len(tokenizer.word_index) + 1, 64, input_length=max_len))\nmodel.add(LSTM(64, dropout=0.1))\nmodel.add(Dense(1, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:58:33.439626Z","iopub.execute_input":"2023-05-11T06:58:33.440138Z","iopub.status.idle":"2023-05-11T06:58:33.767787Z","shell.execute_reply.started":"2023-05-11T06:58:33.440075Z","shell.execute_reply":"2023-05-11T06:58:33.766713Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Model is compiled with binary cross entropy loss and accuracy as metrics in the following code.","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:49:31.246821Z","iopub.execute_input":"2023-05-11T06:49:31.247247Z","iopub.status.idle":"2023-05-11T06:49:31.270611Z","shell.execute_reply.started":"2023-05-11T06:49:31.247209Z","shell.execute_reply":"2023-05-11T06:49:31.269533Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Model is trained on 1000 samples for 50 epochs at a batch size of 32","metadata":{}},{"cell_type":"code","source":"# Train the model\nbatch_size = 32\nepochs = 50\nmodel.fit(train_sequences, train_targets, batch_size=batch_size, epochs=epochs, validation_data=(test_sequences, test_targets))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:50:27.095346Z","iopub.execute_input":"2023-05-11T06:50:27.095802Z","iopub.status.idle":"2023-05-11T06:50:37.401229Z","shell.execute_reply.started":"2023-05-11T06:50:27.095752Z","shell.execute_reply":"2023-05-11T06:50:37.399881Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/50\n3/3 [==============================] - 0s 61ms/step - loss: 0.4620 - accuracy: 0.8250 - val_loss: 0.6641 - val_accuracy: 0.7000\nEpoch 2/50\n3/3 [==============================] - 0s 39ms/step - loss: 0.4657 - accuracy: 0.8250 - val_loss: 0.6842 - val_accuracy: 0.7000\nEpoch 3/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.4663 - accuracy: 0.8250 - val_loss: 0.6897 - val_accuracy: 0.7000\nEpoch 4/50\n3/3 [==============================] - 0s 39ms/step - loss: 0.4672 - accuracy: 0.8250 - val_loss: 0.6705 - val_accuracy: 0.7000\nEpoch 5/50\n3/3 [==============================] - 0s 39ms/step - loss: 0.4626 - accuracy: 0.8250 - val_loss: 0.6511 - val_accuracy: 0.7000\nEpoch 6/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.4649 - accuracy: 0.8250 - val_loss: 0.6407 - val_accuracy: 0.7000\nEpoch 7/50\n3/3 [==============================] - 0s 38ms/step - loss: 0.4642 - accuracy: 0.8250 - val_loss: 0.6390 - val_accuracy: 0.7000\nEpoch 8/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.4650 - accuracy: 0.8250 - val_loss: 0.6412 - val_accuracy: 0.7000\nEpoch 9/50\n3/3 [==============================] - 0s 37ms/step - loss: 0.4634 - accuracy: 0.8250 - val_loss: 0.6465 - val_accuracy: 0.7000\nEpoch 10/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.4633 - accuracy: 0.8250 - val_loss: 0.6542 - val_accuracy: 0.7000\nEpoch 11/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.4651 - accuracy: 0.8250 - val_loss: 0.6641 - val_accuracy: 0.7000\nEpoch 12/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.4613 - accuracy: 0.8250 - val_loss: 0.6598 - val_accuracy: 0.7000\nEpoch 13/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.4612 - accuracy: 0.8250 - val_loss: 0.6524 - val_accuracy: 0.7000\nEpoch 14/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.4617 - accuracy: 0.8250 - val_loss: 0.6418 - val_accuracy: 0.7000\nEpoch 15/50\n3/3 [==============================] - 0s 38ms/step - loss: 0.4643 - accuracy: 0.8250 - val_loss: 0.6336 - val_accuracy: 0.7000\nEpoch 16/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.4661 - accuracy: 0.8250 - val_loss: 0.6314 - val_accuracy: 0.7000\nEpoch 17/50\n3/3 [==============================] - 0s 46ms/step - loss: 0.4669 - accuracy: 0.8250 - val_loss: 0.6352 - val_accuracy: 0.7000\nEpoch 18/50\n3/3 [==============================] - 0s 38ms/step - loss: 0.4662 - accuracy: 0.8250 - val_loss: 0.6523 - val_accuracy: 0.7000\nEpoch 19/50\n3/3 [==============================] - 0s 48ms/step - loss: 0.4618 - accuracy: 0.8250 - val_loss: 0.6661 - val_accuracy: 0.7000\nEpoch 20/50\n3/3 [==============================] - 0s 47ms/step - loss: 0.4597 - accuracy: 0.8250 - val_loss: 0.6639 - val_accuracy: 0.7000\nEpoch 21/50\n3/3 [==============================] - 0s 45ms/step - loss: 0.4570 - accuracy: 0.8250 - val_loss: 0.6710 - val_accuracy: 0.7000\nEpoch 22/50\n3/3 [==============================] - 0s 45ms/step - loss: 0.4552 - accuracy: 0.8250 - val_loss: 0.6791 - val_accuracy: 0.7000\nEpoch 23/50\n3/3 [==============================] - 0s 50ms/step - loss: 0.4500 - accuracy: 0.8250 - val_loss: 0.6617 - val_accuracy: 0.7000\nEpoch 24/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.4268 - accuracy: 0.8250 - val_loss: 0.6741 - val_accuracy: 0.7000\nEpoch 25/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.3710 - accuracy: 0.8250 - val_loss: 0.6238 - val_accuracy: 0.7000\nEpoch 26/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.2542 - accuracy: 0.8250 - val_loss: 0.6283 - val_accuracy: 0.7000\nEpoch 27/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.1515 - accuracy: 0.8750 - val_loss: 0.7495 - val_accuracy: 0.3000\nEpoch 28/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.1123 - accuracy: 0.9875 - val_loss: 0.8892 - val_accuracy: 0.3000\nEpoch 29/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.0828 - accuracy: 0.9875 - val_loss: 1.0302 - val_accuracy: 0.3000\nEpoch 30/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.0705 - accuracy: 0.9875 - val_loss: 1.1769 - val_accuracy: 0.3000\nEpoch 31/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.0596 - accuracy: 0.9875 - val_loss: 1.3079 - val_accuracy: 0.3000\nEpoch 32/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.0535 - accuracy: 0.9875 - val_loss: 1.4370 - val_accuracy: 0.3000\nEpoch 33/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.0505 - accuracy: 0.9875 - val_loss: 1.5741 - val_accuracy: 0.3000\nEpoch 34/50\n3/3 [==============================] - 0s 44ms/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 1.7068 - val_accuracy: 0.3000\nEpoch 35/50\n3/3 [==============================] - 0s 44ms/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 1.8224 - val_accuracy: 0.3000\nEpoch 36/50\n3/3 [==============================] - 0s 45ms/step - loss: 0.0470 - accuracy: 0.9875 - val_loss: 1.8788 - val_accuracy: 0.3000\nEpoch 37/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9131 - val_accuracy: 0.3000\nEpoch 38/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9485 - val_accuracy: 0.3000\nEpoch 39/50\n3/3 [==============================] - 0s 40ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9749 - val_accuracy: 0.3000\nEpoch 40/50\n3/3 [==============================] - 0s 46ms/step - loss: 0.0469 - accuracy: 0.9875 - val_loss: 2.0009 - val_accuracy: 0.3000\nEpoch 41/50\n3/3 [==============================] - 0s 45ms/step - loss: 0.0466 - accuracy: 0.9875 - val_loss: 1.9827 - val_accuracy: 0.3000\nEpoch 42/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9841 - val_accuracy: 0.3000\nEpoch 43/50\n3/3 [==============================] - 0s 44ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9841 - val_accuracy: 0.3000\nEpoch 44/50\n3/3 [==============================] - 0s 50ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 1.9850 - val_accuracy: 0.3000\nEpoch 45/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.0467 - accuracy: 0.9875 - val_loss: 1.9901 - val_accuracy: 0.3000\nEpoch 46/50\n3/3 [==============================] - 0s 42ms/step - loss: 0.0462 - accuracy: 0.9875 - val_loss: 1.9626 - val_accuracy: 0.3000\nEpoch 47/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 1.9224 - val_accuracy: 0.3000\nEpoch 48/50\n3/3 [==============================] - 0s 41ms/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 1.9022 - val_accuracy: 0.3000\nEpoch 49/50\n3/3 [==============================] - 0s 45ms/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 1.8891 - val_accuracy: 0.3000\nEpoch 50/50\n3/3 [==============================] - 0s 43ms/step - loss: 0.0464 - accuracy: 0.9875 - val_loss: 1.8780 - val_accuracy: 0.3000\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f54986027d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"The following code defines a function called generate_response that takes in an input text and generates a response based on the predicted label for that input.\n\nFirst, the input text is tokenized using the tokenizer.texts_to_sequences() function, which converts the input text to a sequence of integer tokens based on the tokenizer used during training.\n\nNext, the input sequence is padded using pad_sequences() to ensure that it has the same length as the training sequences.\n\nThe model is then used to predict the label probabilities for the input sequence using model.predict(). The label_probs variable contains the predicted probabilities for each label in the training set.\n\nFinally, a response is generated based on the predicted label. If the predicted label probability is greater than or equal to 0.5, the response \"That sounds romantic!\" is returned. Otherwise, the response \"I'm not sure what you mean.\" is returned.","metadata":{}},{"cell_type":"code","source":"# Define a function to generate a response\ndef generate_response(input_text,max_len = 40):\n    # Tokenize the input text\n    input_sequence = tokenizer.texts_to_sequences([input_text])\n    # Pad the input sequence to have the same length as the training sequences\n    input_sequence = pad_sequences(input_sequence, maxlen=max_len, padding='post')\n    # Predict the label for the input sequence\n    label_probs = model.predict(input_sequence)[0]\n    # Return a response based on the predicted label\n    if label_probs >= 0.5:\n        return \"That sounds romantic!\"\n    else:\n        return \"I'm not sure what you mean.\"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:50:37.403735Z","iopub.execute_input":"2023-05-11T06:50:37.404809Z","iopub.status.idle":"2023-05-11T06:50:37.411815Z","shell.execute_reply.started":"2023-05-11T06:50:37.404764Z","shell.execute_reply":"2023-05-11T06:50:37.410673Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Inferencing the trained model on a sample text.","metadata":{}},{"cell_type":"code","source":"input_text = \"Hey, do you want to go see a movie tonight? I have planned a candle night dinner after that!\"\nresponse = generate_response(input_text)\nprint(response)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:50:37.413932Z","iopub.execute_input":"2023-05-11T06:50:37.414362Z","iopub.status.idle":"2023-05-11T06:50:37.493312Z","shell.execute_reply.started":"2023-05-11T06:50:37.414320Z","shell.execute_reply":"2023-05-11T06:50:37.492154Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 25ms/step\nThat sounds romantic!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}