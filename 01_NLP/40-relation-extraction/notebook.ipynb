{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "> Relation Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first text pair, the relation mentioned in the second text indicates that \"John\" is the CEO of \"Abc.\" In this case, we want the model to predict a positive relation between the two texts, so we assign a label of 1 to indicate a positive relation.\n",
    "\n",
    "In the second text pair, the relation mentioned in the second text indicates that \"Apple\" is a technology company. Since this relation does not match the first text, we want the model to predict a negative relation, so we assign a label of 0 to indicate a negative relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually defined text pairs and labels\n",
    "text_pairs = [\n",
    "    (\"John is the CEO of Apple.\", \"John - CEO - Abc\"),\n",
    "    (\"Abc is a technology company.\", \"Abc - company - technology\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [1, 0]  # 1 for positive relation, 0 for negative relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text pairs\n",
    "tokens = set()\n",
    "for text_pair in text_pairs:\n",
    "    tokens.update(text_pair[0].split())\n",
    "    tokens.update(text_pair[1].split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word-to-index mapping\n",
    "word2idx = {word: idx + 1 for idx, word in enumerate(tokens)}\n",
    "vocab_size = len(word2idx) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text pairs to sequences of indices\n",
    "text_sequences = []\n",
    "for text_pair in text_pairs:\n",
    "    sequence = []\n",
    "    for word in text_pair[0].split():\n",
    "        sequence.append(word2idx[word])\n",
    "    text_sequences.append(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to the same length\n",
    "max_length = max(len(sequence) for sequence in text_sequences)\n",
    "padded_sequences = []\n",
    "for sequence in text_sequences:\n",
    "    padded_sequence = np.pad(sequence, (0, max_length - len(sequence)))\n",
    "    padded_sequences.append(padded_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(padded_sequences)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "embedding_dim = 50\n",
    "hidden_units = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:22:12.766237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 18:22:12.768514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 18:22:12.770359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:22:17.732198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 18:22:17.737835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 18:22:17.740395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-15 18:22:19.160964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 18:22:19.164200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 18:22:19.167320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 12ms/step - loss: 0.6968 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6903 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6856 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6804 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6749 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6688 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6619 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6538 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6443 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6333 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4f0668d30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for prediction\n",
    "test_text_pairs = [\n",
    "    (\"John works at Bcd.\", \"John - employee - Bcd\"),\n",
    "    (\"Abc makes smartphones.\", \"Abc - manufacturer - smartphones\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:22:46.149255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-15 18:22:46.151201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-15 18:22:46.152702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Pair: ('John works at Bcd.', 'John - employee - Bcd')\n",
      "Prediction: [[0.45906538]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Text Pair: ('Abc makes smartphones.', 'Abc - manufacturer - smartphones')\n",
      "Prediction: [[0.4524533]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for test_text_pair in test_text_pairs:\n",
    "    test_sequence = []\n",
    "    for word in test_text_pair[0].split():\n",
    "        if word in word2idx:\n",
    "            test_sequence.append(word2idx[word])\n",
    "        else:\n",
    "            test_sequence.append(0)  # Use 0 for out-of-vocabulary words\n",
    "    test_sequence = np.array(test_sequence)\n",
    "    test_sequence = np.pad(test_sequence, (0, max_length - len(test_sequence)))\n",
    "    test_sequence = np.reshape(test_sequence, (1, -1))\n",
    "\n",
    "    prediction = model.predict(test_sequence)\n",
    "    print(\"Text Pair:\", test_text_pair)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model exhibits 0.45 probability that there is a positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
