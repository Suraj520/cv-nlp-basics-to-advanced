{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "Camera projection matrix for mapping real world 3D cartesian coordinates to Image plane and vice versa.\n",
    "\n",
    "1. Primary assumption is that all the following concepts are applicable for Pinhole camera.\n",
    "2. x = PX is the equation to map a 2D pixel coordinate to 3D world coordinate where x is 2D pixel coordinate, P is projection matrix and X is 3D world coordinate.\n",
    "3. Four coordinate systems that are involved include world, camera, image plane and sensor coordinate system.\n",
    "4. Initially, The camera needs to be localised in the real world coordinate system.\n",
    "5. The camera location is defined by the projection center followed by the rotational matrix. \n",
    "6. Projection matrix is comprised of 11 degrees of freedom - 6 degrees of freedom for camera extrinsic and 5 including distortion parameter for camera intrinsic.\n",
    "7. It's described in the image below\n",
    "![img.jpg](img.jpg)\n",
    "8. We cannot easily invert Projection matrix as there is a loss of information while projecting 3D image to 2D.\n",
    "9. Camera Extrinsic and Camera Intrinsic are parameter of a camera model. The Extrinsic describe the localisation of the camera in real world (Rotational and Translation).\n",
    "10. Camera Intrinsic comprises of Camera constant(C- Distance of image plane to projection center), m - scale diff between x and y along with fx,fy(focal length), px,py(principal point) and distortion parameter(S- Shear parameter) describe how an image in 3D is mapped to 2D.\n",
    "11. Camera Calibration is a technique used for calculating intrinsic parameter of the image.\n",
    "12. Homogeneous coordinates are coordinates system for projective geometry. They allow us to express transformations elegantly for camera model. They can express transformation as matrices and also express points at infinity.\n",
    "13. To convert a point [x,y] in euclidean space, Add a third dimension by adding 1 to it to transform it to homogeneous space [x,y,1]\n",
    "14. To convert a point [x,y,z] from homogenous space to euclidean, divide it by z and remove the 1 i.e [x/z,y/z]\n",
    "15. Scaled versions of [x,y,1] are equal in homogeneous space i.e [nx,ny,n] is space\n",
    "16. [x,y,0] are points at infinity i.e setting last component as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for projecting point cloud\n",
    "import numpy as np\n",
    "\n",
    "def project_pointcloud(point_cloud,rot,trans, f, s_x,s_y, s_theta, theta_x, theta_y):\n",
    "    #converting 3D point cloud to homogeneous coordinate and transposing it\n",
    "    homogeneous_pointcloud = np.hstack((point_cloud,np.ones((point_cloud.shape[0],1)))).T\n",
    "    perspective_projection = np.eye(3,4)\n",
    "\n",
    "    # se matrix containing rotation and translation of the camera\n",
    "    se = np.zeros((4,4))\n",
    "    se[:3,:3] = rot\n",
    "    se[-1,-1]=1\n",
    "    se[:3,-1] = -trans # T is the camera position in the frame hence -ve sign is added\n",
    "\n",
    "    #building up the intrinsic parameter matrxi\n",
    "    k = np.zeros((3,3))\n",
    "    k[0,0] = f* s_x\n",
    "    k[0,1] = f*s_theta\n",
    "    k[1,1] = f* s_y\n",
    "    k[0,2] = theta_x\n",
    "    k[1,2] = theta_y\n",
    "    k[2,2] = 1\n",
    "\n",
    "    #performing matrix mult to get proj matrix\n",
    "    proj_matrix = k @ perspective_projection @ se\n",
    "\n",
    "    #getting depth of points with respect to camer5a\n",
    "    pc_cam_frame = se @ homogeneous_pointcloud\n",
    "    depths = pc_cam_frame[2,:]\n",
    "\n",
    "    # project point cloud onto pixel coordinates of the image\n",
    "\n",
    "    pc_pixel = (proj_matrix @ homogeneous_pointcloud)/depths  #x= PX\n",
    "\n",
    "    return np.rint(pc_pixel)[0:2,:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_pc(pc, R, T, f, s_x, s_y, s_theta, theta_x, theta_y):\n",
    "    # convert 3D pc to homogeneus coordinates and transpose it\n",
    "    # pc_homog is then a 3xN matrix\n",
    "    pc_homog = np.hstack((pc, np.ones((pc.shape[0], 1)))).T\n",
    "    persp_proj = np.eye(3, 4)\n",
    "\n",
    "    # se matrix containing rotation and tranlation of the camera (element of the special euclidean group)\n",
    "    se = np.zeros((4, 4))\n",
    "    se[:3, :3] = R\n",
    "    se[-1,-1] = 1\n",
    "    se[:3, -1] = -T # careful: T is the camera position in the origin frame, this is why we add a minus\n",
    "\n",
    "    # Construct intrinsic parameter matrix K\n",
    "    K = np.zeros((3, 3))\n",
    "    K[0, 0] = f * s_x\n",
    "    K[0, 1] = f * s_theta\n",
    "    K[1, 1] = f * s_y\n",
    "    K[0, 2] = theta_x\n",
    "    K[1, 2] = theta_y\n",
    "    K[2, 2] = 1\n",
    "\n",
    "    K_all = K @ persp_proj @ se\n",
    "\n",
    "    # get depths of points w.r.t camera\n",
    "    pc_cam_frame = se @ pc_homog\n",
    "    depths = pc_cam_frame[2, :]\n",
    "\n",
    "    # project point clooud onto pixel coordinates of the image\n",
    "    pc_pixel = (K_all @ pc_homog)/depths\n",
    "\n",
    "    return np.rint(pc_pixel)[0:2, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading point cloud\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pc = o3d.io.read_point_cloud('cube.ply')\n",
    "o3d.visualization.draw_geometries([pc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncolored point cloud\n",
    "points = np.asarray(pc.points)\n",
    "x,y,z = [],[],[]\n",
    "for i in range(len(points)):\n",
    "    x.append(points[i][0])\n",
    "    y.append(points[i][1])\n",
    "    z.append(points[i][2])\n",
    "\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "z = np.asarray(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's an uncolored point cloud\n",
    "colors = np.asarray(pc.colors)\n",
    "green,red,blue = [],[],[]\n",
    "for i in range(len(points)):\n",
    "    green.append(points[i][0])\n",
    "    red.append(points[i][1])\n",
    "    blue.append(points[i][2])\n",
    "\n",
    "green = np.asarray(green)\n",
    "red = np.asarray(red)\n",
    "blue = np.asarray(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = np.zeros((x.shape[0], 3))\n",
    "pc[:, 0] = x\n",
    "pc[:, 1] = y\n",
    "pc[:, 2] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros((x.shape[0], 3))\n",
    "colors[:, 0] = red\n",
    "colors[:, 1] = green\n",
    "colors[:, 2] = blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the translation and rotational matrices\n",
    "Trans = np.array([-1.6, -1.2, -1])\n",
    "Rot = np.array([[0, -1, 0],\n",
    "              [1, 0, 0],\n",
    "              [0, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1000*3\n",
    "s_x = 1\n",
    "s_y = 1\n",
    "s_theta = 0.5\n",
    "theta_x = 2000\n",
    "theta_y = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8600,  5600],\n",
       "       [ 5300,  3800],\n",
       "       [ 3800,  3800],\n",
       "       [ 5600,  5600],\n",
       "       [10100,  8600],\n",
       "       [ 6050,  5300],\n",
       "       [ 4550,  5300],\n",
       "       [ 7100,  8600]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pixel = project_pointcloud(pc, Rot, Trans, f, s_x, s_y, s_theta, theta_x, theta_y)\n",
    "p_pixel = p_pixel.astype(int)\n",
    "p_pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((p_pixel[:, 1].max()+1, p_pixel[:, 0].max()+1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cur_pixel in enumerate(p_pixel):\n",
    "    img[cur_pixel[1], cur_pixel[0], 0] = red[index]\n",
    "    img[cur_pixel[1], cur_pixel[0], 1] = green[index]\n",
    "    img[cur_pixel[1], cur_pixel[0], 2] = blue[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 1., 0.]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f16b5024910>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(img.astype(np.uint8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50052c996937e9a0e161d422489677fdaadc23d756ac209b7397e80e5ea8cea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
