{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "Stemming involve reduction of a word to its word stem and is vital to various tasks of NLP, NLU.\n",
    "\n",
    "General rule of thumb\n",
    "\n",
    "Reduce the suffix to following\n",
    "\n",
    "1. SSES - SS\n",
    "2. S - NULL\n",
    "3. IES - I\n",
    "4. SS - SS\n",
    "5. LY - LI\n",
    "\n",
    "* Porter Algorithm is the most common algorithm deployed in NLP/NLU tasks for Stemming.\n",
    "* Lancaster Stemming which stems based on the last letter of the words also exists, But is often computationally expensive.\n",
    "* Lovins Stemmer on the other hand is a single pass, context sensitive stemmer which removes ending based on the longest match principle.\n",
    "\n",
    "Snowball Stemmer is mostly deployed for stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: program & Stem: program\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: programmer & Stem: programm\n",
      "Original Word: programmed & Stem: program\n",
      "Original Word: programmatically & Stem: programmat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"program\",\"programming\",\"programmer\",\"programmed\",\"programmatically\"]\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: Only & Stem: onli\n",
      "Original Word: a & Stem: a\n",
      "Original Word: troubled & Stem: troubl\n",
      "Original Word: programmer & Stem: programm\n",
      "Original Word: uses & Stem: use\n",
      "Original Word: troubling & Stem: troubl\n",
      "Original Word: methods & Stem: method\n",
      "Original Word: of & Stem: of\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: to & Stem: to\n",
      "Original Word: write & Stem: write\n",
      "Original Word: a & Stem: a\n",
      "Original Word: better & Stem: better\n",
      "Original Word: program & Stem: program\n",
      "Original Word: with & Stem: with\n",
      "Original Word: which & Stem: which\n",
      "Original Word: others & Stem: other\n",
      "Original Word: are & Stem: are\n",
      "Original Word: not & Stem: not\n",
      "Original Word: troubled & Stem: troubl\n"
     ]
    }
   ],
   "source": [
    "# from sentences\n",
    "sentence = \"Only a troubled programmer uses troubling methods of programming to write a better program with which others are not troubled\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,stemmer.stem(word))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: program & Stem: program\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: programmer & Stem: programm\n",
      "Original Word: programmed & Stem: program\n",
      "Original Word: programmatically & Stem: programmat\n"
     ]
    }
   ],
   "source": [
    "# similarly in place of porter stemmer we can use Snowball stemmer\n",
    "# let's compare the result of snowball stemmer.MARTIN_EXTENSIONS\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "words = [\"program\",\"programming\",\"programmer\",\"programmed\",\"programmatically\"]\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,snowball_stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: Only & Stem: onli\n",
      "Original Word: a & Stem: a\n",
      "Original Word: troubled & Stem: troubl\n",
      "Original Word: programmer & Stem: programm\n",
      "Original Word: uses & Stem: use\n",
      "Original Word: troubling & Stem: troubl\n",
      "Original Word: methods & Stem: method\n",
      "Original Word: of & Stem: of\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: to & Stem: to\n",
      "Original Word: write & Stem: write\n",
      "Original Word: a & Stem: a\n",
      "Original Word: better & Stem: better\n",
      "Original Word: program & Stem: program\n",
      "Original Word: with & Stem: with\n",
      "Original Word: which & Stem: which\n",
      "Original Word: others & Stem: other\n",
      "Original Word: are & Stem: are\n",
      "Original Word: not & Stem: not\n",
      "Original Word: troubled & Stem: troubl\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Only a troubled programmer uses troubling methods of programming to write a better program with which others are not troubled\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,snowball_stemmer.stem(word))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same results from both porter stemmer and Snowball stemmer.\n",
    "Let's evaluate Lancaster Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: program & Stem: program\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: programmer & Stem: program\n",
      "Original Word: programmed & Stem: program\n",
      "Original Word: programmatically & Stem: program\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "words = [\"program\",\"programming\",\"programmer\",\"programmed\",\"programmatically\"]\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,lancaster_stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: Only & Stem: on\n",
      "Original Word: a & Stem: a\n",
      "Original Word: troubled & Stem: troubl\n",
      "Original Word: programmer & Stem: program\n",
      "Original Word: uses & Stem: us\n",
      "Original Word: troubling & Stem: troubl\n",
      "Original Word: methods & Stem: method\n",
      "Original Word: of & Stem: of\n",
      "Original Word: programming & Stem: program\n",
      "Original Word: to & Stem: to\n",
      "Original Word: write & Stem: writ\n",
      "Original Word: a & Stem: a\n",
      "Original Word: better & Stem: bet\n",
      "Original Word: program & Stem: program\n",
      "Original Word: with & Stem: with\n",
      "Original Word: which & Stem: which\n",
      "Original Word: others & Stem: oth\n",
      "Original Word: are & Stem: ar\n",
      "Original Word: not & Stem: not\n",
      "Original Word: troubled & Stem: troubl\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Only a troubled programmer uses troubling methods of programming to write a better program with which others are not troubled\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for word in words:\n",
    "    print((\"Original Word: {} & Stem: {}\").format(word,lancaster_stemmer.stem(word))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the results of Lancaster Stemmer looks different than the previous ones.\n",
    "\n",
    "Similarly, We can use Porter2, Paice-Husk and Lovins Stemming algorithms.\n",
    "\n",
    "<a href=\"https://www.scientificpsychic.com/paice/paice.html\">Relevant Links </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50052c996937e9a0e161d422489677fdaadc23d756ac209b7397e80e5ea8cea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
